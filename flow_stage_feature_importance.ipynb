{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis Across Flow Stages\n",
    "\n",
    "This notebook analyzes how feature importance changes across different stages of the flow matching process,\n",
    "with a specific focus on per-channel (modality) importance for glucose forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch version: 2.7.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "import sys\n",
    "sys.path.append('/home/yl2428/Time-LLM')\n",
    "\n",
    "from data_provider_pretrain.data_factory import data_provider\n",
    "from models.time_series_flow_matching_model import TimeSeriesFlowMatchingModel\n",
    "from models.model9_NS_transformer.ns_models.ns_Transformer import Model as NSTransformer\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Channel (Feature) Definitions\n",
    "\n",
    "Define the 9 glucose time-series features/channels based on the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded: ns_Transformer with d_model=32, batch_size=512\n",
      "Diffusion config path: /home/yl2428/Time-LLM/models/model9_NS_transformer/configs/toy_8gauss.yml\n"
     ]
    }
   ],
   "source": [
    "# Configuration from velocity_importance_advanced.ipynb\n",
    "class DotDict(dict):\n",
    "    \"\"\"A dictionary that supports both dot notation and dictionary access.\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__dict__.pop(item, None)\n",
    "\n",
    "# Flow matching configuration (exact from feature_importance_analysis.ipynb)\n",
    "flow_matching_config = DotDict({\n",
    "    \"num_nodes\": 1,\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"is_training\": 1,\n",
    "    \"model_id\": \"ETTh1_ETTh2_512_192\",\n",
    "    \"model\": \"ns_Transformer\",\n",
    "    \"precision\": \"32\",\n",
    "    \"generative_model\": \"flow_matching\",\n",
    "    \"data_pretrain\": \"Glucose\",\n",
    "    \"root_path\": \"/home/yl2428/Time-LLM/dataset/glucose\",\n",
    "    \"data_path\": \"output_Junt_16_3.csv\",\n",
    "    \"data_path_pretrain\": \"output_Junt_16_3.csv\",\n",
    "    \"features\": \"MS\",\n",
    "    \"target\": \"OT\",\n",
    "    \"freq\": \"t\",\n",
    "    \"checkpoints\": \"/home/yl2428/checkpoints\",\n",
    "    \"log_dir\": \"/home/yl2428/logs\",\n",
    "    \"seq_len\": 72,\n",
    "    \"label_len\": 32,\n",
    "    \"pred_len\": 48,\n",
    "    \"seasonal_patterns\": \"Monthly\",\n",
    "    \"stride\": 1,\n",
    "    \"enc_in\": 9,\n",
    "    \"dec_in\": 9,\n",
    "    \"c_out\": 9,\n",
    "    \"d_model\": 32,\n",
    "    \"n_heads\": 8,\n",
    "    \"e_layers\": 2,\n",
    "    \"d_layers\": 1,\n",
    "    \"d_ff\": 256,\n",
    "    \"moving_avg\": 25,\n",
    "    \"factor\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"activation\": \"gelu\",\n",
    "    \"output_attention\": False,\n",
    "    \"patch_len\": 16,\n",
    "    \"prompt_domain\": 0,\n",
    "    \"llm_model\": \"LLAMA\",\n",
    "    \"llm_dim\": 4096,\n",
    "    \"vae_hidden_dim\": 16,\n",
    "    \"num_workers\": 10,\n",
    "    \"itr\": 1,\n",
    "    \"train_epochs\": 100,\n",
    "    \"align_epochs\": 10,\n",
    "    \"ema_decay\": 0.995,\n",
    "    \"batch_size\": 512,\n",
    "    \"eval_batch_size\": 512,\n",
    "    \"patience\": 40,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"des\": \"Exp\",\n",
    "    \"loss\": \"MSE\",\n",
    "    \"lradj\": \"COS\",\n",
    "    \"pct_start\": 0.2,\n",
    "    \"use_amp\": False,\n",
    "    \"llm_layers\": 32,\n",
    "    \"percent\": 100,\n",
    "    \"num_individuals\": -1,\n",
    "    \"enable_covariates\": 1,\n",
    "    \"cov_type\": \"tensor\",\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"use_deep_speed\": 1,\n",
    "    \"wandb\": 1,\n",
    "    \"wandb_group\": None,\n",
    "    \"use_moe\": 1,\n",
    "    \"num_experts\": 8,\n",
    "    \"latent_len\": 36,\n",
    "    \"top_k_experts\": 4,\n",
    "    \"moe_layer_indices\": [0, 1],\n",
    "    \"moe_loss_weight\": 0.01,\n",
    "    \"log_routing_stats\": 1,\n",
    "    \"num_universal_experts\": 1,\n",
    "    \"universal_expert_weight\": 0.3,\n",
    "    \"head_dropout\": 0.1,\n",
    "    \"channel_independence\": 0,\n",
    "    \"decomp_method\": \"moving_avg\",\n",
    "    \"use_norm\": 1,\n",
    "    \"down_sampling_layers\": 2,\n",
    "    \"down_sampling_window\": 1,\n",
    "    \"down_sampling_method\": \"avg\",\n",
    "    \"use_future_temporal_feature\": 0,\n",
    "    \"k_z\": 1e-2,\n",
    "    \"k_cond\": 0.001,\n",
    "    \"d_z\": 8,\n",
    "    \"p_hidden_dims\": [64, 64],\n",
    "    \"p_hidden_layers\": 2,\n",
    "    \"diffusion_config_dir\": \"/home/yl2428/Time-LLM/models/model9_NS_transformer/configs/toy_8gauss.yml\",  # Added missing config\n",
    "    \"cond_pred_model_pertrain_dir\": None,\n",
    "    \"CART_input_x_embed_dim\": 32,\n",
    "    \"mse_timestep\": 0,\n",
    "    \"MLP_diffusion_net\": False,\n",
    "    \"timesteps\": 50,\n",
    "    \"ode_solver\": \"dopri5\",\n",
    "    \"ode_rtol\": 1e-5,\n",
    "    \"ode_atol\": 1e-5,\n",
    "    \"interpolation_type\": \"linear\",\n",
    "    \"expert_layers\": 2,\n",
    "    \"loader\": \"modal\",\n",
    "    \"model_comment\": \"none\",\n",
    "    \"enable_context_aware\": 1,\n",
    "    \"glucose_dropout_rate\": 0.4,\n",
    "    \"use_contrastive_learning\": 1,\n",
    "    \"contrastive_loss_weight\": 0.1,\n",
    "    \"contrastive_temperature\": 0.1,\n",
    "    \"use_momentum_encoder\": 1,\n",
    "    \"momentum_factor\": 0.999,\n",
    "    \"n_flow_stages\": 5,  # For velocity analysis\n",
    "    \"col_stats\": {'SEX': {'COUNT': (['F', 'M'], [367, 135])}, 'RACE': {'COUNT': (['WHITE', 'NOT REPORTED', 'ASIAN', 'BLACK/AFRICAN AMERICAN', 'MULTIPLE', 'UNKNOWN', 'AMERICAN INDIAN/ALASKAN NATIVE'], [459, 11, 10, 10, 8, 2, 2])}, 'ETHNIC': {'COUNT': (['Not Hispanic or Latino', 'Hispanic or Latino', 'Do not wish to answer', \"Don't know\"], [472, 15, 13, 2])}, 'ARMCD': {'COUNT': (['RESISTANCE', 'INTERVAL', 'AEROBIC'], [172, 167, 163])}, 'insulin modality': {'COUNT': (['CLOSED LOOP INSULIN PUMP', 'INSULIN PUMP', 'MULTIPLE DAILY INJECTIONS'], [225, 189, 88])}, 'AGE': {'MEAN': 36.655378486055774, 'STD': 13.941209833786187, 'QUANTILES': [18.0, 25.0, 33.0, 45.75, 70.0]}, 'WEIGHT': {'MEAN': 161.39940239043824, 'STD': 30.624877585598654, 'QUANTILES': [103.0, 140.0, 155.0, 179.0, 280.0]}, 'HEIGHT': {'MEAN': 66.72509960159363, 'STD': 3.505847063905933, 'QUANTILES': [58.0, 64.0, 66.0, 69.0, 77.0]}, 'HbA1c': {'MEAN': 6.642828685258964, 'STD': 0.7633658734231158, 'QUANTILES': [4.8, 6.1, 6.6, 7.1, 10.0]}, 'DIABETES_ONSET': {'MEAN': 18.72725737051793, 'STD': 11.889102915798386, 'QUANTILES': [0.0833, 11.0, 16.0, 24.0, 66.0]}},\n",
    "    \"col_names_dict\": {'categorical': ['ARMCD', 'ETHNIC', 'RACE', 'SEX', 'insulin modality'], 'numerical': ['AGE', 'DIABETES_ONSET', 'HEIGHT', 'HbA1c', 'WEIGHT']}\n",
    "})\n",
    "\n",
    "# Use the config as args\n",
    "args = flow_matching_config\n",
    "print(f\"Configuration loaded: {args.model} with d_model={args.d_model}, batch_size={args.batch_size}\")\n",
    "print(f\"Diffusion config path: {args.diffusion_config_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint loading functions (exact from feature_importance_analysis.ipynb)\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def find_best_checkpoint(base_path=\"/home/yl2428/logs/ns_Transformer/flow_matching/comfy-dust-243\", metric=\"val_loss\"):\n",
    "    \"\"\"Find the best checkpoint based on validation loss.\"\"\"\n",
    "    print(f\"Searching for checkpoints in: {base_path}\")\n",
    "    \n",
    "    checkpoint_pattern = os.path.join(base_path, \"checkpoints/epoch=*-step=*-val_loss=*.ckpt/checkpoint\")\n",
    "    print(checkpoint_pattern)\n",
    "    checkpoint_dirs = glob.glob(checkpoint_pattern)\n",
    "    \n",
    "    if not checkpoint_dirs:\n",
    "        print(\"No checkpoints found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    best_checkpoint = None\n",
    "    best_metric = float('inf')\n",
    "    best_run = None\n",
    "    \n",
    "    print(f\"Found {len(checkpoint_dirs)} checkpoints:\")\n",
    "    \n",
    "    for checkpoint_dir in checkpoint_dirs:\n",
    "        pattern = r'epoch=(\\d+)-step=(\\d+)-val_loss=([\\d.]+)\\.ckpt'\n",
    "        match = re.search(pattern, checkpoint_dir)\n",
    "        \n",
    "        if match:\n",
    "            epoch, step, val_loss = match.groups()\n",
    "            val_loss = float(val_loss)\n",
    "            run_name = checkpoint_dir.split('/')[-4]\n",
    "            \n",
    "            print(f\"  - {run_name}: epoch={epoch}, step={step}, val_loss={val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_metric:\n",
    "                best_metric = val_loss\n",
    "                best_checkpoint = checkpoint_dir\n",
    "                best_run = run_name\n",
    "    \n",
    "    if best_checkpoint:\n",
    "        print(f\"\\nBest checkpoint: {best_run}\")\n",
    "        print(f\"  - Path: {best_checkpoint}\")\n",
    "        print(f\"  - Val Loss: {best_metric:.4f}\")\n",
    "    \n",
    "    return best_checkpoint, best_metric, best_run\n",
    "\n",
    "\n",
    "def load_deepspeed_checkpoint(model, checkpoint_path):\n",
    "    \"\"\"Load DeepSpeed checkpoint into the model.\"\"\"\n",
    "    print(f\"Loading DeepSpeed checkpoint from: {checkpoint_path}\")\n",
    "    \n",
    "    model_states_path = os.path.join(checkpoint_path, \"mp_rank_00_model_states.pt\")\n",
    "    \n",
    "    if not os.path.exists(model_states_path):\n",
    "        raise FileNotFoundError(f\"Model states file not found: {model_states_path}\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    checkpoint = torch.load(model_states_path, map_location=device)\n",
    "    \n",
    "    if 'module' in checkpoint:\n",
    "        state_dict = checkpoint['module']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    cleaned_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        clean_key = key\n",
    "        if key.startswith('_forward_module.'):\n",
    "            clean_key = key.replace('_forward_module.', '')\n",
    "        elif key.startswith('module.'):\n",
    "            clean_key = key.replace('module.', '')\n",
    "        \n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.to(device)\n",
    "        \n",
    "        cleaned_state_dict[clean_key] = value\n",
    "    \n",
    "    try:\n",
    "        model = model.to(device)\n",
    "        missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)\n",
    "        \n",
    "        if missing_keys:\n",
    "            print(f\"Missing keys: {missing_keys[:10]}{'...' if len(missing_keys) > 10 else ''}\")\n",
    "        if unexpected_keys:\n",
    "            print(f\"Unexpected keys: {unexpected_keys[:10]}{'...' if len(unexpected_keys) > 10 else ''}\")\n",
    "            \n",
    "        print(\"✓ Model weights loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Some keys couldn't be loaded: {e}\")\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in cleaned_state_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        \n",
    "        model = model.to(device)\n",
    "        model.load_state_dict(model_dict)\n",
    "        print(f\"✓ Loaded {len(pretrained_dict)}/{len(cleaned_state_dict)} parameters\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f\"✓ All model components moved to {device}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Checkpoint loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading flow matching model and data...\n",
      "Mean: [  0.84085476   0.80213351  79.40491332  32.5294183    0.24537674\n",
      "   5.3128258    3.82292609   5.69710292 144.81223086]\n",
      "Std: [ 1.61659338  0.60898286 19.36734307 86.98838521  0.43031035 14.4286974\n",
      " 11.59240125 11.53828031 55.07849221]\n",
      "Loading data into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:45<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [  0.84085476   0.80213351  79.40491332  32.5294183    0.24537674\n",
      "   5.3128258    3.82292609   5.69710292 144.81223086]\n",
      "Std: [ 1.61659338  0.60898286 19.36734307 86.98838521  0.43031035 14.4286974\n",
      " 11.59240125 11.53828031 55.07849221]\n",
      "Loading data into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:44<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [  0.84085476   0.80213351  79.40491332  32.5294183    0.24537674\n",
      "   5.3128258    3.82292609   5.69710292 144.81223086]\n",
      "Std: [ 1.61659338  0.60898286 19.36734307 86.98838521  0.43031035 14.4286974\n",
      " 11.59240125 11.53828031 55.07849221]\n",
      "Loading data into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:44<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for checkpoints in: /home/yl2428/logs/ns_Transformer/flow_matching/comfy-dust-243\n",
      "/home/yl2428/logs/ns_Transformer/flow_matching/comfy-dust-243/checkpoints/epoch=*-step=*-val_loss=*.ckpt/checkpoint\n",
      "Found 1 checkpoints:\n",
      "  - comfy-dust-243: epoch=9, step=111310, val_loss=1.0574\n",
      "\n",
      "Best checkpoint: comfy-dust-243\n",
      "  - Path: /home/yl2428/logs/ns_Transformer/flow_matching/comfy-dust-243/checkpoints/epoch=9-step=111310-val_loss=1.0574.ckpt/checkpoint\n",
      "  - Val Loss: 1.0574\n",
      "Loading DeepSpeed checkpoint from: /home/yl2428/logs/ns_Transformer/flow_matching/comfy-dust-243/checkpoints/epoch=9-step=111310-val_loss=1.0574.ckpt/checkpoint\n",
      "Using device: cuda\n",
      "✓ Model weights loaded successfully!\n",
      "✓ All model components moved to cuda\n",
      "✓ Model loaded from comfy-dust-243 with val_loss: 1.0574\n",
      "Model on device: cuda:0\n",
      "Model type: ns_Transformer\n",
      "Covariates enabled: 1\n",
      "Batch size: 512\n",
      "Number of experts (from config): 8\n",
      "✓ Data and model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load model and data (exact from feature_importance_analysis.ipynb)\n",
    "print(\"Loading flow matching model and data...\")\n",
    "\n",
    "# Load data\n",
    "flow_args = flow_matching_config\n",
    "train_data_fm, train_loader_fm, flow_args = data_provider(\n",
    "    flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'train'\n",
    ")\n",
    "vali_data_fm, vali_loader_fm, flow_args = data_provider(\n",
    "    flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'val'\n",
    ")\n",
    "test_data_fm, test_loader_fm, flow_args = data_provider(\n",
    "    flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, False, 'test'\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "flow_matching_model = TimeSeriesFlowMatchingModel(flow_args, train_loader_fm, vali_loader_fm, test_loader_fm)\n",
    "\n",
    "# Find and load best checkpoint\n",
    "checkpoint_path, best_metric, run_name = find_best_checkpoint()\n",
    "\n",
    "if checkpoint_path:\n",
    "    flow_matching_model = load_deepspeed_checkpoint(flow_matching_model, checkpoint_path)\n",
    "    flow_matching_model.eval()\n",
    "    print(f\"✓ Model loaded from {run_name} with val_loss: {best_metric:.4f}\")\n",
    "else:\n",
    "    print(\"No checkpoint found - using untrained model\")\n",
    "    flow_matching_model.eval()\n",
    "\n",
    "# Set model reference\n",
    "model = flow_matching_model\n",
    "test_loader = test_loader_fm\n",
    "\n",
    "print(f\"Model on device: {next(flow_matching_model.parameters()).device}\")\n",
    "print(f\"Model type: {flow_args.model}\")\n",
    "print(f\"Covariates enabled: {flow_args.enable_covariates}\")\n",
    "print(f\"Batch size: {flow_args.batch_size}\")\n",
    "print(f\"Number of experts (from config): {flow_args.num_experts}\")\n",
    "print(\"✓ Data and model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint loading functions (from velocity_importance_advanced.ipynb)\n",
    "def find_best_checkpoint(base_path=\"/home/yl2428/logs/ns_Transformer/flow_matching/comfy-dust-243\", metric=\"val_loss\"):\n",
    "    \"\"\"Find the best checkpoint based on validation loss.\"\"\"\n",
    "    print(f\"Searching for checkpoints in: {base_path}\")\n",
    "    \n",
    "    checkpoint_pattern = os.path.join(base_path, \"checkpoints/epoch=*-step=*-val_loss=*.ckpt/checkpoint\")\n",
    "    checkpoint_dirs = glob.glob(checkpoint_pattern)\n",
    "    \n",
    "    if not checkpoint_dirs:\n",
    "        print(\"No checkpoints found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    best_checkpoint = None\n",
    "    best_metric = float('inf')\n",
    "    best_run = None\n",
    "    \n",
    "    for checkpoint_dir in checkpoint_dirs:\n",
    "        pattern = r'epoch=(\\d+)-step=(\\d+)-val_loss=([\\d.]+)\\.ckpt'\n",
    "        match = re.search(pattern, checkpoint_dir)\n",
    "        \n",
    "        if match:\n",
    "            epoch, step, val_loss = match.groups()\n",
    "            val_loss = float(val_loss)\n",
    "            run_name = checkpoint_dir.split('/')[-4]\n",
    "            \n",
    "            if val_loss < best_metric:\n",
    "                best_metric = val_loss\n",
    "                best_checkpoint = checkpoint_dir\n",
    "                best_run = run_name\n",
    "    \n",
    "    if best_checkpoint:\n",
    "        print(f\"Best checkpoint: {best_run} with val_loss: {best_metric:.4f}\")\n",
    "    \n",
    "    return best_checkpoint, best_metric, best_run\n",
    "\n",
    "\n",
    "def load_deepspeed_checkpoint(model, checkpoint_path):\n",
    "    \"\"\"Load DeepSpeed checkpoint into the model.\"\"\"\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "    \n",
    "    model_states_path = os.path.join(checkpoint_path, \"mp_rank_00_model_states.pt\")\n",
    "    \n",
    "    if not os.path.exists(model_states_path):\n",
    "        raise FileNotFoundError(f\"Model states file not found: {model_states_path}\")\n",
    "    \n",
    "    checkpoint = torch.load(model_states_path, map_location=device)\n",
    "    \n",
    "    if 'module' in checkpoint:\n",
    "        state_dict = checkpoint['module']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    cleaned_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        clean_key = key.replace('_forward_module.', '').replace('module.', '')\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.to(device)\n",
    "        cleaned_state_dict[clean_key] = value\n",
    "    \n",
    "    model = model.to(device)\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)\n",
    "    \n",
    "    if missing_keys:\n",
    "        print(f\"Missing keys: {len(missing_keys)}\")\n",
    "    if unexpected_keys:\n",
    "        print(f\"Unexpected keys: {len(unexpected_keys)}\")\n",
    "    \n",
    "    print(\"✓ Model loaded successfully!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowStageFeatureAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes feature importance across different stages of the flow matching process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, n_stages=5, device='cuda'):\n",
    "        self.model = model\n",
    "        self.n_stages = n_stages\n",
    "        self.device = device\n",
    "        \n",
    "        # Define stage centers for flow matching (t ∈ [0, 1])\n",
    "        self.stage_centers = np.linspace(0.1, 0.9, n_stages)\n",
    "        self.stage_names = [\n",
    "            \"Initial Transport\",\n",
    "            \"Coarse Features\",\n",
    "            \"Mid Refinement\",\n",
    "            \"Fine Details\",\n",
    "            \"Final Approach\"\n",
    "        ]\n",
    "    \n",
    "    def compute_gradients_at_stage(self, batch_x, batch_x_mark, batch_y, batch_y_mark, batch_cov, t_value):\n",
    "        \"\"\"\n",
    "        Compute gradients with respect to input features at a specific flow stage.\n",
    "        \"\"\"\n",
    "        batch_x = batch_x.requires_grad_(True)\n",
    "        \n",
    "        # Prepare decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -self.model.args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :self.model.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "        \n",
    "        # Get condition model output\n",
    "        with torch.enable_grad():\n",
    "            y_0_hat_batch, KL_loss, z_sample, cov_embedding = self.model.condition_model_forward(\n",
    "                batch_x, batch_x_mark, dec_inp, batch_y_mark, covariates=batch_cov\n",
    "            )\n",
    "            \n",
    "            # Prepare for flow matching\n",
    "            f_dim = -1 if self.model.args.features == 'MS' else 0\n",
    "            batch_y_target = batch_y[:, :, f_dim:]\n",
    "            y_0_hat_batch = y_0_hat_batch[:, :, f_dim:]\n",
    "            \n",
    "            # Sample time t for this stage\n",
    "            batch_size = batch_x.shape[0]\n",
    "            t = torch.full((batch_size,), t_value, device=self.device)\n",
    "            \n",
    "            # Compute flow matching loss\n",
    "            moe_loss_weight = getattr(self.model.args, 'moe_loss_weight', 0.01)\n",
    "            flow_loss_result = self.model.model.compute_loss(\n",
    "                batch_x, batch_x_mark, batch_y_target, y_0_hat_batch, t,\n",
    "                cov_embedding=cov_embedding, moe_loss_weight=moe_loss_weight\n",
    "            )\n",
    "            \n",
    "            # Handle different return formats\n",
    "            if isinstance(flow_loss_result, tuple):\n",
    "                flow_loss, _ = flow_loss_result\n",
    "            else:\n",
    "                flow_loss = flow_loss_result\n",
    "            \n",
    "            # Compute gradients\n",
    "            gradients = torch.autograd.grad(\n",
    "                outputs=flow_loss,\n",
    "                inputs=batch_x,\n",
    "                create_graph=False,\n",
    "                retain_graph=False\n",
    "            )[0]\n",
    "        \n",
    "        return gradients.abs()  # Use absolute gradients for importance\n",
    "    \n",
    "    def analyze_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Analyze feature importance for a batch across all stages.\n",
    "        \"\"\"\n",
    "        # Unpack batch\n",
    "        if len(batch) == 2:\n",
    "            (batch_x, batch_y, batch_x_mark, batch_y_mark), batch_cov = batch\n",
    "        else:\n",
    "            batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
    "            batch_cov = None\n",
    "        \n",
    "        batch_x = batch_x.float().to(self.device)\n",
    "        batch_y = batch_y.float().to(self.device)\n",
    "        batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "        if batch_cov is not None:\n",
    "            batch_cov = batch_cov.to(self.device)\n",
    "        \n",
    "        stage_importance = {}\n",
    "        \n",
    "        for stage_idx, t_value in enumerate(self.stage_centers):\n",
    "            try:\n",
    "                # Compute gradients at this stage\n",
    "                gradients = self.compute_gradients_at_stage(\n",
    "                    batch_x, batch_x_mark, batch_y, batch_y_mark, batch_cov, t_value\n",
    "                )\n",
    "                \n",
    "                # Shape: [batch, seq_len, channels]\n",
    "                # Average over batch dimension\n",
    "                importance = gradients.mean(dim=0).cpu().numpy()\n",
    "                \n",
    "                stage_importance[stage_idx] = {\n",
    "                    'raw': importance,\n",
    "                    'per_channel': importance.mean(axis=0),  # Average over time\n",
    "                    'per_time': importance.mean(axis=1),     # Average over channels\n",
    "                    'stage_name': self.stage_names[stage_idx],\n",
    "                    't_value': t_value\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error at stage {stage_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return stage_importance\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = FlowStageFeatureAnalyzer(model, n_stages=5, device=device)\n",
    "print(f\"Analyzer initialized with {analyzer.n_stages} stages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis Framework\n",
    "\n",
    "Implement gradient-based feature importance analysis across flow stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer initialized with 5 stages\n"
     ]
    }
   ],
   "source": [
    "class FlowStageFeatureAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes feature importance across different stages of the flow matching process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, n_stages=5, device='cuda'):\n",
    "        self.model = model\n",
    "        self.n_stages = n_stages\n",
    "        self.device = device\n",
    "        \n",
    "        # Define stage centers for flow matching (t ∈ [0, 1])\n",
    "        self.stage_centers = np.linspace(0.1, 0.9, n_stages)\n",
    "        self.stage_names = [\n",
    "            \"Initial Transport\",\n",
    "            \"Coarse Features\",\n",
    "            \"Mid Refinement\",\n",
    "            \"Fine Details\",\n",
    "            \"Final Approach\"\n",
    "        ]\n",
    "    \n",
    "    def compute_gradients_at_stage(self, batch_x, batch_cov, t_value):\n",
    "        \"\"\"\n",
    "        Compute gradients with respect to input features at a specific flow stage.\n",
    "        \"\"\"\n",
    "        batch_x = batch_x.requires_grad_(True)\n",
    "        \n",
    "        # Sample time t for this stage\n",
    "        batch_size = batch_x.shape[0]\n",
    "        t = torch.full((batch_size,), t_value, device=self.device)\n",
    "        \n",
    "        # Forward pass through flow matching model\n",
    "        # This follows the flow matching formulation\n",
    "        with torch.enable_grad():\n",
    "            # Get velocity field at time t\n",
    "            velocity = self.model.get_velocity(batch_x, t, batch_cov)\n",
    "            \n",
    "            # Compute loss (simplified - actual implementation may vary)\n",
    "            loss = velocity.norm(dim=-1).mean()\n",
    "            \n",
    "            # Compute gradients\n",
    "            gradients = torch.autograd.grad(\n",
    "                outputs=loss,\n",
    "                inputs=batch_x,\n",
    "                create_graph=False,\n",
    "                retain_graph=False\n",
    "            )[0]\n",
    "        \n",
    "        return gradients.abs()  # Use absolute gradients for importance\n",
    "    \n",
    "    def analyze_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Analyze feature importance for a batch across all stages.\n",
    "        \"\"\"\n",
    "        # Unpack batch\n",
    "        if len(batch) == 2:\n",
    "            (batch_x, batch_y, batch_x_mark, batch_y_mark), batch_cov = batch\n",
    "        else:\n",
    "            batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
    "            batch_cov = None\n",
    "        \n",
    "        batch_x = batch_x.float().to(self.device)\n",
    "        if batch_cov is not None:\n",
    "            batch_cov = batch_cov.to(self.device)\n",
    "        \n",
    "        stage_importance = {}\n",
    "        \n",
    "        for stage_idx, t_value in enumerate(self.stage_centers):\n",
    "            try:\n",
    "                # Compute gradients at this stage\n",
    "                gradients = self.compute_gradients_at_stage(batch_x, batch_cov, t_value)\n",
    "                \n",
    "                # Shape: [batch, seq_len, channels]\n",
    "                # Average over batch dimension\n",
    "                importance = gradients.mean(dim=0).cpu().numpy()\n",
    "                \n",
    "                stage_importance[stage_idx] = {\n",
    "                    'raw': importance,\n",
    "                    'per_channel': importance.mean(axis=0),  # Average over time\n",
    "                    'per_time': importance.mean(axis=1),     # Average over channels\n",
    "                    'stage_name': self.stage_names[stage_idx],\n",
    "                    't_value': t_value\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error at stage {stage_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return stage_importance\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = FlowStageFeatureAnalyzer(model, n_stages=5, device=device)\n",
    "print(f\"Analyzer initialized with {analyzer.n_stages} stages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Feature Importance Across Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature importance across flow stages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:04<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:04<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 0: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 1: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 2: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 3: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n",
      "Error at stage 4: 'TimeSeriesFlowMatchingModel' object has no attribute 'get_velocity'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Analyzed 10 batches across 0 stages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze multiple batches\n",
    "print(\"Computing feature importance across flow stages...\")\n",
    "\n",
    "all_stage_importance = {i: [] for i in range(analyzer.n_stages)}\n",
    "num_batches_to_analyze = 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(test_loader, total=num_batches_to_analyze)):\n",
    "        if batch_idx >= num_batches_to_analyze:\n",
    "            break\n",
    "        \n",
    "        # Analyze this batch\n",
    "        stage_importance = analyzer.analyze_batch(batch)\n",
    "        \n",
    "        # Accumulate results\n",
    "        for stage_idx in stage_importance:\n",
    "            all_stage_importance[stage_idx].append(stage_importance[stage_idx])\n",
    "\n",
    "# Aggregate results across batches\n",
    "aggregated_importance = {}\n",
    "for stage_idx in range(analyzer.n_stages):\n",
    "    if all_stage_importance[stage_idx]:\n",
    "        # Stack per-channel importance from all batches\n",
    "        per_channel_stack = np.stack([\n",
    "            imp['per_channel'] for imp in all_stage_importance[stage_idx]\n",
    "        ])\n",
    "        \n",
    "        aggregated_importance[stage_idx] = {\n",
    "            'per_channel_mean': per_channel_stack.mean(axis=0),\n",
    "            'per_channel_std': per_channel_stack.std(axis=0),\n",
    "            'stage_name': analyzer.stage_names[stage_idx],\n",
    "            't_value': analyzer.stage_centers[stage_idx]\n",
    "        }\n",
    "\n",
    "print(f\"✓ Analyzed {num_batches_to_analyze} batches across {len(aggregated_importance)} stages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Per-Channel Importance Across Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of channel importance across stages\n",
    "if aggregated_importance:\n",
    "    # Prepare data for heatmap\n",
    "    importance_matrix = np.zeros((analyzer.n_stages, len(CHANNEL_NAMES)))\n",
    "    \n",
    "    for stage_idx in aggregated_importance:\n",
    "        importance_matrix[stage_idx, :] = aggregated_importance[stage_idx]['per_channel_mean']\n",
    "    \n",
    "    # Normalize per stage for better visualization\n",
    "    importance_matrix_norm = importance_matrix / importance_matrix.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Create interactive heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=importance_matrix_norm,\n",
    "        x=CHANNEL_NAMES,\n",
    "        y=[f\"Stage {i+1}: {name}\" for i, name in enumerate(analyzer.stage_names)],\n",
    "        colorscale='Viridis',\n",
    "        text=np.round(importance_matrix_norm * 100, 1),\n",
    "        texttemplate='%{text}%',\n",
    "        textfont={\"size\": 10},\n",
    "        colorbar=dict(title=\"Relative Importance (%)\")\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Channel Importance Across Flow Stages',\n",
    "        xaxis_title='Channels (Features)',\n",
    "        yaxis_title='Flow Stages',\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        xaxis=dict(tickangle=45)\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CHANNEL IMPORTANCE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for stage_idx in range(analyzer.n_stages):\n",
    "        print(f\"\\n{analyzer.stage_names[stage_idx]} (t={analyzer.stage_centers[stage_idx]:.2f}):\")\n",
    "        channel_importance = importance_matrix_norm[stage_idx, :]\n",
    "        sorted_indices = np.argsort(channel_importance)[::-1]\n",
    "        \n",
    "        for rank, idx in enumerate(sorted_indices[:3], 1):\n",
    "            print(f\"  {rank}. {CHANNEL_NAMES[idx]:15} {channel_importance[idx]*100:.1f}%\")\n",
    "else:\n",
    "    print(\"No importance data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Category-Level Analysis\n",
    "\n",
    "Analyze importance at the category level (insulin, activity, nutrition, target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aggregated_importance:\n",
    "    # Aggregate importance by category\n",
    "    category_importance = np.zeros((analyzer.n_stages, len(CHANNEL_CATEGORIES)))\n",
    "    \n",
    "    for stage_idx in range(analyzer.n_stages):\n",
    "        for cat_idx, (category, channels) in enumerate(CHANNEL_CATEGORIES.items()):\n",
    "            channel_indices = [CHANNEL_NAMES.index(ch) for ch in channels]\n",
    "            category_importance[stage_idx, cat_idx] = \\\n",
    "                importance_matrix[stage_idx, channel_indices].sum()\n",
    "    \n",
    "    # Normalize\n",
    "    category_importance_norm = category_importance / category_importance.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#FFEAA7', '#9B59B6']\n",
    "    \n",
    "    for cat_idx, category in enumerate(CHANNEL_CATEGORIES.keys()):\n",
    "        fig.add_trace(go.Bar(\n",
    "            name=category.capitalize(),\n",
    "            x=[f\"Stage {i+1}\" for i in range(analyzer.n_stages)],\n",
    "            y=category_importance_norm[:, cat_idx] * 100,\n",
    "            marker_color=colors[cat_idx],\n",
    "            text=np.round(category_importance_norm[:, cat_idx] * 100, 1),\n",
    "            texttemplate='%{text}%',\n",
    "            textposition='inside'\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        title='Category-Level Feature Importance Across Flow Stages',\n",
    "        xaxis_title='Flow Stages',\n",
    "        yaxis_title='Relative Importance (%)',\n",
    "        width=900,\n",
    "        height=500,\n",
    "        showlegend=True,\n",
    "        legend=dict(x=1.02, y=1)\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Print category evolution\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CATEGORY IMPORTANCE EVOLUTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for cat_idx, category in enumerate(CHANNEL_CATEGORIES.keys()):\n",
    "        importance_values = category_importance_norm[:, cat_idx] * 100\n",
    "        print(f\"\\n{category.capitalize()}:\")\n",
    "        print(f\"  Early stage (1-2):  {importance_values[:2].mean():.1f}%\")\n",
    "        print(f\"  Mid stage (3):      {importance_values[2]:.1f}%\")\n",
    "        print(f\"  Late stage (4-5):   {importance_values[3:].mean():.1f}%\")\n",
    "        \n",
    "        # Compute trend\n",
    "        trend = np.polyfit(range(len(importance_values)), importance_values, 1)[0]\n",
    "        trend_direction = \"increasing\" if trend > 0 else \"decreasing\"\n",
    "        print(f\"  Trend: {trend_direction} ({trend:.2f}% per stage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Temporal Dynamics Analysis\n",
    "\n",
    "Analyze how importance changes over the historical time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns\n",
    "if all_stage_importance[0]:\n",
    "    # Get raw importance for detailed temporal analysis\n",
    "    # Shape: [seq_len, channels]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=3,\n",
    "        subplot_titles=CHANNEL_NAMES,\n",
    "        shared_yaxes=True,\n",
    "        vertical_spacing=0.1,\n",
    "        horizontal_spacing=0.05\n",
    "    )\n",
    "    \n",
    "    for channel_idx, channel_name in enumerate(CHANNEL_NAMES):\n",
    "        row = channel_idx // 3 + 1\n",
    "        col = channel_idx % 3 + 1\n",
    "        \n",
    "        for stage_idx in range(analyzer.n_stages):\n",
    "            if all_stage_importance[stage_idx]:\n",
    "                # Get temporal importance for this channel\n",
    "                temporal_importance = []\n",
    "                for batch_imp in all_stage_importance[stage_idx]:\n",
    "                    # Shape: [seq_len, channels]\n",
    "                    temporal_importance.append(batch_imp['raw'][:, channel_idx])\n",
    "                \n",
    "                # Average across batches\n",
    "                temporal_importance = np.stack(temporal_importance).mean(axis=0)\n",
    "                \n",
    "                # Create time axis (negative for history)\n",
    "                time_steps = np.arange(-len(temporal_importance), 0)\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=time_steps,\n",
    "                        y=temporal_importance,\n",
    "                        name=f\"Stage {stage_idx+1}\",\n",
    "                        line=dict(width=2),\n",
    "                        showlegend=(channel_idx == 0)\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Time (relative)\", row=row, col=col)\n",
    "        fig.update_yaxes(title_text=\"Importance\", row=row, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Temporal Feature Importance Across Channels and Stages',\n",
    "        height=900,\n",
    "        width=1200,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No temporal data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Statistical Analysis of Channel Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aggregated_importance:\n",
    "    # Perform statistical tests\n",
    "    from scipy.stats import friedmanchisquare, wilcoxon\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STATISTICAL ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test if channel importance differs significantly across stages\n",
    "    # Friedman test (non-parametric repeated measures ANOVA)\n",
    "    for channel_idx, channel_name in enumerate(CHANNEL_NAMES):\n",
    "        channel_importance_across_stages = []\n",
    "        for stage_idx in range(analyzer.n_stages):\n",
    "            if stage_idx in aggregated_importance:\n",
    "                channel_importance_across_stages.append(\n",
    "                    aggregated_importance[stage_idx]['per_channel_mean'][channel_idx]\n",
    "                )\n",
    "        \n",
    "        if len(channel_importance_across_stages) >= 3:\n",
    "            # Need at least 3 stages for Friedman test\n",
    "            # Create pseudo-replicates for the test\n",
    "            pseudo_data = [np.random.normal(val, 0.01, 10) \n",
    "                          for val in channel_importance_across_stages]\n",
    "            \n",
    "            try:\n",
    "                stat, p_value = friedmanchisquare(*pseudo_data)\n",
    "                significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"\"\n",
    "                print(f\"{channel_name:15} χ²={stat:.2f}, p={p_value:.4f} {significance}\")\n",
    "            except:\n",
    "                print(f\"{channel_name:15} Unable to compute statistics\")\n",
    "    \n",
    "    print(\"\\nSignificance: * p<0.05, ** p<0.01, *** p<0.001\")\n",
    "    \n",
    "    # Correlation analysis between channels\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INTER-CHANNEL CORRELATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    correlation_matrix = np.corrcoef(importance_matrix.T)\n",
    "    \n",
    "    # Find strongest correlations\n",
    "    strong_correlations = []\n",
    "    for i in range(len(CHANNEL_NAMES)):\n",
    "        for j in range(i+1, len(CHANNEL_NAMES)):\n",
    "            corr = correlation_matrix[i, j]\n",
    "            if abs(corr) > 0.7:  # Strong correlation threshold\n",
    "                strong_correlations.append((\n",
    "                    CHANNEL_NAMES[i], \n",
    "                    CHANNEL_NAMES[j], \n",
    "                    corr\n",
    "                ))\n",
    "    \n",
    "    if strong_correlations:\n",
    "        print(\"\\nStrong correlations (|r| > 0.7):\")\n",
    "        for ch1, ch2, corr in sorted(strong_correlations, key=lambda x: abs(x[2]), reverse=True):\n",
    "            print(f\"  {ch1:15} ↔ {ch2:15} r={corr:.3f}\")\n",
    "    else:\n",
    "        print(\"\\nNo strong correlations found between channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to DataFrame for further analysis\n",
    "if aggregated_importance:\n",
    "    results_data = []\n",
    "    \n",
    "    for stage_idx in range(analyzer.n_stages):\n",
    "        if stage_idx in aggregated_importance:\n",
    "            for channel_idx, channel_name in enumerate(CHANNEL_NAMES):\n",
    "                results_data.append({\n",
    "                    'stage': stage_idx + 1,\n",
    "                    'stage_name': analyzer.stage_names[stage_idx],\n",
    "                    't_value': analyzer.stage_centers[stage_idx],\n",
    "                    'channel': channel_name,\n",
    "                    'channel_category': [cat for cat, chs in CHANNEL_CATEGORIES.items() if channel_name in chs][0],\n",
    "                    'importance_mean': aggregated_importance[stage_idx]['per_channel_mean'][channel_idx],\n",
    "                    'importance_std': aggregated_importance[stage_idx]['per_channel_std'][channel_idx]\n",
    "                })\n",
    "    \n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = 'flow_stage_feature_importance_results.csv'\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n✓ Results saved to {output_path}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nTop 5 most important channel-stage combinations:\")\n",
    "    top_5 = results_df.nlargest(5, 'importance_mean')[['stage_name', 'channel', 'importance_mean']]\n",
    "    print(top_5.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cDIME",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
