{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from data_provider_pretrain.data_factory import data_provider\n",
    "from models.time_series_diffusion_model import TimeSeriesDiffusionModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from utils.callbacks import EMA\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import wandb\n",
    "from datetime import timedelta\n",
    "from utils.clean_args import clean_args\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Time-LLM')\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "torch.cuda.manual_seed(fix_seed)\n",
    "torch.cuda.manual_seed_all(fix_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class DotDict(dict):\n",
    "    \"\"\"\n",
    "    A dictionary that supports both dot notation and dictionary access.\n",
    "    This allows both `args.att` and `args['att']` to work.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__dict__.pop(item, None)\n",
    "\n",
    "default_config = DotDict({\n",
    "    # Basic config\n",
    "    \"num_nodes\": 1,\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"is_training\": 1,\n",
    "    \"model_id\": \"ETTh1_ETTh2_512_192\",\n",
    "    \"model\": \"ns_Transformer\",\n",
    "    \"precision\": \"32\",\n",
    "    \n",
    "    # Data loader\n",
    "    \"data_pretrain\": \"Glucose\",\n",
    "    \"root_path\": \"/home/yl2428/Time-LLM/dataset/glucose\",\n",
    "    \"data_path\": \"combined_data_Jun_28.csv\",\n",
    "    \"data_path_pretrain\": \"combined_data_Jun_28.csv\",\n",
    "    \"features\": \"M\",\n",
    "    \"target\": \"OT\",\n",
    "    \"freq\": \"t\",\n",
    "    \"checkpoints\": \"/gpfs/gibbs/pi/gerstein/yl2428/checkpoints/\",\n",
    "    \"log_dir\": \"/gpfs/gibbs/pi/gerstein/yl2428/logs\",\n",
    "    \n",
    "    # Forecasting task\n",
    "    \"seq_len\": 128,\n",
    "    \"label_len\": 12,\n",
    "    \"pred_len\": 32,\n",
    "    \"seasonal_patterns\": \"Monthly\",\n",
    "    \"stride\": 8,\n",
    "    \n",
    "    # Model define\n",
    "    \"enc_in\": 4,\n",
    "    \"dec_in\": 4,\n",
    "    \"c_out\": 4,\n",
    "    \"d_model\": 32,\n",
    "    \"n_heads\": 8,\n",
    "    \"e_layers\": 2,\n",
    "    \"d_layers\": 1,\n",
    "    \"d_ff\": 128,\n",
    "    \"moving_avg\": 25,\n",
    "    \"factor\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"activation\": \"gelu\",\n",
    "    \"output_attention\": False,\n",
    "    \"patch_len\": 16,\n",
    "    \"prompt_domain\": 0,\n",
    "    \"llm_model\": \"LLAMA\",\n",
    "    \"llm_dim\": 4096,\n",
    "    \n",
    "    # Optimization\n",
    "    \"num_workers\": 10,\n",
    "    \"itr\": 1,\n",
    "    \"train_epochs\": 100,\n",
    "    \"align_epochs\": 10,\n",
    "    \"ema_decay\": 0.97,\n",
    "    \"batch_size\": 64,\n",
    "    \"eval_batch_size\": 2,\n",
    "    \"patience\": 10,\n",
    "    \"learning_rate\": 0.0004,\n",
    "    \"des\": \"Exp\",\n",
    "    \"loss\": \"MSE\",\n",
    "    \"lradj\": \"COS\",\n",
    "    \"pct_start\": 0.2,\n",
    "    \"use_amp\": False,\n",
    "    \"llm_layers\": 32,\n",
    "    \"percent\": 100,\n",
    "    \"num_individuals\": -1,\n",
    "    \"enable_covariates\": 1,\n",
    "    \"cov_type\": \"tensor\",\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"use_deep_speed\": 1,\n",
    "    \n",
    "    # Wandb\n",
    "    \"wandb\": 1,\n",
    "    \"wandb_group\": None,\n",
    "    \"wandb_api_key\": \"6f1080f993d5d7ad6103e69ef57dd9291f1bf366\",\n",
    "    \"num_experts\": 8,\n",
    "    \"head_dropout\": 0.1,\n",
    "    \n",
    "    # TimeMixer-specific parameters\n",
    "    \"channel_independence\": 0,\n",
    "    \"decomp_method\": \"moving_avg\",\n",
    "    \"use_norm\": 1,\n",
    "    \"down_sampling_layers\": 2,\n",
    "    \"down_sampling_window\": 1,\n",
    "    \"down_sampling_method\": \"avg\",\n",
    "    \"use_future_temporal_feature\": 0,\n",
    "    \n",
    "    # Diffusion specific parameters\n",
    "    \"k_z\": 1e-2,\n",
    "    \"k_cond\": 1,\n",
    "    \"d_z\": 8,\n",
    "    \n",
    "    # De-stationary projector params\n",
    "    \"p_hidden_dims\": [64, 64],\n",
    "    \"p_hidden_layers\": 2,\n",
    "    \n",
    "    # CART related args\n",
    "    \"diffusion_config_dir\": \"/home/yl2428/Time-LLM/models/model9_NS_transformer/configs/toy_8gauss.yml\",\n",
    "    \"cond_pred_model_pertrain_dir\": None,\n",
    "    \"CART_input_x_embed_dim\": 32,\n",
    "    \"mse_timestep\": 0,\n",
    "    \"MLP_diffusion_net\": False,\n",
    "    \n",
    "    # Ax args\n",
    "    \"timesteps\": 1000,\n",
    "    \n",
    "    # Additional parameters\n",
    "    \"master_port\": 8889,\n",
    "    \"comment\": \"TimeLLM-ECL\"\n",
    "})\n",
    "\n",
    "\n",
    "args = default_config\n",
    "\n",
    "for ii in range(args.itr):\n",
    "    train_data, train_loader, args = data_provider(args, args.data_pretrain, args.data_path_pretrain, True, 'train')\n",
    "    vali_data, vali_loader, args = data_provider(args, args.data_pretrain, args.data_path_pretrain, True, 'val')\n",
    "    test_data, test_loader, args = data_provider(args, args.data_pretrain, args.data_path_pretrain, False, 'test')\n",
    "    model = TimeSeriesDiffusionModel(args, train_loader, vali_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from data_provider_pretrain.data_factory import data_provider\n",
    "from models.time_series_flow_matching_model import TimeSeriesFlowMatchingModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from utils.callbacks import EMA\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import wandb\n",
    "from datetime import timedelta\n",
    "from utils.clean_args import clean_args\n",
    "import glob\n",
    "import re\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "torch.cuda.manual_seed(fix_seed)\n",
    "torch.cuda.manual_seed_all(fix_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class DotDict(dict):\n",
    "    \"\"\"\n",
    "    A dictionary that supports both dot notation and dictionary access.\n",
    "    This allows both `args.att` and `args['att']` to work.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__dict__.pop(item, None)\n",
    "\n",
    "# Flow matching configuration based on train_glucose_diffusion_slurm.sh\n",
    "flow_matching_config = DotDict({\n",
    "    # Basic config\n",
    "    \"num_nodes\": 1,\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"is_training\": 1,\n",
    "    \"model_id\": \"ETTh1_ETTh2_512_192\",\n",
    "    \"model\": \"ns_DLinear\",  # From shell script\n",
    "    \"precision\": \"32\",\n",
    "    \"generative_model\": \"flow_matching\",  # Key difference from diffusion\n",
    "    \n",
    "    # Data loader (from shell script)\n",
    "    \"data_pretrain\": \"Glucose\",\n",
    "    \"root_path\": \"/home/yl2428/Time-LLM/dataset/glucose\",\n",
    "    \"data_path\": \"combined_data_Jun_28.csv\",\n",
    "    \"data_path_pretrain\": \"combined_data_Jun_28.csv\",\n",
    "    \"features\": \"MS\",  # From shell script\n",
    "    \"target\": \"OT\",\n",
    "    \"freq\": \"t\",\n",
    "    \"checkpoints\": \"/home/yl2428/checkpoints/\",\n",
    "    \"log_dir\": \"/home/yl2428/logs\",\n",
    "    \n",
    "    # Forecasting task (from shell script)\n",
    "    \"seq_len\": 48,\n",
    "    \"label_len\": 32,\n",
    "    \"pred_len\": 36,\n",
    "    \"seasonal_patterns\": \"Monthly\",\n",
    "    \"stride\": 1,  # From shell script\n",
    "    \n",
    "    # Model define (from shell script)\n",
    "    \"enc_in\": 4,\n",
    "    \"dec_in\": 4,\n",
    "    \"c_out\": 4,\n",
    "    \"d_model\": 32,  # From shell script\n",
    "    \"n_heads\": 8,\n",
    "    \"e_layers\": 2,\n",
    "    \"d_layers\": 1,\n",
    "    \"d_ff\": 256,  # From shell script\n",
    "    \"moving_avg\": 25,\n",
    "    \"factor\": 3,  # From shell script\n",
    "    \"dropout\": 0.1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"activation\": \"gelu\",\n",
    "    \"output_attention\": False,\n",
    "    \"patch_len\": 16,\n",
    "    \"prompt_domain\": 0,\n",
    "    \"llm_model\": \"LLAMA\",\n",
    "    \"llm_dim\": 4096,\n",
    "    \n",
    "    # VAE-specific parameters for ns_DLinear\n",
    "    \"latent_len\": 24,  # Half of seq_len by default\n",
    "    \"vae_hidden_dim\": 16,\n",
    "    \n",
    "    # Required for Trompt encoder - these will be populated by data_provider\n",
    "    \"col_stats\": None,\n",
    "    \"col_names_dict\": None,\n",
    "    \n",
    "    # Optimization (from shell script)\n",
    "    \"num_workers\": 10,\n",
    "    \"itr\": 1,\n",
    "    \"train_epochs\": 100,  # From shell script\n",
    "    \"align_epochs\": 10,\n",
    "    \"ema_decay\": 0.995,\n",
    "    \"batch_size\": 64,  # From shell script\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"patience\": 10,\n",
    "    \"learning_rate\": 0.0001,  # From shell script\n",
    "    \"des\": \"Exp\",\n",
    "    \"loss\": \"MSE\",\n",
    "    \"lradj\": \"COS\",\n",
    "    \"pct_start\": 0.2,\n",
    "    \"use_amp\": False,\n",
    "    \"llm_layers\": 32,  # From shell script (llama_layers)\n",
    "    \"percent\": 100,\n",
    "    \"num_individuals\": 100,  # From shell script\n",
    "    \"enable_covariates\": 1,  # From shell script\n",
    "    \"cov_type\": \"tensor\",\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"use_deep_speed\": 1,  # From shell script\n",
    "    \n",
    "    # Wandb\n",
    "    \"wandb\": 1,\n",
    "    \"wandb_group\": None,\n",
    "    \"wandb_api_key\": \"6f1080f993d5d7ad6103e69ef57dd9291f1bf366\",\n",
    "    \n",
    "    # MoE parameters (from shell script)\n",
    "    \"use_moe\": 1,\n",
    "    \"num_experts\": 8,\n",
    "    \"top_k_experts\": 4,\n",
    "    \"moe_layer_indices\": [0, 1],\n",
    "    \"moe_loss_weight\": 0.01,\n",
    "    \"log_routing_stats\": 1,\n",
    "    \"num_universal_experts\": 1,\n",
    "    \"universal_expert_weight\": 0.3,\n",
    "    \"head_dropout\": 0.1,\n",
    "    \n",
    "    # TimeMixer-specific parameters\n",
    "    \"channel_independence\": 0,\n",
    "    \"decomp_method\": \"moving_avg\",\n",
    "    \"use_norm\": 1,\n",
    "    \"down_sampling_layers\": 2,\n",
    "    \"down_sampling_window\": 1,\n",
    "    \"down_sampling_method\": \"avg\",\n",
    "    \"use_future_temporal_feature\": 0,\n",
    "    \n",
    "    # Flow matching specific parameters\n",
    "    \"k_z\": 1e-2,\n",
    "    \"k_cond\": 1,\n",
    "    \"d_z\": 8,\n",
    "    \n",
    "    # De-stationary projector params\n",
    "    \"p_hidden_dims\": [64, 64],\n",
    "    \"p_hidden_layers\": 2,\n",
    "    \n",
    "    # Flow matching config\n",
    "    \"diffusion_config_dir\": \"/home/yl2428/Time-LLM/models/model9_NS_transformer/configs/toy_8gauss.yml\",\n",
    "    \"cond_pred_model_pertrain_dir\": None,\n",
    "    \"CART_input_x_embed_dim\": 32,\n",
    "    \"mse_timestep\": 0,\n",
    "    \"MLP_diffusion_net\": False,\n",
    "    \n",
    "    # Flow matching specific timesteps (reduced from 1000 for efficiency)\n",
    "    \"timesteps\": 50,\n",
    "    \n",
    "    # Flow matching ODE solver parameters\n",
    "    \"ode_solver\": \"dopri5\",\n",
    "    \"ode_rtol\": 1e-5,\n",
    "    \"ode_atol\": 1e-5,\n",
    "    \"interpolation_type\": \"linear\",\n",
    "})\n",
    "\n",
    "def find_best_checkpoint(base_path=\"/home/yl2428/logs/ns_DLinear/flow_matching\", metric=\"val_loss\"):\n",
    "    \"\"\"\n",
    "    Find the best checkpoint based on validation loss.\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base directory to search for checkpoints\n",
    "        metric: Metric to optimize (default: val_loss, lower is better)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (best_checkpoint_path, best_metric_value, run_name)\n",
    "    \"\"\"\n",
    "    print(f\"Searching for checkpoints in: {base_path}\")\n",
    "    \n",
    "    # Find all checkpoint directories\n",
    "    checkpoint_pattern = os.path.join(base_path, \"*/checkpoints/epoch=*-step=*-val_loss=*.ckpt/checkpoint\")\n",
    "    checkpoint_dirs = glob.glob(checkpoint_pattern)\n",
    "    \n",
    "    if not checkpoint_dirs:\n",
    "        print(\"No checkpoints found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    best_checkpoint = None\n",
    "    best_metric = float('inf')  # Assuming lower is better for val_loss\n",
    "    best_run = None\n",
    "    \n",
    "    print(f\"Found {len(checkpoint_dirs)} checkpoints:\")\n",
    "    \n",
    "    for checkpoint_dir in checkpoint_dirs:\n",
    "        # Extract metric value from path\n",
    "        # Pattern: epoch=X-step=Y-val_loss=Z.ckpt\n",
    "        pattern = r'epoch=(\\d+)-step=(\\d+)-val_loss=([\\d.]+)\\.ckpt'\n",
    "        match = re.search(pattern, checkpoint_dir)\n",
    "        \n",
    "        if match:\n",
    "            epoch, step, val_loss = match.groups()\n",
    "            val_loss = float(val_loss)\n",
    "            \n",
    "            # Extract run name\n",
    "            run_name = checkpoint_dir.split('/')[-4]  # Get run directory name\n",
    "            \n",
    "            print(f\"  - {run_name}: epoch={epoch}, step={step}, val_loss={val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_metric:\n",
    "                best_metric = val_loss\n",
    "                best_checkpoint = checkpoint_dir\n",
    "                best_run = run_name\n",
    "    \n",
    "    if best_checkpoint:\n",
    "        print(f\"\\nBest checkpoint: {best_run}\")\n",
    "        print(f\"  - Path: {best_checkpoint}\")\n",
    "        print(f\"  - Val Loss: {best_metric:.4f}\")\n",
    "    \n",
    "    return best_checkpoint, best_metric, best_run\n",
    "\n",
    "def load_deepspeed_checkpoint(model, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load DeepSpeed checkpoint into the model.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch Lightning model\n",
    "        checkpoint_path: Path to the DeepSpeed checkpoint directory\n",
    "    \n",
    "    Returns:\n",
    "        model: Model with loaded weights\n",
    "    \"\"\"\n",
    "    print(f\"Loading DeepSpeed checkpoint from: {checkpoint_path}\")\n",
    "    \n",
    "    # DeepSpeed saves model states in mp_rank_00_model_states.pt\n",
    "    model_states_path = os.path.join(checkpoint_path, \"mp_rank_00_model_states.pt\")\n",
    "    \n",
    "    if not os.path.exists(model_states_path):\n",
    "        raise FileNotFoundError(f\"Model states file not found: {model_states_path}\")\n",
    "    \n",
    "    print(f\"Loading model states from: {model_states_path}\")\n",
    "    \n",
    "    # Determine the device to use\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(model_states_path, map_location=device)\n",
    "    \n",
    "    # Extract the model state dict\n",
    "    if 'module' in checkpoint:\n",
    "        state_dict = checkpoint['module']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        # Sometimes the checkpoint is the state dict directly\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Remove any DeepSpeed prefixes if they exist\n",
    "    cleaned_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        # Remove common prefixes that DeepSpeed might add\n",
    "        clean_key = key\n",
    "        if key.startswith('_forward_module.'):\n",
    "            clean_key = key.replace('_forward_module.', '')\n",
    "        elif key.startswith('module.'):\n",
    "            clean_key = key.replace('module.', '')\n",
    "        \n",
    "        # Ensure the tensor is on the correct device\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.to(device)\n",
    "        \n",
    "        cleaned_state_dict[clean_key] = value\n",
    "    \n",
    "    # Load the state dict into the model\n",
    "    try:\n",
    "        # First move the model to the device\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Load the state dict\n",
    "        missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)\n",
    "        \n",
    "        if missing_keys:\n",
    "            print(f\"Missing keys: {missing_keys[:10]}{'...' if len(missing_keys) > 10 else ''}\")\n",
    "        if unexpected_keys:\n",
    "            print(f\"Unexpected keys: {unexpected_keys[:10]}{'...' if len(unexpected_keys) > 10 else ''}\")\n",
    "            \n",
    "        print(\"‚úì Model weights loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Some keys couldn't be loaded: {e}\")\n",
    "        # Try to load what we can\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in cleaned_state_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        \n",
    "        # Move model to device first\n",
    "        model = model.to(device)\n",
    "        model.load_state_dict(model_dict)\n",
    "        print(f\"‚úì Loaded {len(pretrained_dict)}/{len(cleaned_state_dict)} parameters\")\n",
    "    \n",
    "    # Ensure all submodules are on the correct device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Special handling for torch_frame components that might have device issues\n",
    "    def move_torch_frame_components_to_device(module, device):\n",
    "        \"\"\"Recursively move torch_frame components to device\"\"\"\n",
    "        for name, child in module.named_children():\n",
    "            if hasattr(child, 'fill_values') and isinstance(child.fill_values, torch.Tensor):\n",
    "                child.fill_values = child.fill_values.to(device)\n",
    "            if hasattr(child, 'embedding_table') and isinstance(child.embedding_table, torch.Tensor):\n",
    "                child.embedding_table = child.embedding_table.to(device)\n",
    "            # Recursively apply to children\n",
    "            move_torch_frame_components_to_device(child, device)\n",
    "    \n",
    "    # Apply device fix to the model\n",
    "    move_torch_frame_components_to_device(model, device)\n",
    "    \n",
    "    print(f\"‚úì All model components moved to {device}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def move_batch_to_device(batch, device):\n",
    "    \"\"\"\n",
    "    Move a batch of data to the specified device.\n",
    "    \n",
    "    Args:\n",
    "        batch: Batch data (can be tuple, list, tensor, or TensorFrame)\n",
    "        device: Target device\n",
    "    \n",
    "    Returns:\n",
    "        batch: Batch moved to device\n",
    "    \"\"\"\n",
    "    if isinstance(batch, (list, tuple)):\n",
    "        return type(batch)(move_batch_to_device(item, device) for item in batch)\n",
    "    elif isinstance(batch, torch.Tensor):\n",
    "        return batch.to(device)\n",
    "    elif hasattr(batch, 'to'):  # For TensorFrame and similar objects\n",
    "        return batch.to(device)\n",
    "    else:\n",
    "        return batch\n",
    "\n",
    "def load_flow_matching_model_with_weights(checkpoint_path=None, auto_find_best=True):\n",
    "    \"\"\"\n",
    "    Load and initialize the flow matching model with the specified configuration and weights.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Specific path to checkpoint directory (optional)\n",
    "        auto_find_best: If True, automatically find the best checkpoint (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, args, loaders, checkpoint_info)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data with flow matching config\n",
    "    flow_args = flow_matching_config\n",
    "    print(\"Loading data for Flow Matching model...\")\n",
    "    \n",
    "    train_data_fm, train_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'train'\n",
    "    )\n",
    "    vali_data_fm, vali_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'val'\n",
    "    )\n",
    "    test_data_fm, test_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, False, 'test'\n",
    "    )\n",
    "    \n",
    "    # Initialize Flow Matching model\n",
    "    print(\"Initializing Time Series Flow Matching Model...\")\n",
    "    flow_matching_model = TimeSeriesFlowMatchingModel(flow_args, train_loader_fm, vali_loader_fm, test_loader_fm)\n",
    "    \n",
    "    checkpoint_info = {}\n",
    "    \n",
    "    # Load weights if specified\n",
    "    if checkpoint_path or auto_find_best:\n",
    "        if auto_find_best and not checkpoint_path:\n",
    "            print(\"\\nFinding best checkpoint...\")\n",
    "            checkpoint_path, best_metric, run_name = find_best_checkpoint()\n",
    "            checkpoint_info = {\n",
    "                'path': checkpoint_path,\n",
    "                'val_loss': best_metric,\n",
    "                'run_name': run_name\n",
    "            }\n",
    "        \n",
    "        if checkpoint_path:\n",
    "            print(f\"\\nLoading weights from checkpoint...\")\n",
    "            flow_matching_model = load_deepspeed_checkpoint(flow_matching_model, checkpoint_path)\n",
    "            if not checkpoint_info:\n",
    "                checkpoint_info = {'path': checkpoint_path}\n",
    "        else:\n",
    "            print(\"No checkpoint found to load.\")\n",
    "    \n",
    "    print(\"‚úì Flow Matching model loaded successfully!\")\n",
    "    print(f\"  - Model type: {flow_args.model}\")\n",
    "    print(f\"  - Generative model: {flow_args.generative_model}\")\n",
    "    print(f\"  - ODE Solver: {flow_args.ode_solver}\")\n",
    "    print(f\"  - Timesteps: {flow_args.timesteps}\")\n",
    "    print(f\"  - Batch size: {flow_args.batch_size}\")\n",
    "    print(f\"  - Learning rate: {flow_args.learning_rate}\")\n",
    "    print(f\"  - MoE enabled: {flow_args.use_moe}\")\n",
    "    print(f\"  - Covariates enabled: {flow_args.enable_covariates}\")\n",
    "    print(f\"  - Model dimensions: d_model={flow_args.d_model}, d_ff={flow_args.d_ff}\")\n",
    "    print(f\"  - Sequence lengths: seq_len={flow_args.seq_len}, pred_len={flow_args.pred_len}\")\n",
    "    \n",
    "    if checkpoint_info:\n",
    "        print(f\"\\nCheckpoint info:\")\n",
    "        if 'run_name' in checkpoint_info:\n",
    "            print(f\"  - Run: {checkpoint_info['run_name']}\")\n",
    "        if 'val_loss' in checkpoint_info:\n",
    "            print(f\"  - Validation Loss: {checkpoint_info['val_loss']:.4f}\")\n",
    "        print(f\"  - Path: {checkpoint_info['path']}\")\n",
    "    \n",
    "    print(f\"\\nüìù Usage Tips:\")\n",
    "    print(f\"  - Use model.eval() before inference\")\n",
    "    print(f\"  - Move data to device: batch = move_batch_to_device(batch, model.device)\")\n",
    "    print(f\"  - For sampling: model.sample_step(batch, batch_idx)\")\n",
    "    \n",
    "    return flow_matching_model, flow_args, (train_loader_fm, vali_loader_fm, test_loader_fm), checkpoint_info\n",
    "\n",
    "def load_flow_matching_model():\n",
    "    \"\"\"Load and initialize the flow matching model with the specified configuration (without weights).\"\"\"\n",
    "    \n",
    "    # Load data with flow matching config\n",
    "    flow_args = flow_matching_config\n",
    "    print(\"Loading data for Flow Matching model...\")\n",
    "    \n",
    "    train_data_fm, train_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'train'\n",
    "    )\n",
    "    vali_data_fm, vali_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'val'\n",
    "    )\n",
    "    test_data_fm, test_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, False, 'test'\n",
    "    )\n",
    "    \n",
    "    # Initialize Flow Matching model\n",
    "    print(\"Initializing Time Series Flow Matching Model...\")\n",
    "    flow_matching_model = TimeSeriesFlowMatchingModel(flow_args, train_loader_fm, vali_loader_fm, test_loader_fm)\n",
    "    \n",
    "    print(\"‚úì Flow Matching model loaded successfully!\")\n",
    "    print(f\"  - Model type: {flow_args.model}\")\n",
    "    print(f\"  - Generative model: {flow_args.generative_model}\")\n",
    "    print(f\"  - ODE Solver: {flow_args.ode_solver}\")\n",
    "    print(f\"  - Timesteps: {flow_args.timesteps}\")\n",
    "    print(f\"  - Batch size: {flow_args.batch_size}\")\n",
    "    print(f\"  - Learning rate: {flow_args.learning_rate}\")\n",
    "    print(f\"  - MoE enabled: {flow_args.use_moe}\")\n",
    "    print(f\"  - Covariates enabled: {flow_args.enable_covariates}\")\n",
    "    print(f\"  - Model dimensions: d_model={flow_args.d_model}, d_ff={flow_args.d_ff}\")\n",
    "    print(f\"  - Sequence lengths: seq_len={flow_args.seq_len}, pred_len={flow_args.pred_len}\")\n",
    "    \n",
    "    return flow_matching_model, flow_args, (train_loader_fm, vali_loader_fm, test_loader_fm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, args, loaders, checkpoint_info = load_flow_matching_model_with_weights(checkpoint_path=\"/home/yl2428/logs/ns_DLinear/flow_matching/fine-sponge-387/checkpoints/epoch=9-step=23070-val_loss=1.8386.ckpt/checkpoint\")\n",
    "train_loader, val_loader, test_loader = loaders\n",
    "\n",
    "print(\"\\nModel summary:\")\n",
    "print(f\"Flow matching model has {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(f\"Condition prediction model has {sum(p.numel() for p in model.cond_pred_model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='cuda',\n",
    "    devices=1, precision='64')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/checkpoints_1.pt')\n",
    "# turn into double\n",
    "for key in state_dict.keys():\n",
    "    state_dict[key] = state_dict[key].double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"ns_Transformer\", name=\"test\")\n",
    "trainer.test(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_outputs[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_outputs[0]['batch_x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.sample_outputs, '/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/sample_outputs_May11.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_outputs = torch.load('/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/sample_outputs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import stype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = model.sample_outputs[0]['batch']\n",
    "batch_x, batch_y, batch_x_mark, batch_y_mark = batch[0]\n",
    "batch_cov = batch[1]\n",
    "with torch.no_grad():\n",
    "    new_batch_x = batch_x.clone()\n",
    "    new_batch_x[53, :, 1] = batch_x[53, :, 1].min()\n",
    "    model.eval()\n",
    "    new_batch = [None, None]\n",
    "    new_batch[0] = new_batch_x, batch_y, batch_x_mark, batch_y_mark\n",
    "    new_batch[1] = batch_cov\n",
    "    model.sample_step(new_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.sample_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def plot_time_series_with_ci(groundtruth, sampled_output, cov, batch_x=None, num_series=5):\n",
    "    fig, axes = plt.subplots(num_series, 1, figsize=(12, 6*num_series), sharex=True)\n",
    "    if num_series == 1:\n",
    "        axes = [axes]\n",
    "    idx_list = [53, 11, 19]  # Adjust or randomize this list as needed\n",
    "    for i in range(num_series):\n",
    "        # Randomly select a time series from the batch\n",
    "        idx = idx_list[i]\n",
    "        hba1c = cov.feat_dict[stype.numerical][idx, 3]\n",
    "        diabetes_onset = cov.feat_dict[stype.numerical][idx, 1]\n",
    "        weight = cov.feat_dict[stype.numerical][idx, 4]\n",
    "        \n",
    "        if batch_x is not None:\n",
    "            # Extract previous glucose values\n",
    "            previous_glucose = batch_x[idx, :, -1].cpu().numpy()\n",
    "            hr = batch_x[idx, :, 0] * 20.41707644 + 7.93461185e+01\n",
    "            steps = batch_x[idx, :, 1] * 20.84327263 +  6.53019535e+00\n",
    "            print(steps)\n",
    "            hr_mean = np.mean(hr.cpu().numpy())\n",
    "            steps_mean = np.sum(steps.cpu().numpy())\n",
    "            \n",
    "            # Concatenate previous glucose with groundtruth and mean predictions\n",
    "            full_groundtruth = np.concatenate([previous_glucose, groundtruth[idx, :, -1]])\n",
    "        \n",
    "        else:\n",
    "            full_groundtruth = groundtruth[idx, :, -1].cpu().numpy()\n",
    "\n",
    "        # Plot ground truth (concatenated)\n",
    "        axes[i].plot(full_groundtruth, color='#1f77b4', label='Ground Truth (with previous)', lw=2)\n",
    "        \n",
    "        # Add textual information\n",
    "        axes[i].text(0, 2.8, f'idx: {idx}, hba1c: {hba1c.cpu().numpy():.2f}, diabetes_onset: {diabetes_onset.cpu().numpy():.2f}, weight: {weight.cpu().numpy():.2f}, steps: {steps_mean:.2f}', \n",
    "                     fontsize=12, color='black', bbox=dict(facecolor='white', alpha=0.5))\n",
    "        \n",
    "        # Calculate mean and confidence interval for predicted values\n",
    "        mean = np.mean(sampled_output[idx, :, :, 0], axis=0)\n",
    "        ci_lower = np.percentile(sampled_output[idx, :, :, 0], 80, axis=0)\n",
    "        ci_upper = np.percentile(sampled_output[idx, :, :, 0], 20, axis=0)\n",
    "        \n",
    "        # Smooth the CI with a moving average\n",
    "        ci_lower_smooth = uniform_filter1d(ci_lower, size=5)\n",
    "        ci_upper_smooth = uniform_filter1d(ci_upper, size=5)\n",
    "        \n",
    "        # Concatenate previous glucose with predicted mean and CI\n",
    "        full_mean = np.concatenate([previous_glucose, mean])\n",
    "        full_ci_lower = np.concatenate([previous_glucose, ci_lower_smooth])\n",
    "        full_ci_upper = np.concatenate([previous_glucose, ci_upper_smooth])\n",
    "        \n",
    "        # Plot mean prediction (concatenated)\n",
    "        axes[i].plot(full_mean, color='#ff7f0e', label='Mean Prediction (with previous)', lw=2)\n",
    "        \n",
    "        # Plot confidence interval (concatenated)\n",
    "        axes[i].fill_between(range(full_mean.shape[0]), full_ci_lower, full_ci_upper, color='#ff7f0e', alpha=0.3, label='95% CI')\n",
    "        \n",
    "        axes[i].set_title(f'Time Series {i+1}', fontsize=14)\n",
    "        axes[i].set_xlabel('Time Step', fontsize=12)\n",
    "        axes[i].set_ylabel('Value', fontsize=12)\n",
    "        \n",
    "        # Set y limit to be the same for all plots\n",
    "        axes[i].set_ylim([-3, 3])\n",
    "        axes[i].legend(loc='upper right', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.savefig('time_series_with_ci.pdf')\n",
    "    plt.show()\n",
    "\n",
    "# Sample invocation of the function with your data\n",
    "# plot_time_series_with_ci(groundtruth, sampled_output, cov, num_series=5)\n",
    "\n",
    "j = 0\n",
    "groundtruth_to_plot = model.sample_outputs[j]['true']\n",
    "sampled_output_to_plot = model.sample_outputs[j]['pred']\n",
    "cov_to_plot = model.sample_outputs[j]['batch_cov']\n",
    "batch_x_to_plot = model.sample_outputs[j]['batch_x']\n",
    "# Call the function to plot 2 random time series\n",
    "plot_time_series_with_ci(groundtruth_to_plot, sampled_output_to_plot, cov_to_plot, batch_x_to_plot, num_series=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_frame import stype # Ensure this is consistent with how stype is used/imported earlier\n",
    "\n",
    "# Ensure 'model' is loaded and model.sample_outputs is populated from previous cells.\n",
    "# For example, if needed:\n",
    "# model.sample_outputs = torch.load('/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/sample_outputs.pt')\n",
    "\n",
    "def perturb_hba1c_covariates(batch_cov, individual_indices, percentage_increase):\n",
    "    \"\"\"\n",
    "    Perturbs HBA1c for specified individuals in the batch_cov.\n",
    "    HBA1c is assumed to be at index 3 of the numerical features based on notebook analysis.\n",
    "    Input batch_cov is expected to be a torch_frame.MaterializedFrame object or similar.\n",
    "    Returns a new batch_cov object with perturbations; does not modify the input object.\n",
    "    \"\"\"\n",
    "    if stype.numerical not in batch_cov.feat_dict:\n",
    "        print(f\"Warning: stype.numerical ('{stype.numerical}') not found in batch_cov.feat_dict. Returning original batch_cov.\")\n",
    "        return batch_cov\n",
    "\n",
    "    # Clone the numerical features tensor to ensure modifications do not affect the original batch_cov\n",
    "    original_numerical_tensor = batch_cov.feat_dict[stype.numerical]\n",
    "    perturbed_numerical_tensor = original_numerical_tensor.clone()\n",
    "    \n",
    "    for idx in individual_indices:\n",
    "        if 0 <= idx < perturbed_numerical_tensor.shape[0]:\n",
    "            # Modify the cloned tensor\n",
    "            current_hba1c_val = perturbed_numerical_tensor[idx, 3]\n",
    "            perturbed_numerical_tensor[idx, 3] = current_hba1c_val * (1 + percentage_increase / 100.0)\n",
    "            # print(f\"Individual {idx}: HbA1c changed from {current_hba1c_val.item():.2f} to {perturbed_numerical_tensor[idx, 3].item():.2f}\")\n",
    "        else:\n",
    "            print(f\"Warning: Index {idx} is out of bounds for numerical_feats (shape: {perturbed_numerical_tensor.shape}). Skipping perturbation for this index.\")\n",
    "            \n",
    "    from copy import deepcopy\n",
    "    new_feat_dict = deepcopy(batch_cov) \n",
    "    # \n",
    "    new_feat_dict.feat_dict[stype.numerical] = perturbed_numerical_tensor\n",
    "    \n",
    "    # Prepare arguments for constructing the new frame object.\n",
    "    # It's important to pass all necessary attributes from the original batch_cov\n",
    "    # that are required by its constructor (e.g., col_names_dict, col_stats).\n",
    "    \n",
    "    return new_feat_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Perturbation Analysis ---\n",
    "# Select a batch for analysis (e.g., the last one processed or a specific one)\n",
    "# If model.sample_outputs is a list of outputs from trainer.test:\n",
    "# Each element in model.sample_outputs would typically be a dictionary\n",
    "# from a single batch processed by test_step.\n",
    "# We'll use the last batch's data as an example.\n",
    "# You might need to adjust which batch or how data is selected based on your exact structure.\n",
    "\n",
    "if not model.sample_outputs:\n",
    "    print(\"Error: model.sample_outputs is empty. Please ensure the model has processed data and populated this list.\")\n",
    "else:\n",
    "    # Assuming the structure seen in the notebook: model.sample_outputs[i]['batch']\n",
    "    # and model.sample_outputs[i]['pred'] for predictions.\n",
    "    # We need an original batch to get 'batch_x', 'batch_y', 'batch_x_mark', 'batch_y_mark', and 'batch_cov'.\n",
    "    \n",
    "    # Let's use the data from the last entry in sample_outputs for perturbation\n",
    "    # This corresponds to the data used for the last plot in the notebook (j = -1)\n",
    "    # Or you can select a specific batch index, e.g., batch_index_to_perturb = 0\n",
    "    batch_index_to_perturb = -1 # Use the last batch by default\n",
    "    \n",
    "    original_batch_data_dict = model.sample_outputs[batch_index_to_perturb]\n",
    "    original_batch_tuple = original_batch_data_dict['batch'] # This is [ (batch_x, batch_y, batch_x_mark, batch_y_mark), batch_cov ]\n",
    "    \n",
    "    batch_x_orig, batch_y_orig, batch_x_mark_orig, batch_y_mark_orig = original_batch_tuple[0]\n",
    "    batch_cov_orig = original_batch_tuple[1]\n",
    "\n",
    "    # Get original predictions (samples before perturbation)\n",
    "    # These are the 'pred' values from the model's output for this original batch\n",
    "    # Assuming 'pred' stores the 50 samples: [batch_size, num_samples, pred_len, num_features]\n",
    "    # And we are interested in the glucose feature, which is the last one (index -1 or 3 for c_out=4)\n",
    "    sampled_output_before_perturb = original_batch_data_dict['pred'][..., -1] # Taking only glucose\n",
    "\n",
    "    num_individuals_in_batch = batch_x_orig.shape[0]\n",
    "    num_to_perturb = min(10, num_individuals_in_batch) # Perturb up to 3 individuals, or fewer if batch is small\n",
    "\n",
    "    # Randomly select individuals to perturb\n",
    "    # Ensure reproducibility if desired, by setting random.seed elsewhere or here for this specific selection\n",
    "    # random.seed(42) # for reproducibility of selection\n",
    "    individuals_to_perturb_indices = random.sample(range(num_individuals_in_batch), num_to_perturb)\n",
    "    print(f\"Original batch size: {num_individuals_in_batch}\")\n",
    "    print(f\"Randomly selected individuals to perturb (indices): {individuals_to_perturb_indices}\")\n",
    "\n",
    "    # Perturb HBA1c for the selected individuals\n",
    "    percentage_increase_hba1c = 200.0\n",
    "    batch_cov_perturbed = perturb_hba1c_covariates(batch_cov_orig, individuals_to_perturb_indices, percentage_increase_hba1c)\n",
    "\n",
    "    # Prepare the new batch for the model's sample_step or equivalent generation function\n",
    "    # The model.sample_step(batch, batch_idx) was used in the notebook\n",
    "    # We need to simulate how samples are generated or find the appropriate generation function.\n",
    "    # If model.sample_step appends to model.sample_outputs, we need to handle that.\n",
    "    # For now, let's assume we need to call a generation function.\n",
    "    # The `sample_step` in TimeSeriesDiffusionModel takes `batch` and `batch_idx`\n",
    "    # and seems to append to `self.sample_outputs`.\n",
    "    # To get samples for the perturbed data without altering `model.sample_outputs` from original runs,\n",
    "    # we might need to call a more direct sampling/prediction method of the model if available,\n",
    "    # or temporarily store and then restore `model.sample_outputs`.\n",
    "\n",
    "    # Let's try to get new samples.\n",
    "    # The model's `predict_step` or a similar generation function is needed.\n",
    "    # In TimeSeriesDiffusionModel, `sample_step` is used during `test_step` and it appends to `self.sample_outputs`.\n",
    "    # A more direct way to get samples would be to call `model.model.sample()` (for the inner diffusion model)\n",
    "    # or `model.cond_pred_model.predict()` if it's about conditional prediction.\n",
    "    # Given the existing notebook structure, `model.sample_step` is what was used to generate `model.sample_outputs`.\n",
    "\n",
    "    # To avoid confusion with previously stored sample_outputs, we will call a direct sampling method\n",
    "    # of the underlying diffusion model if possible.\n",
    "    # The TimeSeriesDiffusionModel has a `sample` method.\n",
    "    # Signature: sample(self, batch_x, batch_x_mark, batch_y_mark, N=50, cond_scale=0.)\n",
    "    \n",
    "    # We need to get cond from batch_cov_perturbed\n",
    "    # The model has `self.cond_pred_model.encode_cond(batch_cov)`\n",
    "    # And then uses this `cond` in its own `sample` method, which calls `self.model.sample`.\n",
    "    \n",
    "    model.eval() # Ensure model is in eval mode\n",
    "    with torch.no_grad():\n",
    "        # 1. Encode covariates to get the condition\n",
    "        # The `encode_cond` method might need the batch_cov on the correct device\n",
    "        device = batch_x_orig.device # Assuming batch_x_orig is already on the correct device\n",
    "        \n",
    "        # The covariates in batch_cov_perturbed need to be on the same device as the model\n",
    "        # Typically, the data loader handles this. Here we do it manually if needed.\n",
    "        # Assuming batch_cov_perturbed.feat_dict[stype.numerical] is a tensor.\n",
    "        \n",
    "        # Create a new batch structure for the perturbed data\n",
    "        perturbed_batch_for_sampling = [\n",
    "            (batch_x_orig.to(device), batch_y_orig.to(device), batch_x_mark_orig.to(device), batch_y_mark_orig.to(device)), # Original x, y, x_mark, y_mark\n",
    "            batch_cov_perturbed # Perturbed covariates\n",
    "        ]\n",
    "\n",
    "        model.sample_step(perturbed_batch_for_sampling , 0)\n",
    "    \n",
    "    sampled_output_after_perturb = model.sample_outputs[-1]['pred']\n",
    "\n",
    "    print(f\"Shape of original sampled output (glucose only): {sampled_output_before_perturb.shape}\")\n",
    "    print(f\"Shape of perturbed sampled output (glucose only): {sampled_output_after_perturb.shape}\")\n",
    "\n",
    "    # Store HBA1c values for individuals of interest for plotting/stats\n",
    "    original_hba1c_values = {}\n",
    "    perturbed_hba1c_values = {}\n",
    "\n",
    "    for i_idx in individuals_to_perturb_indices:\n",
    "        original_hba1c_values[i_idx] = batch_cov_orig.feat_dict[stype.numerical][i_idx, 3].item()\n",
    "        perturbed_hba1c_values[i_idx] = batch_cov_perturbed.feat_dict[stype.numerical][i_idx, 3].item()\n",
    "        print(f\"Individual {i_idx}: Original HbA1c: {original_hba1c_values[i_idx]:.2f}, Perturbed HbA1c: {perturbed_hba1c_values[i_idx]:.2f}\")\n",
    "\n",
    "# Ground truth for plotting (from the original selected batch)\n",
    "groundtruth_for_plot = original_batch_data_dict['true'][..., -1]\n",
    "batch_x_for_plot = original_batch_data_dict['batch_x'][..., -1]\n",
    "sampled_output_after_perturb = model.sample_outputs[-1]['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if not model.sample_outputs or 'individuals_to_perturb_indices' not in locals():\n",
    "    print(\"Error: Ensure the perturbation analysis cell has been run and required variables are available.\")\n",
    "else:\n",
    "    # Assuming c_out was 1 or f_dim correctly selected the single glucose feature for pred_len output\n",
    "    # sampled_output_before_perturb shape: (batch_size, num_samples, pred_len)\n",
    "    # sampled_output_after_perturb shape: (batch_size, num_samples, pred_len, 1) from notebook output\n",
    "    # groundtruth_for_plot shape: (batch_size, pred_len)\n",
    "    # batch_x_for_plot shape: (batch_size, seq_len)\n",
    "    \n",
    "    seq_len = batch_x_for_plot.shape[1]\n",
    "    pred_len = groundtruth_for_plot.shape[1]\n",
    "    time_history = np.arange(seq_len)\n",
    "    time_pred = np.arange(seq_len, seq_len + pred_len)\n",
    "    \n",
    "    for idx in individuals_to_perturb_indices:\n",
    "        history_data = batch_x_for_plot[idx].cpu().numpy()\n",
    "        true_future_data = groundtruth_for_plot[idx]\n",
    "        \n",
    "        # Predictions before perturbation\n",
    "        preds_before_raw = sampled_output_before_perturb[idx] # (num_samples, pred_len)\n",
    "        mean_preds_before = np.mean(preds_before_raw, axis=0)\n",
    "        std_preds_before = np.std(preds_before_raw, axis=0)\n",
    "        \n",
    "        # Predictions after perturbation\n",
    "        # sampled_output_after_perturb has shape (batch_size, num_samples, pred_len, 1)\n",
    "        preds_after_raw = sampled_output_after_perturb[idx, ..., 0] # (num_samples, pred_len)\n",
    "        mean_preds_after = np.mean(preds_after_raw, axis=0)\n",
    "        std_preds_after = np.std(preds_after_raw, axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        \n",
    "        # Plot history\n",
    "        plt.plot(time_history, history_data, label='Input History (Glucose)', color='black', linewidth=1.5)\n",
    "        \n",
    "        # Plot true future\n",
    "        plt.plot(time_pred, true_future_data, label='Ground Truth Future (Glucose)', color='green', linestyle='--', linewidth=2)\n",
    "        \n",
    "        # Plot predictions before perturbation\n",
    "        plt.plot(time_pred, mean_preds_before, \n",
    "                 label=f'Mean Pred (Before Perturb, Orig HbA1c: {original_hba1c_values[idx]:.2f})', \n",
    "                 color='blue', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_before - std_preds_before, mean_preds_before + std_preds_before, \n",
    "                         color='blue', alpha=0.2, label='Std Dev (Before)')\n",
    "        \n",
    "        # Plot predictions after perturbation\n",
    "        plt.plot(time_pred, mean_preds_after, \n",
    "                 label=f'Mean Pred (After Perturb, New HbA1c: {perturbed_hba1c_values[idx]:.2f})', \n",
    "                 color='red', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_after - std_preds_after, mean_preds_after + std_preds_after, \n",
    "                         color='red', alpha=0.2, label='Std Dev (After)')\n",
    "        \n",
    "        plt.title(f'Glucose Prediction Perturbation Analysis for Individual {idx}', fontsize=16)\n",
    "        plt.xlabel('Time Steps', fontsize=14)\n",
    "        plt.ylabel('Glucose Value', fontsize=14)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if 'individuals_to_perturb_indices' not in locals() or \\\n",
    "   'sampled_output_before_perturb' not in locals() or \\\n",
    "   'sampled_output_after_perturb' not in locals():\n",
    "    print(\"Error: Ensure the perturbation analysis and plotting cells have been run, and variables are available.\")\n",
    "else:\n",
    "    print(\"\\n--- Comparison of Average Standard Deviations (Time-Averaged) ---\\n\")\n",
    "    avg_std_devs_before_list = []\n",
    "    avg_std_devs_after_list = []\n",
    "\n",
    "    for idx in individuals_to_perturb_indices:\n",
    "        # Predictions before perturbation: shape (num_samples, pred_len)\"\n",
    "        preds_before_raw = sampled_output_before_perturb[idx]\n",
    "        # Std dev across samples for each time step: shape (pred_len,)\"\n",
    "        std_dev_over_samples_before = np.std(preds_before_raw, axis=0)\n",
    "        # Average this std dev over the prediction length\"\n",
    "        avg_std_before = np.mean(std_dev_over_samples_before)\n",
    "        avg_std_devs_before_list.append(avg_std_before)\n",
    "\n",
    "        # Predictions after perturbation: shape (num_samples, pred_len) after [..., 0] slicing\"\n",
    "        preds_after_raw = sampled_output_after_perturb[idx, ..., 0]\n",
    "        # Std dev across samples for each time step: shape (pred_len,)\"\n",
    "        std_dev_over_samples_after = np.std(preds_after_raw, axis=0)\n",
    "        # Average this std dev over the prediction length\"\n",
    "        avg_std_after = np.mean(std_dev_over_samples_after)\n",
    "        avg_std_devs_after_list.append(avg_std_after)\n",
    "\n",
    "        print(f\"Individual {idx}:\")\n",
    "        print(f\"  Avg. Std. Dev (Before Perturbation): {avg_std_before:.4f}\")\n",
    "        print(f\"  Avg. Std. Dev (After Perturbation):  {avg_std_after:.4f}\")\n",
    "        if avg_std_after > avg_std_before:\n",
    "            print(f\"  Comparison: Uncertainty (std dev) INCREASED by {avg_std_after - avg_std_before:.4f} after perturbation.\")\n",
    "        elif avg_std_after < avg_std_before:\n",
    "            print(f\"  Comparison: Uncertainty (std dev) DECREASED by {avg_std_before - avg_std_after:.4f} after perturbation.\")\n",
    "        else:\n",
    "            print(f\"  Comparison: Uncertainty (std dev) remained the same after perturbation.\")\n",
    "        print(\"-----\")\n",
    "\n",
    "    # Overall average if desired\n",
    "    if avg_std_devs_before_list and avg_std_devs_after_list:\n",
    "        overall_avg_std_before = np.mean(avg_std_devs_before_list)\n",
    "        overall_avg_std_after = np.mean(avg_std_devs_after_list)\n",
    "        print(\"\\nOverall Average Across Perturbed Individuals:\")\n",
    "        print(f\"  Overall Avg. Std. Dev (Before): {overall_avg_std_before:.4f}\")\n",
    "        print(f\"  Overall Avg. Std. Dev (After):  {overall_avg_std_after:.4f}\")\n",
    "        if overall_avg_std_after > overall_avg_std_before:\n",
    "            print(f\"  Overall: Uncertainty INCREASED by {overall_avg_std_after - overall_avg_std_before:.4f}\")\n",
    "        elif overall_avg_std_after < overall_avg_std_before:\n",
    "            print(f\"  Overall: Uncertainty DECREASED by {overall_avg_std_before - overall_avg_std_after:.4f}\")\n",
    "        else:\n",
    "            print(f\"  Overall: Uncertainty remained the same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_steps_batch_x(original_data_tuple, individual_indices, percentage_increase):\n",
    "    \"\"\"\n",
    "    Perturbs 'steps' for specified individuals in batch_x.\n",
    "    'steps' are derived from batch_x[:, :, STEPS_FEATURE_INDEX_IN_BATCH_X] using a specific formula.\n",
    "    This function assumes batch_x is the first element of original_data_tuple:\n",
    "    original_data_tuple = (batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "    Returns a new data_tuple with batch_x perturbed; does not modify the input tuple or its tensors.\n",
    "    \"\"\"\n",
    "    # Constants for step calculation, as provided\n",
    "    STEPS_SCALE = 20.84327263\n",
    "    STEPS_OFFSET = 6.53019535e+00\n",
    "    STEPS_FEATURE_INDEX_IN_BATCH_X = 1 # 0-indexed\n",
    "\n",
    "\n",
    "    original_batch_x = original_data_tuple[0]\n",
    "    perturbed_batch_x = original_batch_x.clone() # Ensure we don't modify the original tensor\n",
    "\n",
    "    for idx in individual_indices:\n",
    "        # Extract the scaled feature series for steps for the specific individual\n",
    "        scaled_steps_series = perturbed_batch_x[idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X]\n",
    "\n",
    "        # Calculate current \"true\" step values (element-wise for the series)\n",
    "        current_true_steps = scaled_steps_series * STEPS_SCALE + STEPS_OFFSET\n",
    "\n",
    "        # Perturb the \"true\" step values\n",
    "        perturbed_true_steps = current_true_steps * (1 + percentage_increase / 100.0)\n",
    "        # Convert perturbed \"true\" steps back to scaled values for storage in batch_x\n",
    "        new_scaled_steps_series = (perturbed_true_steps - STEPS_OFFSET) / STEPS_SCALE\n",
    "\n",
    "        # Update the cloned batch_x with the new scaled step series\n",
    "        perturbed_batch_x[idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X] = new_scaled_steps_series\n",
    "\n",
    "\n",
    "    # Reconstruct the data tuple with the perturbed batch_x\n",
    "    new_data_list = list(original_data_tuple)\n",
    "    new_data_list[0] = perturbed_batch_x\n",
    "    new_data_tuple = tuple(new_data_list)\n",
    "    \n",
    "    return new_data_tuple\n",
    "\n",
    "def perturb_steps_and_hr_batch_x(original_data_tuple, individual_indices, percentage_increase):\n",
    "    \"\"\"\n",
    "    Perturbs both steps AND heart rate together to maintain physiological correlation\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    STEPS_SCALE = 20.84327263\n",
    "    STEPS_OFFSET = 6.53019535e+00\n",
    "    STEPS_FEATURE_INDEX = 1\n",
    "    \n",
    "    HR_SCALE = 79.3461185\n",
    "    HR_OFFSET = 20.41707644  \n",
    "    HR_FEATURE_INDEX = 0\n",
    "    \n",
    "    original_batch_x = original_data_tuple[0]\n",
    "    perturbed_batch_x = original_batch_x.clone()\n",
    "\n",
    "    for idx in individual_indices:\n",
    "        # Perturb steps\n",
    "        scaled_steps = perturbed_batch_x[idx, :, STEPS_FEATURE_INDEX]\n",
    "        true_steps = scaled_steps * STEPS_SCALE + STEPS_OFFSET\n",
    "        perturbed_true_steps = true_steps * (1 + percentage_increase / 100.0)\n",
    "        new_scaled_steps = (perturbed_true_steps - STEPS_OFFSET) / STEPS_SCALE\n",
    "        perturbed_batch_x[idx, :, STEPS_FEATURE_INDEX] = new_scaled_steps\n",
    "        \n",
    "        # Perturb heart rate proportionally (maybe smaller increase, e.g., 50% of steps increase)\n",
    "        scaled_hr = perturbed_batch_x[idx, :, HR_FEATURE_INDEX]\n",
    "        true_hr = scaled_hr * HR_SCALE + HR_OFFSET\n",
    "        hr_percentage_increase = percentage_increase * 0.5  # Adjust this ratio as needed\n",
    "        perturbed_true_hr = true_hr * (1 + hr_percentage_increase / 100.0)\n",
    "        new_scaled_hr = (perturbed_true_hr - HR_OFFSET) / HR_SCALE\n",
    "        perturbed_batch_x[idx, :, HR_FEATURE_INDEX] = new_scaled_hr\n",
    "\n",
    "    # Reconstruct tuple\n",
    "    new_data_list = list(original_data_tuple)\n",
    "    new_data_list[0] = perturbed_batch_x\n",
    "    return tuple(new_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original batch size: 64\n",
      "Randomly selected individuals to perturb (indices): [15, 62, 17, 58, 52, 48, 27, 46, 0, 16, 18, 23, 13, 49, 33, 37, 12, 5, 38, 43, 32, 29, 6, 31, 45, 25, 41, 63, 20, 30, 2, 35, 3, 44, 61, 24, 26, 28, 11, 51, 34, 19, 42, 54, 22, 57, 8, 10, 50, 60, 36, 53, 7, 59, 4, 14, 21, 39, 40, 1, 56, 55, 9, 47]\n",
      "Individual 15: Original Steps: 3.80, Perturbed Steps: 5.70\n",
      "Individual 62: Original Steps: 0.93, Perturbed Steps: 1.40\n",
      "Individual 17: Original Steps: 2.97, Perturbed Steps: 4.45\n",
      "Individual 58: Original Steps: 2.26, Perturbed Steps: 3.39\n",
      "Individual 52: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 48: Original Steps: 6.48, Perturbed Steps: 9.72\n",
      "Individual 27: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 46: Original Steps: 2.83, Perturbed Steps: 4.25\n",
      "Individual 0: Original Steps: 1.62, Perturbed Steps: 2.43\n",
      "Individual 16: Original Steps: 0.26, Perturbed Steps: 0.39\n",
      "Individual 18: Original Steps: 3.86, Perturbed Steps: 5.79\n",
      "Individual 23: Original Steps: 3.94, Perturbed Steps: 5.90\n",
      "Individual 13: Original Steps: 0.29, Perturbed Steps: 0.44\n",
      "Individual 49: Original Steps: 4.43, Perturbed Steps: 6.65\n",
      "Individual 33: Original Steps: 9.89, Perturbed Steps: 14.83\n",
      "Individual 37: Original Steps: 3.03, Perturbed Steps: 4.54\n",
      "Individual 12: Original Steps: 1.24, Perturbed Steps: 1.86\n",
      "Individual 5: Original Steps: 0.95, Perturbed Steps: 1.42\n",
      "Individual 38: Original Steps: 11.81, Perturbed Steps: 17.72\n",
      "Individual 43: Original Steps: 2.66, Perturbed Steps: 4.00\n",
      "Individual 32: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 29: Original Steps: 5.28, Perturbed Steps: 7.92\n",
      "Individual 6: Original Steps: 16.99, Perturbed Steps: 25.49\n",
      "Individual 31: Original Steps: 3.01, Perturbed Steps: 4.51\n",
      "Individual 45: Original Steps: 7.72, Perturbed Steps: 11.58\n",
      "Individual 25: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 41: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 63: Original Steps: 18.25, Perturbed Steps: 27.37\n",
      "Individual 20: Original Steps: 1.63, Perturbed Steps: 2.45\n",
      "Individual 30: Original Steps: 4.30, Perturbed Steps: 6.45\n",
      "Individual 2: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 35: Original Steps: 6.92, Perturbed Steps: 10.38\n",
      "Individual 3: Original Steps: 0.21, Perturbed Steps: 0.31\n",
      "Individual 44: Original Steps: 13.34, Perturbed Steps: 20.01\n",
      "Individual 61: Original Steps: 3.53, Perturbed Steps: 5.29\n",
      "Individual 24: Original Steps: 8.16, Perturbed Steps: 12.23\n",
      "Individual 26: Original Steps: 2.59, Perturbed Steps: 3.88\n",
      "Individual 28: Original Steps: 20.47, Perturbed Steps: 30.70\n",
      "Individual 11: Original Steps: 4.01, Perturbed Steps: 6.01\n",
      "Individual 51: Original Steps: 0.48, Perturbed Steps: 0.73\n",
      "Individual 34: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 19: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 42: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 54: Original Steps: 10.93, Perturbed Steps: 16.39\n",
      "Individual 22: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 57: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 8: Original Steps: 3.88, Perturbed Steps: 5.83\n",
      "Individual 10: Original Steps: 4.50, Perturbed Steps: 6.75\n",
      "Individual 50: Original Steps: 43.46, Perturbed Steps: 65.20\n",
      "Individual 60: Original Steps: 4.26, Perturbed Steps: 6.39\n",
      "Individual 36: Original Steps: 2.17, Perturbed Steps: 3.26\n",
      "Individual 53: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 7: Original Steps: 9.64, Perturbed Steps: 14.46\n",
      "Individual 59: Original Steps: 0.98, Perturbed Steps: 1.46\n",
      "Individual 4: Original Steps: 7.43, Perturbed Steps: 11.15\n",
      "Individual 14: Original Steps: 2.05, Perturbed Steps: 3.08\n",
      "Individual 21: Original Steps: 2.39, Perturbed Steps: 3.58\n",
      "Individual 39: Original Steps: 4.36, Perturbed Steps: 6.54\n",
      "Individual 40: Original Steps: 7.05, Perturbed Steps: 10.58\n",
      "Individual 1: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 56: Original Steps: 19.76, Perturbed Steps: 29.64\n",
      "Individual 55: Original Steps: 2.64, Perturbed Steps: 3.96\n",
      "Individual 9: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 47: Original Steps: 2.40, Perturbed Steps: 3.61\n",
      "\n",
      "Shape of original sampled output (glucose only): (64, 100, 36)\n",
      "Shape of perturbed sampled output (glucose only): (64, 100, 36)\n"
     ]
    }
   ],
   "source": [
    "# Steps Perturbation Analysis\n",
    "# Using the last batch from model.sample_outputs for perturbation analysis\n",
    "\n",
    "if not model.sample_outputs:\n",
    "    print(\"Error: model.sample_outputs is empty. Please ensure the model has processed data.\")\n",
    "else:\n",
    "    # Use the last batch for perturbation\n",
    "    batch_index_to_perturb = 1\n",
    "    original_batch_data_dict = model.sample_outputs[batch_index_to_perturb]\n",
    "    original_batch_tuple = original_batch_data_dict['batch']\n",
    "    \n",
    "    batch_x_orig, batch_y_orig, batch_x_mark_orig, batch_y_mark_orig = original_batch_tuple[0]\n",
    "    batch_cov_orig = original_batch_tuple[1]\n",
    "    \n",
    "    # Get original predictions before perturbation\n",
    "    sampled_output_before_perturb = original_batch_data_dict['pred'][..., -1]  # Glucose channel only\n",
    "    \n",
    "    num_individuals_in_batch = batch_x_orig.shape[0]\n",
    "    num_to_perturb = min(64, num_individuals_in_batch)\n",
    "    \n",
    "    # Randomly select individuals to perturb\n",
    "    individuals_to_perturb_indices = random.sample(range(num_individuals_in_batch), num_to_perturb)\n",
    "    print(f\"Original batch size: {num_individuals_in_batch}\")\n",
    "    print(f\"Randomly selected individuals to perturb (indices): {individuals_to_perturb_indices}\")\n",
    "    \n",
    "    # Apply steps perturbation with 50% increase\n",
    "    percentage_increase_steps = 50.0\n",
    "    perturbed_batch_tuple = perturb_steps_and_hr_batch_x(original_batch_tuple[0], individuals_to_perturb_indices, percentage_increase_steps)\n",
    "    \n",
    "    # Calculate original and perturbed steps values for comparison\n",
    "    STEPS_SCALE = 20.84327263\n",
    "    STEPS_OFFSET = 6.53019535e+00\n",
    "    STEPS_FEATURE_INDEX_IN_BATCH_X = 1\n",
    "    \n",
    "    original_steps_values = {}\n",
    "    perturbed_steps_values = {}\n",
    "    \n",
    "    for i_idx in individuals_to_perturb_indices:\n",
    "        # Calculate original steps (average across time series)\n",
    "        orig_scaled = batch_x_orig[i_idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X].mean().item()\n",
    "        orig_true_steps = orig_scaled * STEPS_SCALE + STEPS_OFFSET\n",
    "        \n",
    "        # Calculate perturbed steps\n",
    "        pert_scaled = perturbed_batch_tuple[0][i_idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X].mean().item()\n",
    "        pert_true_steps = pert_scaled * STEPS_SCALE + STEPS_OFFSET\n",
    "        \n",
    "        original_steps_values[i_idx] = orig_true_steps\n",
    "        perturbed_steps_values[i_idx] = pert_true_steps\n",
    "        \n",
    "        print(f\"Individual {i_idx}: Original Steps: {orig_true_steps:.2f}, Perturbed Steps: {pert_true_steps:.2f}\")\n",
    "    \n",
    "    # Create perturbed batch for model inference\n",
    "    perturbed_batch_for_sampling = [\n",
    "        perturbed_batch_tuple,\n",
    "        batch_cov_orig\n",
    "    ]\n",
    "    \n",
    "    # Run model inference with perturbed data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model.sample_step(perturbed_batch_for_sampling, 1)\n",
    "    \n",
    "    # Get perturbed predictions\n",
    "    sampled_output_after_perturb = model.sample_outputs[-1]['pred'][..., -1]\n",
    "    \n",
    "    print(f\"\\nShape of original sampled output (glucose only): {sampled_output_before_perturb.shape}\")\n",
    "    print(f\"Shape of perturbed sampled output (glucose only): {sampled_output_after_perturb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Individual Statistics ===\n",
      "\n",
      "Individual 15:\n",
      "  Steps: 3.80 ‚Üí 5.70 (50.0% increase)\n",
      "  Pred Mean: -0.663 ‚Üí -0.602\n",
      "  Pred Std:  0.377 ‚Üí 0.425\n",
      "\n",
      "Individual 62:\n",
      "  Steps: 0.93 ‚Üí 1.40 (50.0% increase)\n",
      "  Pred Mean: -0.030 ‚Üí 0.016\n",
      "  Pred Std:  0.474 ‚Üí 0.507\n",
      "\n",
      "Individual 17:\n",
      "  Steps: 2.97 ‚Üí 4.45 (50.0% increase)\n",
      "  Pred Mean: -0.215 ‚Üí -0.177\n",
      "  Pred Std:  0.386 ‚Üí 0.409\n",
      "\n",
      "Individual 58:\n",
      "  Steps: 2.26 ‚Üí 3.39 (50.0% increase)\n",
      "  Pred Mean: -0.211 ‚Üí -0.207\n",
      "  Pred Std:  0.329 ‚Üí 0.348\n",
      "\n",
      "Individual 52:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: 0.040 ‚Üí 0.050\n",
      "  Pred Std:  0.364 ‚Üí 0.372\n",
      "\n",
      "Individual 48:\n",
      "  Steps: 6.48 ‚Üí 9.72 (50.0% increase)\n",
      "  Pred Mean: -0.011 ‚Üí -0.035\n",
      "  Pred Std:  0.286 ‚Üí 0.310\n",
      "\n",
      "Individual 27:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.330 ‚Üí -0.337\n",
      "  Pred Std:  0.299 ‚Üí 0.303\n",
      "\n",
      "Individual 46:\n",
      "  Steps: 2.83 ‚Üí 4.25 (50.0% increase)\n",
      "  Pred Mean: 0.447 ‚Üí 0.440\n",
      "  Pred Std:  0.661 ‚Üí 0.662\n",
      "\n",
      "Individual 0:\n",
      "  Steps: 1.62 ‚Üí 2.43 (50.0% increase)\n",
      "  Pred Mean: -0.605 ‚Üí -0.577\n",
      "  Pred Std:  0.322 ‚Üí 0.343\n",
      "\n",
      "Individual 16:\n",
      "  Steps: 0.26 ‚Üí 0.39 (50.0% increase)\n",
      "  Pred Mean: -0.538 ‚Üí -0.529\n",
      "  Pred Std:  0.323 ‚Üí 0.334\n",
      "\n",
      "Individual 18:\n",
      "  Steps: 3.86 ‚Üí 5.79 (50.0% increase)\n",
      "  Pred Mean: -0.117 ‚Üí -0.108\n",
      "  Pred Std:  0.292 ‚Üí 0.311\n",
      "\n",
      "Individual 23:\n",
      "  Steps: 3.94 ‚Üí 5.90 (50.0% increase)\n",
      "  Pred Mean: -0.165 ‚Üí -0.137\n",
      "  Pred Std:  0.498 ‚Üí 0.499\n",
      "\n",
      "Individual 13:\n",
      "  Steps: 0.29 ‚Üí 0.44 (50.0% increase)\n",
      "  Pred Mean: -0.266 ‚Üí -0.250\n",
      "  Pred Std:  0.330 ‚Üí 0.351\n",
      "\n",
      "Individual 49:\n",
      "  Steps: 4.43 ‚Üí 6.65 (50.0% increase)\n",
      "  Pred Mean: 1.240 ‚Üí 1.244\n",
      "  Pred Std:  0.510 ‚Üí 0.510\n",
      "\n",
      "Individual 33:\n",
      "  Steps: 9.89 ‚Üí 14.83 (50.0% increase)\n",
      "  Pred Mean: -0.233 ‚Üí -0.255\n",
      "  Pred Std:  0.444 ‚Üí 0.426\n",
      "\n",
      "Individual 37:\n",
      "  Steps: 3.03 ‚Üí 4.54 (50.0% increase)\n",
      "  Pred Mean: 0.283 ‚Üí 0.283\n",
      "  Pred Std:  0.503 ‚Üí 0.519\n",
      "\n",
      "Individual 12:\n",
      "  Steps: 1.24 ‚Üí 1.86 (50.0% increase)\n",
      "  Pred Mean: -0.230 ‚Üí -0.197\n",
      "  Pred Std:  0.426 ‚Üí 0.452\n",
      "\n",
      "Individual 5:\n",
      "  Steps: 0.95 ‚Üí 1.42 (50.0% increase)\n",
      "  Pred Mean: -0.244 ‚Üí -0.225\n",
      "  Pred Std:  0.455 ‚Üí 0.458\n",
      "\n",
      "Individual 38:\n",
      "  Steps: 11.81 ‚Üí 17.72 (50.0% increase)\n",
      "  Pred Mean: 0.297 ‚Üí 0.325\n",
      "  Pred Std:  0.642 ‚Üí 0.658\n",
      "\n",
      "Individual 43:\n",
      "  Steps: 2.66 ‚Üí 4.00 (50.0% increase)\n",
      "  Pred Mean: -0.491 ‚Üí -0.478\n",
      "  Pred Std:  0.347 ‚Üí 0.355\n",
      "\n",
      "Individual 32:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: 0.254 ‚Üí 0.253\n",
      "  Pred Std:  0.472 ‚Üí 0.480\n",
      "\n",
      "Individual 29:\n",
      "  Steps: 5.28 ‚Üí 7.92 (50.0% increase)\n",
      "  Pred Mean: -0.403 ‚Üí -0.379\n",
      "  Pred Std:  0.379 ‚Üí 0.398\n",
      "\n",
      "Individual 6:\n",
      "  Steps: 16.99 ‚Üí 25.49 (50.0% increase)\n",
      "  Pred Mean: 1.066 ‚Üí 1.097\n",
      "  Pred Std:  0.758 ‚Üí 0.775\n",
      "\n",
      "Individual 31:\n",
      "  Steps: 3.01 ‚Üí 4.51 (50.0% increase)\n",
      "  Pred Mean: -0.020 ‚Üí -0.051\n",
      "  Pred Std:  0.412 ‚Üí 0.407\n",
      "\n",
      "Individual 45:\n",
      "  Steps: 7.72 ‚Üí 11.58 (50.0% increase)\n",
      "  Pred Mean: 0.452 ‚Üí 0.412\n",
      "  Pred Std:  0.810 ‚Üí 0.781\n",
      "\n",
      "Individual 25:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.103 ‚Üí -0.099\n",
      "  Pred Std:  0.404 ‚Üí 0.397\n",
      "\n",
      "Individual 41:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: 1.341 ‚Üí 1.329\n",
      "  Pred Std:  0.559 ‚Üí 0.569\n",
      "\n",
      "Individual 63:\n",
      "  Steps: 18.25 ‚Üí 27.37 (50.0% increase)\n",
      "  Pred Mean: 0.322 ‚Üí 0.273\n",
      "  Pred Std:  0.530 ‚Üí 0.535\n",
      "\n",
      "Individual 20:\n",
      "  Steps: 1.63 ‚Üí 2.45 (50.0% increase)\n",
      "  Pred Mean: -0.019 ‚Üí 0.008\n",
      "  Pred Std:  0.556 ‚Üí 0.594\n",
      "\n",
      "Individual 30:\n",
      "  Steps: 4.30 ‚Üí 6.45 (50.0% increase)\n",
      "  Pred Mean: -0.042 ‚Üí -0.082\n",
      "  Pred Std:  0.490 ‚Üí 0.462\n",
      "\n",
      "Individual 2:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.726 ‚Üí -0.712\n",
      "  Pred Std:  0.357 ‚Üí 0.361\n",
      "\n",
      "Individual 35:\n",
      "  Steps: 6.92 ‚Üí 10.38 (50.0% increase)\n",
      "  Pred Mean: 0.472 ‚Üí 0.447\n",
      "  Pred Std:  0.630 ‚Üí 0.686\n",
      "\n",
      "Individual 3:\n",
      "  Steps: 0.21 ‚Üí 0.31 (50.0% increase)\n",
      "  Pred Mean: -0.759 ‚Üí -0.742\n",
      "  Pred Std:  0.239 ‚Üí 0.246\n",
      "\n",
      "Individual 44:\n",
      "  Steps: 13.34 ‚Üí 20.01 (50.0% increase)\n",
      "  Pred Mean: 0.067 ‚Üí 0.051\n",
      "  Pred Std:  0.517 ‚Üí 0.514\n",
      "\n",
      "Individual 61:\n",
      "  Steps: 3.53 ‚Üí 5.29 (50.0% increase)\n",
      "  Pred Mean: -0.420 ‚Üí -0.393\n",
      "  Pred Std:  0.481 ‚Üí 0.490\n",
      "\n",
      "Individual 24:\n",
      "  Steps: 8.16 ‚Üí 12.23 (50.0% increase)\n",
      "  Pred Mean: -0.001 ‚Üí 0.049\n",
      "  Pred Std:  0.620 ‚Üí 0.648\n",
      "\n",
      "Individual 26:\n",
      "  Steps: 2.59 ‚Üí 3.88 (50.0% increase)\n",
      "  Pred Mean: -0.559 ‚Üí -0.512\n",
      "  Pred Std:  0.278 ‚Üí 0.312\n",
      "\n",
      "Individual 28:\n",
      "  Steps: 20.47 ‚Üí 30.70 (50.0% increase)\n",
      "  Pred Mean: -0.244 ‚Üí -0.217\n",
      "  Pred Std:  0.341 ‚Üí 0.356\n",
      "\n",
      "Individual 11:\n",
      "  Steps: 4.01 ‚Üí 6.01 (50.0% increase)\n",
      "  Pred Mean: 0.102 ‚Üí 0.069\n",
      "  Pred Std:  0.471 ‚Üí 0.473\n",
      "\n",
      "Individual 51:\n",
      "  Steps: 0.48 ‚Üí 0.73 (50.0% increase)\n",
      "  Pred Mean: 1.308 ‚Üí 1.293\n",
      "  Pred Std:  0.367 ‚Üí 0.392\n",
      "\n",
      "Individual 34:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.932 ‚Üí -0.918\n",
      "  Pred Std:  0.222 ‚Üí 0.233\n",
      "\n",
      "Individual 19:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.560 ‚Üí -0.542\n",
      "  Pred Std:  0.285 ‚Üí 0.312\n",
      "\n",
      "Individual 42:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.488 ‚Üí -0.494\n",
      "  Pred Std:  0.285 ‚Üí 0.279\n",
      "\n",
      "Individual 54:\n",
      "  Steps: 10.93 ‚Üí 16.39 (50.0% increase)\n",
      "  Pred Mean: 0.769 ‚Üí 0.793\n",
      "  Pred Std:  0.781 ‚Üí 0.773\n",
      "\n",
      "Individual 22:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.438 ‚Üí -0.429\n",
      "  Pred Std:  0.313 ‚Üí 0.329\n",
      "\n",
      "Individual 57:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: 1.040 ‚Üí 1.031\n",
      "  Pred Std:  0.304 ‚Üí 0.302\n",
      "\n",
      "Individual 8:\n",
      "  Steps: 3.88 ‚Üí 5.83 (50.0% increase)\n",
      "  Pred Mean: -0.374 ‚Üí -0.360\n",
      "  Pred Std:  0.524 ‚Üí 0.541\n",
      "\n",
      "Individual 10:\n",
      "  Steps: 4.50 ‚Üí 6.75 (50.0% increase)\n",
      "  Pred Mean: -0.276 ‚Üí -0.270\n",
      "  Pred Std:  0.581 ‚Üí 0.579\n",
      "\n",
      "Individual 50:\n",
      "  Steps: 43.46 ‚Üí 65.20 (50.0% increase)\n",
      "  Pred Mean: 0.164 ‚Üí 0.168\n",
      "  Pred Std:  0.545 ‚Üí 0.545\n",
      "\n",
      "Individual 60:\n",
      "  Steps: 4.26 ‚Üí 6.39 (50.0% increase)\n",
      "  Pred Mean: 0.573 ‚Üí 0.578\n",
      "  Pred Std:  0.620 ‚Üí 0.659\n",
      "\n",
      "Individual 36:\n",
      "  Steps: 2.17 ‚Üí 3.26 (50.0% increase)\n",
      "  Pred Mean: -0.177 ‚Üí -0.174\n",
      "  Pred Std:  0.638 ‚Üí 0.619\n",
      "\n",
      "Individual 53:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: 0.338 ‚Üí 0.324\n",
      "  Pred Std:  0.567 ‚Üí 0.582\n",
      "\n",
      "Individual 7:\n",
      "  Steps: 9.64 ‚Üí 14.46 (50.0% increase)\n",
      "  Pred Mean: -0.158 ‚Üí -0.130\n",
      "  Pred Std:  0.451 ‚Üí 0.457\n",
      "\n",
      "Individual 59:\n",
      "  Steps: 0.98 ‚Üí 1.46 (50.0% increase)\n",
      "  Pred Mean: -0.656 ‚Üí -0.585\n",
      "  Pred Std:  0.362 ‚Üí 0.384\n",
      "\n",
      "Individual 4:\n",
      "  Steps: 7.43 ‚Üí 11.15 (50.0% increase)\n",
      "  Pred Mean: -0.430 ‚Üí -0.406\n",
      "  Pred Std:  0.541 ‚Üí 0.548\n",
      "\n",
      "Individual 14:\n",
      "  Steps: 2.05 ‚Üí 3.08 (50.0% increase)\n",
      "  Pred Mean: 0.212 ‚Üí 0.190\n",
      "  Pred Std:  0.533 ‚Üí 0.534\n",
      "\n",
      "Individual 21:\n",
      "  Steps: 2.39 ‚Üí 3.58 (50.0% increase)\n",
      "  Pred Mean: 1.036 ‚Üí 0.958\n",
      "  Pred Std:  0.366 ‚Üí 0.401\n",
      "\n",
      "Individual 39:\n",
      "  Steps: 4.36 ‚Üí 6.54 (50.0% increase)\n",
      "  Pred Mean: 0.157 ‚Üí 0.227\n",
      "  Pred Std:  0.333 ‚Üí 0.378\n",
      "\n",
      "Individual 40:\n",
      "  Steps: 7.05 ‚Üí 10.58 (50.0% increase)\n",
      "  Pred Mean: 0.067 ‚Üí 0.067\n",
      "  Pred Std:  0.614 ‚Üí 0.589\n",
      "\n",
      "Individual 1:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.511 ‚Üí -0.498\n",
      "  Pred Std:  0.382 ‚Üí 0.381\n",
      "\n",
      "Individual 56:\n",
      "  Steps: 19.76 ‚Üí 29.64 (50.0% increase)\n",
      "  Pred Mean: -0.420 ‚Üí -0.406\n",
      "  Pred Std:  0.463 ‚Üí 0.478\n",
      "\n",
      "Individual 55:\n",
      "  Steps: 2.64 ‚Üí 3.96 (50.0% increase)\n",
      "  Pred Mean: 0.321 ‚Üí 0.356\n",
      "  Pred Std:  0.372 ‚Üí 0.425\n",
      "\n",
      "Individual 9:\n",
      "  Steps: -0.00 ‚Üí -0.00 (50.0% increase)\n",
      "  Pred Mean: -0.348 ‚Üí -0.329\n",
      "  Pred Std:  0.261 ‚Üí 0.275\n",
      "\n",
      "Individual 47:\n",
      "  Steps: 2.40 ‚Üí 3.61 (50.0% increase)\n",
      "  Pred Mean: -0.279 ‚Üí -0.265\n",
      "  Pred Std:  0.501 ‚Üí 0.520\n",
      "\n",
      "=== Overall Statistics ===\n",
      "Overall prediction mean change: -0.021 ‚Üí -0.012\n",
      "Overall prediction std change:  0.450 ‚Üí 0.462\n",
      "\n",
      "=== Summary Analysis ===\n",
      "Average steps increase applied: 50.0%\n",
      "Number of individuals perturbed: 64\n",
      "Average glucose prediction change (perturbed): 0.0087\n",
      "Average glucose prediction change (control): nan\n",
      "Differential effect: nan\n"
     ]
    }
   ],
   "source": [
    "# Plotting and Statistical Analysis of Steps Perturbation Results\n",
    "\n",
    "# Calculate prediction statistics\n",
    "pred_mean_before = sampled_output_before_perturb.mean(axis=1)  # Mean across samples\n",
    "pred_std_before = sampled_output_before_perturb.std(axis=1)    # Std across samples\n",
    "pred_mean_after = sampled_output_after_perturb.mean(axis=1)   # Mean across samples  \n",
    "pred_std_after = sampled_output_after_perturb.std(axis=1)     # Std across samples\n",
    "\n",
    "# Print individual statistics for perturbed individuals\n",
    "print(\"\\n=== Individual Statistics ===\")\n",
    "for i_idx in individuals_to_perturb_indices:\n",
    "    print(f\"\\nIndividual {i_idx}:\")\n",
    "    print(f\"  Steps: {original_steps_values[i_idx]:.2f} ‚Üí {perturbed_steps_values[i_idx]:.2f} ({percentage_increase_steps}% increase)\")\n",
    "    print(f\"  Pred Mean: {pred_mean_before[i_idx].mean():.3f} ‚Üí {pred_mean_after[i_idx].mean():.3f}\")\n",
    "    print(f\"  Pred Std:  {pred_std_before[i_idx].mean():.3f} ‚Üí {pred_std_after[i_idx].mean():.3f}\")\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\n=== Overall Statistics ===\")\n",
    "print(f\"Overall prediction mean change: {pred_mean_before.mean():.3f} ‚Üí {pred_mean_after.mean():.3f}\")\n",
    "print(f\"Overall prediction std change:  {pred_std_before.mean():.3f} ‚Üí {pred_std_after.mean():.3f}\")\n",
    "\n",
    "# Create plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Steps Perturbation Analysis Results', fontsize=16)\n",
    "\n",
    "# Plot 1: Individual glucose predictions before/after for selected individuals\n",
    "ax1 = axes[0, 0]\n",
    "n_individuals_to_plot = min(3, len(individuals_to_perturb_indices))\n",
    "for plot_idx, i_idx in enumerate(individuals_to_perturb_indices[:n_individuals_to_plot]):\n",
    "    time_steps = range(pred_mean_before.shape[1])\n",
    "    ax1.plot(time_steps, pred_mean_before[i_idx], 'b-', alpha=0.7, label=f'Before (Ind {i_idx})' if plot_idx == 0 else \"\")\n",
    "    ax1.plot(time_steps, pred_mean_after[i_idx], 'r--', alpha=0.7, label=f'After (Ind {i_idx})' if plot_idx == 0 else \"\")\n",
    "\n",
    "ax1.set_title('Individual Glucose Predictions')\n",
    "ax1.set_xlabel('Time Steps')\n",
    "ax1.set_ylabel('Glucose Level')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Average prediction change across all perturbed individuals\n",
    "ax2 = axes[0, 1]\n",
    "perturbed_before = pred_mean_before[individuals_to_perturb_indices]\n",
    "perturbed_after = pred_mean_after[individuals_to_perturb_indices]\n",
    "time_steps = range(pred_mean_before.shape[1])\n",
    "ax2.plot(time_steps, perturbed_before.mean(axis=0), 'b-', linewidth=2, label='Before Perturbation')\n",
    "ax2.plot(time_steps, perturbed_after.mean(axis=0), 'r-', linewidth=2, label='After Perturbation')\n",
    "ax2.fill_between(time_steps, \n",
    "                 perturbed_before.mean(axis=0) - perturbed_before.std(axis=0),\n",
    "                 perturbed_before.mean(axis=0) + perturbed_before.std(axis=0),\n",
    "                 alpha=0.2, color='blue')\n",
    "ax2.fill_between(time_steps,\n",
    "                 perturbed_after.mean(axis=0) - perturbed_after.std(axis=0), \n",
    "                 perturbed_after.mean(axis=0) + perturbed_after.std(axis=0),\n",
    "                 alpha=0.2, color='red')\n",
    "ax2.set_title('Average Glucose Predictions (Perturbed Individuals)')\n",
    "ax2.set_xlabel('Time Steps')\n",
    "ax2.set_ylabel('Glucose Level')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Steps values comparison\n",
    "ax3 = axes[1, 0]\n",
    "individuals_plot = list(individuals_to_perturb_indices[:5])  # Show first 5\n",
    "orig_steps = [original_steps_values[i] for i in individuals_plot]\n",
    "pert_steps = [perturbed_steps_values[i] for i in individuals_plot]\n",
    "x_pos = range(len(individuals_plot))\n",
    "width = 0.35\n",
    "ax3.bar([x - width/2 for x in x_pos], orig_steps, width, label='Original Steps', alpha=0.7)\n",
    "ax3.bar([x + width/2 for x in x_pos], pert_steps, width, label='Perturbed Steps', alpha=0.7)\n",
    "ax3.set_title('Steps Values: Before vs After Perturbation')\n",
    "ax3.set_xlabel('Individual Index')\n",
    "ax3.set_ylabel('Steps Value')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([f'Ind {i}' for i in individuals_plot])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Prediction difference distribution\n",
    "ax4 = axes[1, 1]\n",
    "pred_diff = pred_mean_after - pred_mean_before\n",
    "perturbed_diff = pred_diff[individuals_to_perturb_indices].flatten()\n",
    "control_diff = np.delete(pred_diff, individuals_to_perturb_indices, axis=0).flatten()\n",
    "ax4.hist(perturbed_diff, bins=30, alpha=0.7, label='Perturbed Individuals', color='red')\n",
    "ax4.hist(control_diff, bins=30, alpha=0.7, label='Control Individuals', color='blue')\n",
    "ax4.set_title('Distribution of Prediction Changes')\n",
    "ax4.set_xlabel('Glucose Prediction Change')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary analysis\n",
    "print(f\"\\n=== Summary Analysis ===\")\n",
    "print(f\"Average steps increase applied: {percentage_increase_steps}%\")\n",
    "print(f\"Number of individuals perturbed: {len(individuals_to_perturb_indices)}\")\n",
    "mean_pred_change_perturbed = pred_diff[individuals_to_perturb_indices].mean()\n",
    "mean_pred_change_control = np.delete(pred_diff, individuals_to_perturb_indices, axis=0).mean()\n",
    "print(f\"Average glucose prediction change (perturbed): {mean_pred_change_perturbed:.4f}\")\n",
    "print(f\"Average glucose prediction change (control): {mean_pred_change_control:.4f}\")\n",
    "print(f\"Differential effect: {mean_pred_change_perturbed - mean_pred_change_control:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steps Perturbation Summary Analysis ===\n",
      "Perturbation applied: 50.0% change in steps\n",
      "Number of individuals perturbed: 64\n",
      "Average glucose prediction change (perturbed individuals): 0.0087\n",
      "Average glucose prediction change (control individuals): 0.0000\n",
      "Differential effect of steps perturbation: 0.0087\n",
      "\n",
      "=== Individual Results ===\n",
      "Individual 15:\n",
      "  Steps change: 3.8 ‚Üí 5.7 (+1.9)\n",
      "  Avg glucose prediction change: -0.0905\n",
      "Individual 62:\n",
      "  Steps change: 0.9 ‚Üí 1.4 (+0.5)\n",
      "  Avg glucose prediction change: +0.1444\n",
      "Individual 17:\n",
      "  Steps change: 3.0 ‚Üí 4.4 (+1.5)\n",
      "  Avg glucose prediction change: +0.2248\n",
      "Individual 58:\n",
      "  Steps change: 2.3 ‚Üí 3.4 (+1.1)\n",
      "  Avg glucose prediction change: +0.0946\n",
      "Individual 52:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0348\n",
      "Individual 48:\n",
      "  Steps change: 6.5 ‚Üí 9.7 (+3.2)\n",
      "  Avg glucose prediction change: -0.0475\n",
      "Individual 27:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0376\n",
      "Individual 46:\n",
      "  Steps change: 2.8 ‚Üí 4.2 (+1.4)\n",
      "  Avg glucose prediction change: +0.0249\n",
      "Individual 0:\n",
      "  Steps change: 1.6 ‚Üí 2.4 (+0.8)\n",
      "  Avg glucose prediction change: -0.0468\n",
      "Individual 16:\n",
      "  Steps change: 0.3 ‚Üí 0.4 (+0.1)\n",
      "  Avg glucose prediction change: -0.0232\n",
      "Individual 18:\n",
      "  Steps change: 3.9 ‚Üí 5.8 (+1.9)\n",
      "  Avg glucose prediction change: +0.0643\n",
      "Individual 23:\n",
      "  Steps change: 3.9 ‚Üí 5.9 (+2.0)\n",
      "  Avg glucose prediction change: +0.0669\n",
      "Individual 13:\n",
      "  Steps change: 0.3 ‚Üí 0.4 (+0.1)\n",
      "  Avg glucose prediction change: +0.0810\n",
      "Individual 49:\n",
      "  Steps change: 4.4 ‚Üí 6.6 (+2.2)\n",
      "  Avg glucose prediction change: +0.0555\n",
      "Individual 33:\n",
      "  Steps change: 9.9 ‚Üí 14.8 (+4.9)\n",
      "  Avg glucose prediction change: -0.0829\n",
      "Individual 37:\n",
      "  Steps change: 3.0 ‚Üí 4.5 (+1.5)\n",
      "  Avg glucose prediction change: -0.0470\n",
      "Individual 12:\n",
      "  Steps change: 1.2 ‚Üí 1.9 (+0.6)\n",
      "  Avg glucose prediction change: -0.1110\n",
      "Individual 5:\n",
      "  Steps change: 0.9 ‚Üí 1.4 (+0.5)\n",
      "  Avg glucose prediction change: -0.0039\n",
      "Individual 38:\n",
      "  Steps change: 11.8 ‚Üí 17.7 (+5.9)\n",
      "  Avg glucose prediction change: -0.0085\n",
      "Individual 43:\n",
      "  Steps change: 2.7 ‚Üí 4.0 (+1.3)\n",
      "  Avg glucose prediction change: -0.0240\n",
      "Individual 32:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: -0.0083\n",
      "Individual 29:\n",
      "  Steps change: 5.3 ‚Üí 7.9 (+2.6)\n",
      "  Avg glucose prediction change: -0.0558\n",
      "Individual 6:\n",
      "  Steps change: 17.0 ‚Üí 25.5 (+8.5)\n",
      "  Avg glucose prediction change: +0.0956\n",
      "Individual 31:\n",
      "  Steps change: 3.0 ‚Üí 4.5 (+1.5)\n",
      "  Avg glucose prediction change: -0.1289\n",
      "Individual 45:\n",
      "  Steps change: 7.7 ‚Üí 11.6 (+3.9)\n",
      "  Avg glucose prediction change: -0.1065\n",
      "Individual 25:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0008\n",
      "Individual 41:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: -0.0553\n",
      "Individual 63:\n",
      "  Steps change: 18.2 ‚Üí 27.4 (+9.1)\n",
      "  Avg glucose prediction change: -0.0526\n",
      "Individual 20:\n",
      "  Steps change: 1.6 ‚Üí 2.5 (+0.8)\n",
      "  Avg glucose prediction change: +0.0353\n",
      "Individual 30:\n",
      "  Steps change: 4.3 ‚Üí 6.4 (+2.1)\n",
      "  Avg glucose prediction change: -0.0600\n",
      "Individual 2:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0382\n",
      "Individual 35:\n",
      "  Steps change: 6.9 ‚Üí 10.4 (+3.5)\n",
      "  Avg glucose prediction change: -0.0019\n",
      "Individual 3:\n",
      "  Steps change: 0.2 ‚Üí 0.3 (+0.1)\n",
      "  Avg glucose prediction change: -0.0182\n",
      "Individual 44:\n",
      "  Steps change: 13.3 ‚Üí 20.0 (+6.7)\n",
      "  Avg glucose prediction change: +0.0971\n",
      "Individual 61:\n",
      "  Steps change: 3.5 ‚Üí 5.3 (+1.8)\n",
      "  Avg glucose prediction change: -0.0228\n",
      "Individual 24:\n",
      "  Steps change: 8.2 ‚Üí 12.2 (+4.1)\n",
      "  Avg glucose prediction change: +0.0889\n",
      "Individual 26:\n",
      "  Steps change: 2.6 ‚Üí 3.9 (+1.3)\n",
      "  Avg glucose prediction change: +0.0256\n",
      "Individual 28:\n",
      "  Steps change: 20.5 ‚Üí 30.7 (+10.2)\n",
      "  Avg glucose prediction change: +0.0277\n",
      "Individual 11:\n",
      "  Steps change: 4.0 ‚Üí 6.0 (+2.0)\n",
      "  Avg glucose prediction change: +0.0161\n",
      "Individual 51:\n",
      "  Steps change: 0.5 ‚Üí 0.7 (+0.2)\n",
      "  Avg glucose prediction change: -0.0090\n",
      "Individual 34:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0943\n",
      "Individual 19:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0370\n",
      "Individual 42:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0210\n",
      "Individual 54:\n",
      "  Steps change: 10.9 ‚Üí 16.4 (+5.5)\n",
      "  Avg glucose prediction change: +0.2858\n",
      "Individual 22:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0441\n",
      "Individual 57:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: -0.0378\n",
      "Individual 8:\n",
      "  Steps change: 3.9 ‚Üí 5.8 (+1.9)\n",
      "  Avg glucose prediction change: +0.0325\n",
      "Individual 10:\n",
      "  Steps change: 4.5 ‚Üí 6.7 (+2.2)\n",
      "  Avg glucose prediction change: +0.0372\n",
      "Individual 50:\n",
      "  Steps change: 43.5 ‚Üí 65.2 (+21.7)\n",
      "  Avg glucose prediction change: +0.0890\n",
      "Individual 60:\n",
      "  Steps change: 4.3 ‚Üí 6.4 (+2.1)\n",
      "  Avg glucose prediction change: +0.0118\n",
      "Individual 36:\n",
      "  Steps change: 2.2 ‚Üí 3.3 (+1.1)\n",
      "  Avg glucose prediction change: +0.0737\n",
      "Individual 53:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: -0.0438\n",
      "Individual 7:\n",
      "  Steps change: 9.6 ‚Üí 14.5 (+4.8)\n",
      "  Avg glucose prediction change: -0.0058\n",
      "Individual 59:\n",
      "  Steps change: 1.0 ‚Üí 1.5 (+0.5)\n",
      "  Avg glucose prediction change: +0.0814\n",
      "Individual 4:\n",
      "  Steps change: 7.4 ‚Üí 11.2 (+3.7)\n",
      "  Avg glucose prediction change: -0.1066\n",
      "Individual 14:\n",
      "  Steps change: 2.1 ‚Üí 3.1 (+1.0)\n",
      "  Avg glucose prediction change: -0.1329\n",
      "Individual 21:\n",
      "  Steps change: 2.4 ‚Üí 3.6 (+1.2)\n",
      "  Avg glucose prediction change: -0.0923\n",
      "Individual 39:\n",
      "  Steps change: 4.4 ‚Üí 6.5 (+2.2)\n",
      "  Avg glucose prediction change: +0.2010\n",
      "Individual 40:\n",
      "  Steps change: 7.1 ‚Üí 10.6 (+3.5)\n",
      "  Avg glucose prediction change: +0.0164\n",
      "Individual 1:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: -0.0413\n",
      "Individual 56:\n",
      "  Steps change: 19.8 ‚Üí 29.6 (+9.9)\n",
      "  Avg glucose prediction change: -0.0345\n",
      "Individual 55:\n",
      "  Steps change: 2.6 ‚Üí 4.0 (+1.3)\n",
      "  Avg glucose prediction change: +0.0970\n",
      "Individual 9:\n",
      "  Steps change: -0.0 ‚Üí -0.0 (-0.0)\n",
      "  Avg glucose prediction change: +0.0035\n",
      "Individual 47:\n",
      "  Steps change: 2.4 ‚Üí 3.6 (+1.2)\n",
      "  Avg glucose prediction change: +0.0329\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Individual time series plots for each perturbed individual (following HbA1c style)\n",
    "if 'individuals_to_perturb_indices' not in locals() or \\\n",
    "   'sampled_output_before_perturb' not in locals() or \\\n",
    "   'sampled_output_after_perturb' not in locals():\n",
    "    print(\"Error: Ensure the perturbation analysis has been run and variables are available.\")\n",
    "else:\n",
    "    # Get the time series data for plotting\n",
    "    seq_len = batch_x_orig.shape[1]\n",
    "    # Defensive: pred_len should be the last dimension of the predictions\n",
    "    # For before perturb: shape (num_individuals, num_samples, pred_len)\n",
    "    # For after perturb: shape (num_individuals, num_samples, pred_len, num_channels) or (num_individuals, num_samples, pred_len) if squeezed\n",
    "    # We'll handle both cases\n",
    "    if sampled_output_before_perturb.ndim == 3:\n",
    "        pred_len = sampled_output_before_perturb.shape[2]\n",
    "    elif sampled_output_before_perturb.ndim == 2:\n",
    "        pred_len = sampled_output_before_perturb.shape[1]\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected shape for sampled_output_before_perturb\")\n",
    "    time_history = np.arange(seq_len)\n",
    "    time_pred = np.arange(seq_len, seq_len + pred_len)\n",
    "\n",
    "    # Plot individual time series for each perturbed individual\n",
    "    for idx in individuals_to_perturb_indices:\n",
    "        # Get input history (glucose channel)\n",
    "        history_data = batch_x_orig[idx, :, 0].cpu().numpy()  # Assuming glucose is channel 0\n",
    "\n",
    "        # Get ground truth future\n",
    "        true_future_data = batch_y_orig[idx, -pred_len:, 0].cpu().numpy()  # Glucose channel\n",
    "\n",
    "        # Get predictions before perturbation\n",
    "        preds_before_raw = sampled_output_before_perturb[idx]  # (num_samples, pred_len)\n",
    "        if preds_before_raw.ndim == 2:\n",
    "            mean_preds_before = np.mean(preds_before_raw, axis=0)\n",
    "            std_preds_before = np.std(preds_before_raw, axis=0)\n",
    "        elif preds_before_raw.ndim == 1:\n",
    "            mean_preds_before = preds_before_raw\n",
    "            std_preds_before = np.zeros_like(mean_preds_before)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected shape for preds_before_raw\")\n",
    "\n",
    "        # Get predictions after perturbation\n",
    "        preds_after_raw = sampled_output_after_perturb[idx]\n",
    "        # Handle possible extra channel dimension\n",
    "        if preds_after_raw.ndim == 3:\n",
    "            # (num_samples, pred_len, num_channels)\n",
    "            preds_after_raw = preds_after_raw[..., 0]  # Glucose channel\n",
    "        if preds_after_raw.ndim == 2:\n",
    "            mean_preds_after = np.mean(preds_after_raw, axis=0)\n",
    "            std_preds_after = np.std(preds_after_raw, axis=0)\n",
    "        elif preds_after_raw.ndim == 1:\n",
    "            mean_preds_after = preds_after_raw\n",
    "            std_preds_after = np.zeros_like(mean_preds_after)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected shape for preds_after_raw\")\n",
    "\n",
    "        # Ensure all arrays are 1D and of length pred_len\n",
    "        mean_preds_before = np.asarray(mean_preds_before).flatten()\n",
    "        std_preds_before = np.asarray(std_preds_before).flatten()\n",
    "        mean_preds_after = np.asarray(mean_preds_after).flatten()\n",
    "        std_preds_after = np.asarray(std_preds_after).flatten()\n",
    "        true_future_data = np.asarray(true_future_data).flatten()\n",
    "        # Defensive: truncate or pad to pred_len if needed\n",
    "        if mean_preds_before.shape[0] != pred_len:\n",
    "            mean_preds_before = mean_preds_before[:pred_len]\n",
    "            std_preds_before = std_preds_before[:pred_len]\n",
    "        if mean_preds_after.shape[0] != pred_len:\n",
    "            mean_preds_after = mean_preds_after[:pred_len]\n",
    "            std_preds_after = std_preds_after[:pred_len]\n",
    "        if true_future_data.shape[0] != pred_len:\n",
    "            true_future_data = true_future_data[:pred_len]\n",
    "\n",
    "        plt.figure(figsize=(15, 7))\n",
    "\n",
    "        # Plot input history\n",
    "        plt.plot(time_history, history_data, label='Input History (Glucose)',\n",
    "                 color='black', linewidth=1.5)\n",
    "\n",
    "        # Plot ground truth future\n",
    "        plt.plot(time_pred, true_future_data, label='Ground Truth Future (Glucose)',\n",
    "                 color='green', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Plot predictions before perturbation\n",
    "        plt.plot(time_pred, mean_preds_before,\n",
    "                 label=f'Mean Pred (Before Perturb, Orig Steps: {original_steps_values[idx]:.1f})',\n",
    "                 color='blue', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_before - std_preds_before,\n",
    "                         mean_preds_before + std_preds_before,\n",
    "                         color='blue', alpha=0.2, label='Std Dev (Before)')\n",
    "\n",
    "        # Plot predictions after perturbation\n",
    "        plt.plot(time_pred, mean_preds_after,\n",
    "                 label=f'Mean Pred (After Perturb, New Steps: {perturbed_steps_values[idx]:.1f})',\n",
    "                 color='red', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_after - std_preds_after,\n",
    "                         mean_preds_after + std_preds_after,\n",
    "                         color='red', alpha=0.2, label='Std Dev (After)')\n",
    "\n",
    "        plt.title(f'Glucose Prediction Steps Perturbation Analysis for Individual {idx}', fontsize=16)\n",
    "        plt.xlabel('Time Steps', fontsize=14)\n",
    "        plt.ylabel('Glucose Value', fontsize=14)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Summary statistics analysis\n",
    "print(f\"\\n=== Steps Perturbation Summary Analysis ===\")\n",
    "print(f\"Perturbation applied: {percentage_increase_steps}% change in steps\")\n",
    "print(f\"Number of individuals perturbed: {len(individuals_to_perturb_indices)}\")\n",
    "\n",
    "# Calculate prediction differences\n",
    "# Defensive: mean over axis=1 (samples), keep pred_len dimension\n",
    "pred_mean_before = sampled_output_before_perturb.mean(axis=1)  # (num_individuals, pred_len)\n",
    "if sampled_output_after_perturb.ndim == 4:\n",
    "    pred_mean_after = sampled_output_after_perturb[..., 0].mean(axis=1)  # (num_individuals, pred_len)\n",
    "else:\n",
    "    pred_mean_after = sampled_output_after_perturb.mean(axis=1)   # (num_individuals, pred_len)\n",
    "pred_diff = pred_mean_after - pred_mean_before  # (num_individuals, pred_len)\n",
    "\n",
    "# Calculate effect sizes\n",
    "perturbed_diff = pred_diff[individuals_to_perturb_indices].mean()\n",
    "control_indices = [i for i in range(pred_diff.shape[0]) if i not in individuals_to_perturb_indices]\n",
    "control_diff = pred_diff[control_indices].mean() if control_indices else 0\n",
    "\n",
    "print(f\"Average glucose prediction change (perturbed individuals): {perturbed_diff:.4f}\")\n",
    "print(f\"Average glucose prediction change (control individuals): {control_diff:.4f}\")\n",
    "print(f\"Differential effect of steps perturbation: {perturbed_diff - control_diff:.4f}\")\n",
    "\n",
    "# Individual statistics\n",
    "print(f\"\\n=== Individual Results ===\")\n",
    "for i_idx in individuals_to_perturb_indices:\n",
    "    steps_change = perturbed_steps_values[i_idx] - original_steps_values[i_idx]\n",
    "    # Defensive: mean over pred_len dimension\n",
    "    pred_change = pred_mean_after[i_idx, -1].mean() - pred_mean_before[i_idx, -1].mean()\n",
    "    print(f\"Individual {i_idx}:\")\n",
    "    print(f\"  Steps change: {original_steps_values[i_idx]:.1f} ‚Üí {perturbed_steps_values[i_idx]:.1f} ({steps_change:+.1f})\")\n",
    "    print(f\"  Avg glucose prediction change: {pred_change:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cDIME",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
