{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [7.93461185e+01 6.53019535e+00 1.44037396e-02 1.44911487e+02]\n",
      "Std: [20.41707644 20.84327263  0.27630121 55.13396884]\n",
      "Loading data into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from data_provider_pretrain.data_factory import data_provider\n",
    "from models.time_series_diffusion_model import TimeSeriesDiffusionModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from utils.callbacks import EMA\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import wandb\n",
    "from datetime import timedelta\n",
    "from utils.clean_args import clean_args\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Time-LLM')\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "torch.cuda.manual_seed(fix_seed)\n",
    "torch.cuda.manual_seed_all(fix_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class DotDict(dict):\n",
    "    \"\"\"\n",
    "    A dictionary that supports both dot notation and dictionary access.\n",
    "    This allows both `args.att` and `args['att']` to work.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__dict__.pop(item, None)\n",
    "\n",
    "default_config = DotDict({\n",
    "    # Basic config\n",
    "    \"num_nodes\": 1,\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"is_training\": 1,\n",
    "    \"model_id\": \"ETTh1_ETTh2_512_192\",\n",
    "    \"model\": \"ns_Transformer\",\n",
    "    \"precision\": \"32\",\n",
    "    \n",
    "    # Data loader\n",
    "    \"data_pretrain\": \"Glucose\",\n",
    "    \"root_path\": \"/home/yl2428/Time-LLM/dataset/glucose\",\n",
    "    \"data_path\": \"combined_data_Jun_28.csv\",\n",
    "    \"data_path_pretrain\": \"combined_data_Jun_28.csv\",\n",
    "    \"features\": \"M\",\n",
    "    \"target\": \"OT\",\n",
    "    \"freq\": \"t\",\n",
    "    \"checkpoints\": \"/gpfs/gibbs/pi/gerstein/yl2428/checkpoints/\",\n",
    "    \"log_dir\": \"/gpfs/gibbs/pi/gerstein/yl2428/logs\",\n",
    "    \n",
    "    # Forecasting task\n",
    "    \"seq_len\": 128,\n",
    "    \"label_len\": 12,\n",
    "    \"pred_len\": 32,\n",
    "    \"seasonal_patterns\": \"Monthly\",\n",
    "    \"stride\": 8,\n",
    "    \n",
    "    # Model define\n",
    "    \"enc_in\": 4,\n",
    "    \"dec_in\": 4,\n",
    "    \"c_out\": 4,\n",
    "    \"d_model\": 32,\n",
    "    \"n_heads\": 8,\n",
    "    \"e_layers\": 2,\n",
    "    \"d_layers\": 1,\n",
    "    \"d_ff\": 128,\n",
    "    \"moving_avg\": 25,\n",
    "    \"factor\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"activation\": \"gelu\",\n",
    "    \"output_attention\": False,\n",
    "    \"patch_len\": 16,\n",
    "    \"prompt_domain\": 0,\n",
    "    \"llm_model\": \"LLAMA\",\n",
    "    \"llm_dim\": 4096,\n",
    "    \n",
    "    # Optimization\n",
    "    \"num_workers\": 10,\n",
    "    \"itr\": 1,\n",
    "    \"train_epochs\": 100,\n",
    "    \"align_epochs\": 10,\n",
    "    \"ema_decay\": 0.97,\n",
    "    \"batch_size\": 64,\n",
    "    \"eval_batch_size\": 2,\n",
    "    \"patience\": 10,\n",
    "    \"learning_rate\": 0.0004,\n",
    "    \"des\": \"Exp\",\n",
    "    \"loss\": \"MSE\",\n",
    "    \"lradj\": \"COS\",\n",
    "    \"pct_start\": 0.2,\n",
    "    \"use_amp\": False,\n",
    "    \"llm_layers\": 32,\n",
    "    \"percent\": 100,\n",
    "    \"num_individuals\": -1,\n",
    "    \"enable_covariates\": 1,\n",
    "    \"cov_type\": \"tensor\",\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"use_deep_speed\": 1,\n",
    "    \n",
    "    # Wandb\n",
    "    \"wandb\": 1,\n",
    "    \"wandb_group\": None,\n",
    "    \"wandb_api_key\": \"6f1080f993d5d7ad6103e69ef57dd9291f1bf366\",\n",
    "    \"num_experts\": 8,\n",
    "    \"head_dropout\": 0.1,\n",
    "    \n",
    "    # TimeMixer-specific parameters\n",
    "    \"channel_independence\": 0,\n",
    "    \"decomp_method\": \"moving_avg\",\n",
    "    \"use_norm\": 1,\n",
    "    \"down_sampling_layers\": 2,\n",
    "    \"down_sampling_window\": 1,\n",
    "    \"down_sampling_method\": \"avg\",\n",
    "    \"use_future_temporal_feature\": 0,\n",
    "    \n",
    "    # Diffusion specific parameters\n",
    "    \"k_z\": 1e-2,\n",
    "    \"k_cond\": 1,\n",
    "    \"d_z\": 8,\n",
    "    \n",
    "    # De-stationary projector params\n",
    "    \"p_hidden_dims\": [64, 64],\n",
    "    \"p_hidden_layers\": 2,\n",
    "    \n",
    "    # CART related args\n",
    "    \"diffusion_config_dir\": \"/home/yl2428/Time-LLM/models/model9_NS_transformer/configs/toy_8gauss.yml\",\n",
    "    \"cond_pred_model_pertrain_dir\": None,\n",
    "    \"CART_input_x_embed_dim\": 32,\n",
    "    \"mse_timestep\": 0,\n",
    "    \"MLP_diffusion_net\": False,\n",
    "    \n",
    "    # Ax args\n",
    "    \"timesteps\": 1000,\n",
    "    \n",
    "    # Additional parameters\n",
    "    \"master_port\": 8889,\n",
    "    \"comment\": \"TimeLLM-ECL\"\n",
    "})\n",
    "\n",
    "\n",
    "args = default_config\n",
    "\n",
    "for ii in range(args.itr):\n",
    "    train_data, train_loader, args = data_provider(args, args.data_pretrain, args.data_path_pretrain, True, 'train')\n",
    "    vali_data, vali_loader, args = data_provider(args, args.data_pretrain, args.data_path_pretrain, True, 'val')\n",
    "    test_data, test_loader, args = data_provider(args, args.data_pretrain, args.data_path_pretrain, True, 'test')\n",
    "    model = TimeSeriesDiffusionModel(args, train_loader, vali_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from data_provider_pretrain.data_factory import data_provider\n",
    "from models.time_series_flow_matching_model import TimeSeriesFlowMatchingModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from utils.callbacks import EMA\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import wandb\n",
    "from datetime import timedelta\n",
    "from utils.clean_args import clean_args\n",
    "import glob\n",
    "import re\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "torch.cuda.manual_seed(fix_seed)\n",
    "torch.cuda.manual_seed_all(fix_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class DotDict(dict):\n",
    "    \"\"\"\n",
    "    A dictionary that supports both dot notation and dictionary access.\n",
    "    This allows both `args.att` and `args['att']` to work.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__dict__.pop(item, None)\n",
    "\n",
    "# Flow matching configuration based on train_glucose_diffusion_slurm.sh\n",
    "flow_matching_config = DotDict({\n",
    "    # Basic config\n",
    "    \"num_nodes\": 1,\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"is_training\": 1,\n",
    "    \"model_id\": \"ETTh1_ETTh2_512_192\",\n",
    "    \"model\": \"ns_Transformer\",  # From shell script\n",
    "    \"precision\": \"32\",\n",
    "    \"generative_model\": \"flow_matching\",  # Key difference from diffusion\n",
    "    \n",
    "    # Data loader (from shell script)\n",
    "    \"data_pretrain\": \"Glucose\",\n",
    "    \"root_path\": \"/home/yl2428/Time-LLM/dataset/glucose\",\n",
    "    \"data_path\": \"combined_data_Jun_28.csv\",\n",
    "    \"data_path_pretrain\": \"combined_data_Jun_28.csv\",\n",
    "    \"features\": \"MS\",  # From shell script\n",
    "    \"target\": \"OT\",\n",
    "    \"freq\": \"t\",\n",
    "    \"checkpoints\": \"/home/yl2428/checkpoints/\",\n",
    "    \"log_dir\": \"/home/yl2428/logs\",\n",
    "    \n",
    "    # Forecasting task (from shell script)\n",
    "    \"seq_len\": 72,\n",
    "    \"label_len\": 32,\n",
    "    \"pred_len\": 64,\n",
    "    \"seasonal_patterns\": \"Monthly\",\n",
    "    \"stride\": 1,  # From shell script\n",
    "    \n",
    "    # Model define (from shell script)\n",
    "    \"enc_in\": 4,\n",
    "    \"dec_in\": 4,\n",
    "    \"c_out\": 4,\n",
    "    \"d_model\": 32,  # From shell script\n",
    "    \"n_heads\": 8,\n",
    "    \"e_layers\": 2,\n",
    "    \"d_layers\": 1,\n",
    "    \"d_ff\": 256,  # From shell script\n",
    "    \"moving_avg\": 25,\n",
    "    \"factor\": 3,  # From shell script\n",
    "    \"dropout\": 0.1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"activation\": \"gelu\",\n",
    "    \"output_attention\": False,\n",
    "    \"patch_len\": 16,\n",
    "    \"prompt_domain\": 0,\n",
    "    \"llm_model\": \"LLAMA\",\n",
    "    \"llm_dim\": 4096,\n",
    "    \n",
    "    # VAE-specific parameters for ns_DLinear\n",
    "    \"latent_len\": 24,  # Half of seq_len by default\n",
    "    \"vae_hidden_dim\": 16,\n",
    "    \n",
    "    # Required for Trompt encoder - these will be populated by data_provider\n",
    "    \"col_stats\": None,\n",
    "    \"col_names_dict\": None,\n",
    "    \n",
    "    # Optimization (from shell script)\n",
    "    \"num_workers\": 10,\n",
    "    \"itr\": 1,\n",
    "    \"train_epochs\": 100,  # From shell script\n",
    "    \"align_epochs\": 10,\n",
    "    \"ema_decay\": 0.995,\n",
    "    \"batch_size\": 256,  # From shell script\n",
    "    \"eval_batch_size\": 256,\n",
    "    \"patience\": 10,\n",
    "    \"learning_rate\": 0.0001,  # From shell script\n",
    "    \"des\": \"Exp\",\n",
    "    \"loss\": \"MSE\",\n",
    "    \"lradj\": \"COS\",\n",
    "    \"pct_start\": 0.2,\n",
    "    \"use_amp\": False,\n",
    "    \"llm_layers\": 32,  # From shell script (llama_layers)\n",
    "    \"percent\": 100,\n",
    "    \"num_individuals\": 100,  # From shell script\n",
    "    \"enable_covariates\": 1,  # From shell script\n",
    "    \"cov_type\": \"tensor\",\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"use_deep_speed\": 1,  # From shell script\n",
    "    \n",
    "    # Wandb\n",
    "    \"wandb\": 1,\n",
    "    \"wandb_group\": None,\n",
    "    \"wandb_api_key\": \"6f1080f993d5d7ad6103e69ef57dd9291f1bf366\",\n",
    "    \n",
    "    # MoE parameters (from shell script)\n",
    "    \"use_moe\": 1,\n",
    "    \"num_experts\": 8,\n",
    "    \"top_k_experts\": 4,\n",
    "    \"moe_layer_indices\": [0, 1],\n",
    "    \"moe_loss_weight\": 0.01,\n",
    "    \"log_routing_stats\": 1,\n",
    "    \"num_universal_experts\": 1,\n",
    "    \"universal_expert_weight\": 0.3,\n",
    "    \"head_dropout\": 0.1,\n",
    "    \n",
    "    # TimeMixer-specific parameters\n",
    "    \"channel_independence\": 0,\n",
    "    \"decomp_method\": \"moving_avg\",\n",
    "    \"use_norm\": 1,\n",
    "    \"down_sampling_layers\": 2,\n",
    "    \"down_sampling_window\": 1,\n",
    "    \"down_sampling_method\": \"avg\",\n",
    "    \"use_future_temporal_feature\": 0,\n",
    "    \n",
    "    # Flow matching specific parameters\n",
    "    \"k_z\": 1e-2,\n",
    "    \"k_cond\": 1,\n",
    "    \"d_z\": 8,\n",
    "    \n",
    "    # De-stationary projector params\n",
    "    \"p_hidden_dims\": [64, 64],\n",
    "    \"p_hidden_layers\": 2,\n",
    "    \n",
    "    # Flow matching config\n",
    "    \"diffusion_config_dir\": \"/home/yl2428/Time-LLM/models/model9_NS_transformer/configs/toy_8gauss.yml\",\n",
    "    \"cond_pred_model_pertrain_dir\": None,\n",
    "    \"CART_input_x_embed_dim\": 32,\n",
    "    \"mse_timestep\": 0,\n",
    "    \"MLP_diffusion_net\": False,\n",
    "    \n",
    "    # Flow matching specific timesteps (reduced from 1000 for efficiency)\n",
    "    \"timesteps\": 50,\n",
    "    \n",
    "    # Flow matching ODE solver parameters\n",
    "    \"ode_solver\": \"dopri5\",\n",
    "    \"ode_rtol\": 1e-5,\n",
    "    \"ode_atol\": 1e-5,\n",
    "    \"interpolation_type\": \"linear\",\n",
    "    \"expert_layers\": 2,  # Add the missing expert_layers parameter\n",
    "})\n",
    "\n",
    "def find_best_checkpoint(base_path=\"/home/yl2428/logs/ns_DLinear/flow_matching\", metric=\"val_loss\"):\n",
    "    \"\"\"\n",
    "    Find the best checkpoint based on validation loss.\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base directory to search for checkpoints\n",
    "        metric: Metric to optimize (default: val_loss, lower is better)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (best_checkpoint_path, best_metric_value, run_name)\n",
    "    \"\"\"\n",
    "    print(f\"Searching for checkpoints in: {base_path}\")\n",
    "    \n",
    "    # Find all checkpoint directories\n",
    "    checkpoint_pattern = os.path.join(base_path, \"*/checkpoints/epoch=*-step=*-val_loss=*.ckpt/checkpoint\")\n",
    "    checkpoint_dirs = glob.glob(checkpoint_pattern)\n",
    "    \n",
    "    if not checkpoint_dirs:\n",
    "        print(\"No checkpoints found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    best_checkpoint = None\n",
    "    best_metric = float('inf')  # Assuming lower is better for val_loss\n",
    "    best_run = None\n",
    "    \n",
    "    print(f\"Found {len(checkpoint_dirs)} checkpoints:\")\n",
    "    \n",
    "    for checkpoint_dir in checkpoint_dirs:\n",
    "        # Extract metric value from path\n",
    "        # Pattern: epoch=X-step=Y-val_loss=Z.ckpt\n",
    "        pattern = r'epoch=(\\d+)-step=(\\d+)-val_loss=([\\d.]+)\\.ckpt'\n",
    "        match = re.search(pattern, checkpoint_dir)\n",
    "        \n",
    "        if match:\n",
    "            epoch, step, val_loss = match.groups()\n",
    "            val_loss = float(val_loss)\n",
    "            \n",
    "            # Extract run name\n",
    "            run_name = checkpoint_dir.split('/')[-4]  # Get run directory name\n",
    "            \n",
    "            print(f\"  - {run_name}: epoch={epoch}, step={step}, val_loss={val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_metric:\n",
    "                best_metric = val_loss\n",
    "                best_checkpoint = checkpoint_dir\n",
    "                best_run = run_name\n",
    "    \n",
    "    if best_checkpoint:\n",
    "        print(f\"\\nBest checkpoint: {best_run}\")\n",
    "        print(f\"  - Path: {best_checkpoint}\")\n",
    "        print(f\"  - Val Loss: {best_metric:.4f}\")\n",
    "    \n",
    "    return best_checkpoint, best_metric, best_run\n",
    "\n",
    "def load_deepspeed_checkpoint(model, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load DeepSpeed checkpoint into the model.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch Lightning model\n",
    "        checkpoint_path: Path to the DeepSpeed checkpoint directory\n",
    "    \n",
    "    Returns:\n",
    "        model: Model with loaded weights\n",
    "    \"\"\"\n",
    "    print(f\"Loading DeepSpeed checkpoint from: {checkpoint_path}\")\n",
    "    \n",
    "    # DeepSpeed saves model states in mp_rank_00_model_states.pt\n",
    "    model_states_path = os.path.join(checkpoint_path, \"mp_rank_00_model_states.pt\")\n",
    "    \n",
    "    if not os.path.exists(model_states_path):\n",
    "        raise FileNotFoundError(f\"Model states file not found: {model_states_path}\")\n",
    "    \n",
    "    print(f\"Loading model states from: {model_states_path}\")\n",
    "    \n",
    "    # Determine the device to use\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(model_states_path, map_location=device)\n",
    "    \n",
    "    # Extract the model state dict\n",
    "    if 'module' in checkpoint:\n",
    "        state_dict = checkpoint['module']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        # Sometimes the checkpoint is the state dict directly\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Remove any DeepSpeed prefixes if they exist\n",
    "    cleaned_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        # Remove common prefixes that DeepSpeed might add\n",
    "        clean_key = key\n",
    "        if key.startswith('_forward_module.'):\n",
    "            clean_key = key.replace('_forward_module.', '')\n",
    "        elif key.startswith('module.'):\n",
    "            clean_key = key.replace('module.', '')\n",
    "        \n",
    "        # Ensure the tensor is on the correct device\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.to(device)\n",
    "        \n",
    "        cleaned_state_dict[clean_key] = value\n",
    "    \n",
    "    # Load the state dict into the model\n",
    "    try:\n",
    "        # First move the model to the device\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Load the state dict\n",
    "        missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)\n",
    "        \n",
    "        if missing_keys:\n",
    "            print(f\"Missing keys: {missing_keys[:10]}{'...' if len(missing_keys) > 10 else ''}\")\n",
    "        if unexpected_keys:\n",
    "            print(f\"Unexpected keys: {unexpected_keys[:10]}{'...' if len(unexpected_keys) > 10 else ''}\")\n",
    "            \n",
    "        print(\"✓ Model weights loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Some keys couldn't be loaded: {e}\")\n",
    "        # Try to load what we can\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in cleaned_state_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        \n",
    "        # Move model to device first\n",
    "        model = model.to(device)\n",
    "        model.load_state_dict(model_dict)\n",
    "        print(f\"✓ Loaded {len(pretrained_dict)}/{len(cleaned_state_dict)} parameters\")\n",
    "    \n",
    "    # Ensure all submodules are on the correct device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Special handling for torch_frame components that might have device issues\n",
    "    def move_torch_frame_components_to_device(module, device):\n",
    "        \"\"\"Recursively move torch_frame components to device\"\"\"\n",
    "        for name, child in module.named_children():\n",
    "            if hasattr(child, 'fill_values') and isinstance(child.fill_values, torch.Tensor):\n",
    "                child.fill_values = child.fill_values.to(device)\n",
    "            if hasattr(child, 'embedding_table') and isinstance(child.embedding_table, torch.Tensor):\n",
    "                child.embedding_table = child.embedding_table.to(device)\n",
    "            # Recursively apply to children\n",
    "            move_torch_frame_components_to_device(child, device)\n",
    "    \n",
    "    # Apply device fix to the model\n",
    "    move_torch_frame_components_to_device(model, device)\n",
    "    \n",
    "    print(f\"✓ All model components moved to {device}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def move_batch_to_device(batch, device):\n",
    "    \"\"\"\n",
    "    Move a batch of data to the specified device.\n",
    "    \n",
    "    Args:\n",
    "        batch: Batch data (can be tuple, list, tensor, or TensorFrame)\n",
    "        device: Target device\n",
    "    \n",
    "    Returns:\n",
    "        batch: Batch moved to device\n",
    "    \"\"\"\n",
    "    if isinstance(batch, (list, tuple)):\n",
    "        return type(batch)(move_batch_to_device(item, device) for item in batch)\n",
    "    elif isinstance(batch, torch.Tensor):\n",
    "        return batch.to(device)\n",
    "    elif hasattr(batch, 'to'):  # For TensorFrame and similar objects\n",
    "        return batch.to(device)\n",
    "    else:\n",
    "        return batch\n",
    "\n",
    "def load_flow_matching_model_with_weights(checkpoint_path=None, auto_find_best=True):\n",
    "    \"\"\"\n",
    "    Load and initialize the flow matching model with the specified configuration and weights.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Specific path to checkpoint directory (optional)\n",
    "        auto_find_best: If True, automatically find the best checkpoint (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, args, loaders, checkpoint_info)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data with flow matching config\n",
    "    flow_args = flow_matching_config\n",
    "    print(\"Loading data for Flow Matching model...\")\n",
    "    \n",
    "    train_data_fm, train_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'train'\n",
    "    )\n",
    "    vali_data_fm, vali_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'val'\n",
    "    )\n",
    "    test_data_fm, test_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, False, 'test'\n",
    "    )\n",
    "    \n",
    "    # Initialize Flow Matching model\n",
    "    print(\"Initializing Time Series Flow Matching Model...\")\n",
    "    flow_matching_model = TimeSeriesFlowMatchingModel(flow_args, train_loader_fm, vali_loader_fm, test_loader_fm)\n",
    "    \n",
    "    checkpoint_info = {}\n",
    "    \n",
    "    # Load weights if specified\n",
    "    if checkpoint_path or auto_find_best:\n",
    "        if auto_find_best and not checkpoint_path:\n",
    "            print(\"\\nFinding best checkpoint...\")\n",
    "            checkpoint_path, best_metric, run_name = find_best_checkpoint()\n",
    "            checkpoint_info = {\n",
    "                'path': checkpoint_path,\n",
    "                'val_loss': best_metric,\n",
    "                'run_name': run_name\n",
    "            }\n",
    "        \n",
    "        if checkpoint_path:\n",
    "            print(f\"\\nLoading weights from checkpoint...\")\n",
    "            flow_matching_model = load_deepspeed_checkpoint(flow_matching_model, checkpoint_path)\n",
    "            if not checkpoint_info:\n",
    "                checkpoint_info = {'path': checkpoint_path}\n",
    "        else:\n",
    "            print(\"No checkpoint found to load.\")\n",
    "    \n",
    "    print(\"✓ Flow Matching model loaded successfully!\")\n",
    "    print(f\"  - Model type: {flow_args.model}\")\n",
    "    print(f\"  - Generative model: {flow_args.generative_model}\")\n",
    "    print(f\"  - ODE Solver: {flow_args.ode_solver}\")\n",
    "    print(f\"  - Timesteps: {flow_args.timesteps}\")\n",
    "    print(f\"  - Batch size: {flow_args.batch_size}\")\n",
    "    print(f\"  - Learning rate: {flow_args.learning_rate}\")\n",
    "    print(f\"  - MoE enabled: {flow_args.use_moe}\")\n",
    "    print(f\"  - Covariates enabled: {flow_args.enable_covariates}\")\n",
    "    print(f\"  - Model dimensions: d_model={flow_args.d_model}, d_ff={flow_args.d_ff}\")\n",
    "    print(f\"  - Sequence lengths: seq_len={flow_args.seq_len}, pred_len={flow_args.pred_len}\")\n",
    "    \n",
    "    if checkpoint_info:\n",
    "        print(f\"\\nCheckpoint info:\")\n",
    "        if 'run_name' in checkpoint_info:\n",
    "            print(f\"  - Run: {checkpoint_info['run_name']}\")\n",
    "        if 'val_loss' in checkpoint_info:\n",
    "            print(f\"  - Validation Loss: {checkpoint_info['val_loss']:.4f}\")\n",
    "        print(f\"  - Path: {checkpoint_info['path']}\")\n",
    "    \n",
    "    print(f\"\\n📝 Usage Tips:\")\n",
    "    print(f\"  - Use model.eval() before inference\")\n",
    "    print(f\"  - Move data to device: batch = move_batch_to_device(batch, model.device)\")\n",
    "    print(f\"  - For sampling: model.sample_step(batch, batch_idx)\")\n",
    "    \n",
    "    return flow_matching_model, flow_args, (train_loader_fm, vali_loader_fm, test_loader_fm), checkpoint_info\n",
    "\n",
    "def load_flow_matching_model():\n",
    "    \"\"\"Load and initialize the flow matching model with the specified configuration (without weights).\"\"\"\n",
    "    \n",
    "    # Load data with flow matching config\n",
    "    flow_args = flow_matching_config\n",
    "    print(\"Loading data for Flow Matching model...\")\n",
    "    \n",
    "    train_data_fm, train_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'train'\n",
    "    )\n",
    "    vali_data_fm, vali_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'val'\n",
    "    )\n",
    "    test_data_fm, test_loader_fm, flow_args = data_provider(\n",
    "        flow_args, flow_args.data_pretrain, flow_args.data_path_pretrain, True, 'test'\n",
    "    )\n",
    "    \n",
    "    # Initialize Flow Matching model\n",
    "    print(\"Initializing Time Series Flow Matching Model...\")\n",
    "    flow_matching_model = TimeSeriesFlowMatchingModel(flow_args, train_loader_fm, vali_loader_fm, test_loader_fm)\n",
    "    \n",
    "    print(\"✓ Flow Matching model loaded successfully!\")\n",
    "    print(f\"  - Model type: {flow_args.model}\")\n",
    "    print(f\"  - Generative model: {flow_args.generative_model}\")\n",
    "    print(f\"  - ODE Solver: {flow_args.ode_solver}\")\n",
    "    print(f\"  - Timesteps: {flow_args.timesteps}\")\n",
    "    print(f\"  - Batch size: {flow_args.batch_size}\")\n",
    "    print(f\"  - Learning rate: {flow_args.learning_rate}\")\n",
    "    print(f\"  - MoE enabled: {flow_args.use_moe}\")\n",
    "    print(f\"  - Covariates enabled: {flow_args.enable_covariates}\")\n",
    "    print(f\"  - Model dimensions: d_model={flow_args.d_model}, d_ff={flow_args.d_ff}\")\n",
    "    print(f\"  - Sequence lengths: seq_len={flow_args.seq_len}, pred_len={flow_args.pred_len}\")\n",
    "    \n",
    "    return flow_matching_model, flow_args, (train_loader_fm, vali_loader_fm, test_loader_fm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for Flow Matching model...\n",
      "Mean: [7.93461185e+01 6.53019535e+00 1.44037396e-02 1.44911487e+02]\n",
      "Std: [20.41707644 20.84327263  0.27630121 55.13396884]\n",
      "Loading data into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [7.93461185e+01 6.53019535e+00 1.44037396e-02 1.44911487e+02]\n",
      "Std: [20.41707644 20.84327263  0.27630121 55.13396884]\n",
      "Loading data into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [7.93461185e+01 6.53019535e+00 1.44037396e-02 1.44911487e+02]\n",
      "Std: [20.41707644 20.84327263  0.27630121 55.13396884]\n",
      "Loading data into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Time Series Flow Matching Model...\n",
      "\n",
      "Loading weights from checkpoint...\n",
      "Loading DeepSpeed checkpoint from: /home/yl2428/logs/ns_Transformer/flow_matching/rose-meadow-390/checkpoints/epoch=21-step=25058-val_loss=2.8174.ckpt/checkpoint\n",
      "Loading model states from: /home/yl2428/logs/ns_Transformer/flow_matching/rose-meadow-390/checkpoints/epoch=21-step=25058-val_loss=2.8174.ckpt/checkpoint/mp_rank_00_model_states.pt\n",
      "Using device: cuda\n",
      "✓ Model weights loaded successfully!\n",
      "✓ All model components moved to cuda\n",
      "✓ Flow Matching model loaded successfully!\n",
      "  - Model type: ns_Transformer\n",
      "  - Generative model: flow_matching\n",
      "  - ODE Solver: dopri5\n",
      "  - Timesteps: 50\n",
      "  - Batch size: 256\n",
      "  - Learning rate: 0.0001\n",
      "  - MoE enabled: 1\n",
      "  - Covariates enabled: 1\n",
      "  - Model dimensions: d_model=32, d_ff=256\n",
      "  - Sequence lengths: seq_len=72, pred_len=64\n",
      "\n",
      "Checkpoint info:\n",
      "  - Path: /home/yl2428/logs/ns_Transformer/flow_matching/rose-meadow-390/checkpoints/epoch=21-step=25058-val_loss=2.8174.ckpt/checkpoint\n",
      "\n",
      "📝 Usage Tips:\n",
      "  - Use model.eval() before inference\n",
      "  - Move data to device: batch = move_batch_to_device(batch, model.device)\n",
      "  - For sampling: model.sample_step(batch, batch_idx)\n",
      "\n",
      "Model summary:\n",
      "Flow matching model has 1684033 parameters\n",
      "Condition prediction model has 808848 parameters\n"
     ]
    }
   ],
   "source": [
    "# model, args, loaders, checkpoint_info = load_flow_matching_model_with_weights(checkpoint_path=\"/home/yl2428/logs/ns_Transformer/flow_matching/lilac-aardvark-389/checkpoints/epoch=9-step=23070-val_loss=1.8386.ckpt/checkpoint\")\n",
    "# model, args, loaders, checkpoint_info = load_flow_matching_model_with_weights(checkpoint_path=\"/home/yl2428/logs/ns_Transformer/flow_matching/lilac-aardvark-389/checkpoints/epoch=14-step=34605-val_loss=1.8891.ckpt/checkpoint\")\n",
    "model, args, loaders, checkpoint_info = load_flow_matching_model_with_weights(checkpoint_path=\"/home/yl2428/logs/ns_Transformer/flow_matching/rose-meadow-390/checkpoints/epoch=21-step=25058-val_loss=2.8174.ckpt/checkpoint\")\n",
    "train_loader, val_loader, test_loader = loaders\n",
    "\n",
    "print(\"\\nModel summary:\")\n",
    "print(f\"Flow matching model has {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(f\"Condition prediction model has {sum(p.numel() for p in model.cond_pred_model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeSeriesFlowMatchingModel(\n",
       "  (model): Model(\n",
       "    (flow_model): ConditionalVelocityModel(\n",
       "      (lin1): ConditionalLinear(\n",
       "        (lin): Linear(in_features=2, out_features=128, bias=True)\n",
       "        (embed): Embedding(51, 128)\n",
       "        (cov_projection): Linear(in_features=32, out_features=128, bias=True)\n",
       "      )\n",
       "      (lin2): ConditionalLinear(\n",
       "        (lin): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (embed): Embedding(51, 128)\n",
       "        (cov_projection): Linear(in_features=32, out_features=128, bias=True)\n",
       "      )\n",
       "      (lin3): ConditionalLinear(\n",
       "        (lin): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (embed): Embedding(51, 128)\n",
       "        (cov_projection): Linear(in_features=32, out_features=128, bias=True)\n",
       "      )\n",
       "      (lin4): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (enc_embedding): DataEmbedding(\n",
       "      (value_embedding): TokenEmbedding(\n",
       "        (tokenConv): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "      (position_embedding): PositionalEmbedding()\n",
       "      (temporal_embedding): TimeFeatureEmbedding(\n",
       "        (embed): Linear(in_features=5, out_features=32, bias=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (cond_pred_model): Model(\n",
       "    (enc_embedding): DataEmbedding(\n",
       "      (value_embedding): TokenEmbedding(\n",
       "        (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "      (position_embedding): PositionalEmbedding()\n",
       "      (temporal_embedding): TimeFeatureEmbedding(\n",
       "        (embed): Linear(in_features=5, out_features=32, bias=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (dec_embedding): DataEmbedding(\n",
       "      (value_embedding): TokenEmbedding(\n",
       "        (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "      (position_embedding): PositionalEmbedding()\n",
       "      (temporal_embedding): TimeFeatureEmbedding(\n",
       "        (embed): Linear(in_features=5, out_features=32, bias=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (ts_cov_encoder): TimeSeriesCovariateEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Conv1d(3, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(8, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      )\n",
       "      (batch_norms): ModuleList(\n",
       "        (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (global_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (projection): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_layers): ModuleList()\n",
       "    (moe_layers): ModuleDict(\n",
       "      (0): MixtureOfExperts(\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x ExpertNetwork(\n",
       "            (expert_encoder): Encoder(\n",
       "              (attn_layers): ModuleList(\n",
       "                (0-1): 2 x EncoderLayer(\n",
       "                  (attention): AttentionLayer(\n",
       "                    (inner_attention): DSAttention(\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  )\n",
       "                  (conv1): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
       "                  (conv2): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (expert_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (specialized_router): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=16, out_features=7, bias=True)\n",
       "          (4): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (1): MixtureOfExperts(\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x ExpertNetwork(\n",
       "            (expert_encoder): Encoder(\n",
       "              (attn_layers): ModuleList(\n",
       "                (0-1): 2 x EncoderLayer(\n",
       "                  (attention): AttentionLayer(\n",
       "                    (inner_attention): DSAttention(\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  )\n",
       "                  (conv1): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
       "                  (conv2): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (expert_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (specialized_router): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=16, out_features=7, bias=True)\n",
       "          (4): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (self_attention): AttentionLayer(\n",
       "            (inner_attention): DSAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (cross_attention): AttentionLayer(\n",
       "            (inner_attention): DSAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv1): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
       "          (conv2): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
       "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "    (tau_learner): Projector(\n",
       "      (series_conv): Conv1d(72, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      (backbone): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=64, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (delta_learner): Projector(\n",
       "      (series_conv): Conv1d(72, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      (backbone): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=64, out_features=72, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (z_mean): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (z_logvar): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (cov_encoder): Trompt(\n",
       "      (encoders): ModuleList(\n",
       "        (0-5): 6 x StypeWiseFeatureEncoder(\n",
       "          (encoder_dict): ModuleDict(\n",
       "            (categorical): EmbeddingEncoder(\n",
       "              (post_module): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (emb): Embedding(20, 32, padding_idx=0)\n",
       "            )\n",
       "            (numerical): LinearEncoder(\n",
       "              (post_module): Sequential(\n",
       "                (0): ReLU()\n",
       "                (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (trompt_convs): ModuleList(\n",
       "        (0-5): 6 x TromptConv(\n",
       "          (lin): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (group_norm): GroupNorm(2, 128, eps=1e-05, affine=True)\n",
       "          (layer_norm_e_column): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm_e_prompt): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (trompt_decoder): TromptDecoder(\n",
       "        (lin_attn): Linear(in_features=32, out_features=1, bias=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (z_out): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (covariate_fusion): Sequential(\n",
       "      (0): Linear(in_features=224, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cond_pred_model_train): Model(\n",
       "    (enc_embedding): DataEmbedding(\n",
       "      (value_embedding): TokenEmbedding(\n",
       "        (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "      (position_embedding): PositionalEmbedding()\n",
       "      (temporal_embedding): TimeFeatureEmbedding(\n",
       "        (embed): Linear(in_features=5, out_features=32, bias=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (dec_embedding): DataEmbedding(\n",
       "      (value_embedding): TokenEmbedding(\n",
       "        (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "      (position_embedding): PositionalEmbedding()\n",
       "      (temporal_embedding): TimeFeatureEmbedding(\n",
       "        (embed): Linear(in_features=5, out_features=32, bias=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (ts_cov_encoder): TimeSeriesCovariateEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Conv1d(3, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(8, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      )\n",
       "      (batch_norms): ModuleList(\n",
       "        (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (global_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "      (projection): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_layers): ModuleList()\n",
       "    (moe_layers): ModuleDict(\n",
       "      (0): MixtureOfExperts(\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x ExpertNetwork(\n",
       "            (expert_encoder): Encoder(\n",
       "              (attn_layers): ModuleList(\n",
       "                (0-1): 2 x EncoderLayer(\n",
       "                  (attention): AttentionLayer(\n",
       "                    (inner_attention): DSAttention(\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  )\n",
       "                  (conv1): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
       "                  (conv2): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (expert_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (specialized_router): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=16, out_features=7, bias=True)\n",
       "          (4): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (1): MixtureOfExperts(\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x ExpertNetwork(\n",
       "            (expert_encoder): Encoder(\n",
       "              (attn_layers): ModuleList(\n",
       "                (0-1): 2 x EncoderLayer(\n",
       "                  (attention): AttentionLayer(\n",
       "                    (inner_attention): DSAttention(\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  )\n",
       "                  (conv1): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
       "                  (conv2): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
       "                  (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (expert_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (specialized_router): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=16, out_features=7, bias=True)\n",
       "          (4): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (self_attention): AttentionLayer(\n",
       "            (inner_attention): DSAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (cross_attention): AttentionLayer(\n",
       "            (inner_attention): DSAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv1): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
       "          (conv2): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
       "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "    (tau_learner): Projector(\n",
       "      (series_conv): Conv1d(72, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      (backbone): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=64, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (delta_learner): Projector(\n",
       "      (series_conv): Conv1d(72, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      (backbone): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=64, out_features=72, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (z_mean): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (z_logvar): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (cov_encoder): Trompt(\n",
       "      (encoders): ModuleList(\n",
       "        (0-5): 6 x StypeWiseFeatureEncoder(\n",
       "          (encoder_dict): ModuleDict(\n",
       "            (categorical): EmbeddingEncoder(\n",
       "              (post_module): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (emb): Embedding(20, 32, padding_idx=0)\n",
       "            )\n",
       "            (numerical): LinearEncoder(\n",
       "              (post_module): Sequential(\n",
       "                (0): ReLU()\n",
       "                (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (trompt_convs): ModuleList(\n",
       "        (0-5): 6 x TromptConv(\n",
       "          (lin): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (group_norm): GroupNorm(2, 128, eps=1e-05, affine=True)\n",
       "          (layer_norm_e_column): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm_e_prompt): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (trompt_decoder): TromptDecoder(\n",
       "        (lin_attn): Linear(in_features=32, out_features=1, bias=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (z_out): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (covariate_fusion): Sequential(\n",
       "      (0): Linear(in_features=224, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='cuda',\n",
    "    devices=1, precision='64')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myl2428\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yl2428/Time-LLM/wandb/run-20250604_152323-9lea7tw1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yl2428/ns_Transformer/runs/9lea7tw1' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/yl2428/ns_Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yl2428/ns_Transformer' target=\"_blank\">https://wandb.ai/yl2428/ns_Transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yl2428/ns_Transformer/runs/9lea7tw1' target=\"_blank\">https://wandb.ai/yl2428/ns_Transformer/runs/9lea7tw1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 5090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   5%|▌         | 1/20 [00:55<17:35,  0.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:817\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    814\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    816\u001b[0m )\n\u001b[0;32m--> 817\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1049\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating:\n\u001b[0;32m-> 1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:145\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:437\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    432\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    436\u001b[0m )\n\u001b[0;32m--> 437\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:425\u001b[0m, in \u001b[0;36mStrategy.test_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Time-LLM/models/time_series_flow_matching_model.py:239\u001b[0m, in \u001b[0;36mTimeSeriesFlowMatchingModel.test_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Time-LLM/models/time_series_flow_matching_model.py:176\u001b[0m, in \u001b[0;36mTimeSeriesFlowMatchingModel.sample_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mflow_config\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39mn_z_samples_depart):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Use flow matching sampling with ODE solver\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     y_tile_seq \u001b[38;5;241m=\u001b[39m \u001b[43msample_flow_matching\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_tile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mark_tile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_0_hat_tile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_T_mean_tile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdopri5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcov_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_embedding_tile\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# Since we now only output glucose channels (1 channel), not c_out\u001b[39;00m\n",
      "File \u001b[0;32m~/Time-LLM/models/model9_NS_transformer/flow_matching_models/flow_matching_utils.py:142\u001b[0m, in \u001b[0;36msample_flow_matching\u001b[0;34m(model, x, x_mark, y_0_hat, y_T_mean, num_timesteps, solver, rtol, atol, cov_embedding)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 142\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mode_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Return final state (at t=0)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py:80\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py:34\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 34\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:246\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:311\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:70\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (alpha_i, beta_i) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tableau\u001b[38;5;241m.\u001b[39malpha, tableau\u001b[38;5;241m.\u001b[39mbeta)):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alpha_i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.\u001b[39m:\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;66;03m# Always step to perturbing just before the end time, in case of discontinuities.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m         ti \u001b[38;5;241m=\u001b[39m t1\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mns_Transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:775\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/cDIME/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"ns_Transformer\", name=\"test\")\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/checkpoints_1.pt')\n",
    "# turn into double\n",
    "for key in state_dict.keys():\n",
    "    state_dict[key] = state_dict[key].double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_outputs[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_outputs[0]['batch_x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.sample_outputs, '/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/sample_outputs_May11.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_outputs = torch.load('/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/sample_outputs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import stype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = model.sample_outputs[0]['batch']\n",
    "batch_x, batch_y, batch_x_mark, batch_y_mark = batch[0]\n",
    "batch_cov = batch[1]\n",
    "# with torch.no_grad():\n",
    "#     new_batch_x = batch_x.clone()\n",
    "#     new_batch_x[53, :, 1] = batch_x[53, :, 1].min()\n",
    "#     model.eval()\n",
    "#     new_batch = [None, None]\n",
    "#     new_batch[0] = new_batch_x, batch_y, batch_x_mark, batch_y_mark\n",
    "#     new_batch[1] = batch_cov\n",
    "#     model.sample_step(new_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([220., 122., 160., 131., 160., 187., 181., 215., 224., 134., 165., 152.,\n",
       "        152., 134., 193., 193., 193., 135., 220., 176., 210., 113., 170., 187.,\n",
       "        150., 152., 127., 152., 187., 220., 220., 180., 185., 108., 127., 122.,\n",
       "        131., 224., 220., 131., 185., 176., 161., 200., 132., 180., 131., 110.,\n",
       "        170., 113., 170., 220., 152., 140., 215., 135., 185., 110., 122., 176.,\n",
       "        135., 168., 168., 170., 145., 168., 187., 127., 241., 150., 176., 165.,\n",
       "        150., 127., 185., 165., 135., 241., 135., 142., 110., 215., 185., 127.,\n",
       "        150., 150., 140., 113., 127., 145., 122., 187., 215., 165., 110., 154.,\n",
       "        185., 220., 127., 135., 220., 135., 110., 215., 134., 220., 180., 185.,\n",
       "        113., 165., 170., 195., 176., 176., 168., 122., 130., 131., 176., 110.,\n",
       "        193., 220., 140., 185., 185., 183., 185., 220., 220., 127., 142., 235.,\n",
       "        215., 150., 134., 193., 168., 113., 127., 187., 140., 220., 150., 193.,\n",
       "        145., 135., 165., 127., 180., 122., 220., 145., 180., 185., 180., 110.,\n",
       "        134., 200., 152., 176., 224., 145., 176., 168., 220., 187., 127., 152.,\n",
       "        168., 113., 176., 127., 185., 180., 165., 176., 134., 135., 187., 142.,\n",
       "        241., 150., 168., 135., 193., 164., 145., 176., 127., 224., 122., 165.,\n",
       "        155., 108., 170., 193., 131., 176., 187., 180., 220., 176., 168., 181.,\n",
       "        200., 224., 145., 168., 127., 122., 135., 152., 220., 180., 152., 131.,\n",
       "        220., 181., 185., 170., 135., 152., 113., 135., 168., 168., 168., 180.,\n",
       "        235., 193., 165., 150., 215., 215., 152., 127., 135., 195., 145., 127.,\n",
       "        165., 220., 193., 193., 150., 180., 224., 152., 160., 152., 176., 127.,\n",
       "        145., 193., 134., 142.], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_cov.feat_dict[stype.numerical][:,4 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.sample_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def plot_time_series_with_ci(groundtruth, sampled_output, cov, batch_x=None, num_series=5):\n",
    "    fig, axes = plt.subplots(num_series, 1, figsize=(12, 6*num_series), sharex=True)\n",
    "    if num_series == 1:\n",
    "        axes = [axes]\n",
    "    idx_list = [53, 11, 19]  # Adjust or randomize this list as needed\n",
    "    for i in range(num_series):\n",
    "        # Randomly select a time series from the batch\n",
    "        idx = idx_list[i]\n",
    "        hba1c = cov.feat_dict[stype.numerical][idx, 3]\n",
    "        diabetes_onset = cov.feat_dict[stype.numerical][idx, 1]\n",
    "        weight = cov.feat_dict[stype.numerical][idx, 4]\n",
    "        \n",
    "        if batch_x is not None:\n",
    "            # Extract previous glucose values\n",
    "            previous_glucose = batch_x[idx, :, -1].cpu().numpy()\n",
    "            hr = batch_x[idx, :, 0] * 20.41707644 + 7.93461185e+01\n",
    "            steps = batch_x[idx, :, 1] * 20.84327263 +  6.53019535e+00\n",
    "            print(steps)\n",
    "            hr_mean = np.mean(hr.cpu().numpy())\n",
    "            steps_mean = np.sum(steps.cpu().numpy())\n",
    "            \n",
    "            # Concatenate previous glucose with groundtruth and mean predictions\n",
    "            full_groundtruth = np.concatenate([previous_glucose, groundtruth[idx, :, -1]])\n",
    "        \n",
    "        else:\n",
    "            full_groundtruth = groundtruth[idx, :, -1].cpu().numpy()\n",
    "\n",
    "        # Plot ground truth (concatenated)\n",
    "        axes[i].plot(full_groundtruth, color='#1f77b4', label='Ground Truth (with previous)', lw=2)\n",
    "        \n",
    "        # Add textual information\n",
    "        axes[i].text(0, 2.8, f'idx: {idx}, hba1c: {hba1c.cpu().numpy():.2f}, diabetes_onset: {diabetes_onset.cpu().numpy():.2f}, weight: {weight.cpu().numpy():.2f}, steps: {steps_mean:.2f}', \n",
    "                     fontsize=12, color='black', bbox=dict(facecolor='white', alpha=0.5))\n",
    "        \n",
    "        # Calculate mean and confidence interval for predicted values\n",
    "        mean = np.mean(sampled_output[idx, :, :, 0], axis=0)\n",
    "        ci_lower = np.percentile(sampled_output[idx, :, :, 0], 80, axis=0)\n",
    "        ci_upper = np.percentile(sampled_output[idx, :, :, 0], 20, axis=0)\n",
    "        \n",
    "        # Smooth the CI with a moving average\n",
    "        ci_lower_smooth = uniform_filter1d(ci_lower, size=5)\n",
    "        ci_upper_smooth = uniform_filter1d(ci_upper, size=5)\n",
    "        \n",
    "        # Concatenate previous glucose with predicted mean and CI\n",
    "        full_mean = np.concatenate([previous_glucose, mean])\n",
    "        full_ci_lower = np.concatenate([previous_glucose, ci_lower_smooth])\n",
    "        full_ci_upper = np.concatenate([previous_glucose, ci_upper_smooth])\n",
    "        \n",
    "        # Plot mean prediction (concatenated)\n",
    "        axes[i].plot(full_mean, color='#ff7f0e', label='Mean Prediction (with previous)', lw=2)\n",
    "        \n",
    "        # Plot confidence interval (concatenated)\n",
    "        axes[i].fill_between(range(full_mean.shape[0]), full_ci_lower, full_ci_upper, color='#ff7f0e', alpha=0.3, label='95% CI')\n",
    "        \n",
    "        axes[i].set_title(f'Time Series {i+1}', fontsize=14)\n",
    "        axes[i].set_xlabel('Time Step', fontsize=12)\n",
    "        axes[i].set_ylabel('Value', fontsize=12)\n",
    "        \n",
    "        # Set y limit to be the same for all plots\n",
    "        axes[i].set_ylim([-3, 3])\n",
    "        axes[i].legend(loc='upper right', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.savefig('time_series_with_ci.pdf')\n",
    "    plt.show()\n",
    "\n",
    "# Sample invocation of the function with your data\n",
    "# plot_time_series_with_ci(groundtruth, sampled_output, cov, num_series=5)\n",
    "\n",
    "j = 0\n",
    "groundtruth_to_plot = model.sample_outputs[j]['true']\n",
    "sampled_output_to_plot = model.sample_outputs[j]['pred']\n",
    "cov_to_plot = model.sample_outputs[j]['batch_cov']\n",
    "batch_x_to_plot = model.sample_outputs[j]['batch_x']\n",
    "# Call the function to plot 2 random time series\n",
    "plot_time_series_with_ci(groundtruth_to_plot, sampled_output_to_plot, cov_to_plot, batch_x_to_plot, num_series=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specific slice you intend to modify\n",
    "original_tensor_slice = batch_cov_orig.feat_dict[stype.numerical][:, 3]\n",
    "modified_slice = original_tensor_slice.clone() * 1.1\n",
    "batch_cov_orig.feat_dict[stype.numerical][:, 3] = modified_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch_x\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_x' is not defined"
     ]
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_frame import stype # Ensure this is consistent with how stype is used/imported earlier\n",
    "\n",
    "# Ensure 'model' is loaded and model.sample_outputs is populated from previous cells.\n",
    "# For example, if needed:\n",
    "# model.sample_outputs = torch.load('/gpfs/gibbs/pi/gerstein/yl2428/logs/ns_Transformer/desert-sweep-6/checkpoints/sample_outputs.pt')\n",
    "\n",
    "def perturb_hba1c_covariates(batch_cov, individual_indices, percentage_increase):\n",
    "    \"\"\"\n",
    "    Perturbs HBA1c for specified individuals in the batch_cov.\n",
    "    HBA1c is assumed to be at index 3 of the numerical features based on notebook analysis.\n",
    "    Input batch_cov is expected to be a torch_frame.MaterializedFrame object or similar.\n",
    "    Returns a new batch_cov object with perturbations; does not modify the input object.\n",
    "    \"\"\"\n",
    "    if stype.numerical not in batch_cov.feat_dict:\n",
    "        print(f\"Warning: stype.numerical ('{stype.numerical}') not found in batch_cov.feat_dict. Returning original batch_cov.\")\n",
    "        return batch_cov\n",
    "\n",
    "    # Clone the numerical features tensor to ensure modifications do not affect the original batch_cov\n",
    "    original_numerical_tensor = batch_cov.feat_dict[stype.numerical]\n",
    "    perturbed_numerical_tensor = original_numerical_tensor.clone()\n",
    "    \n",
    "    for idx in individual_indices:\n",
    "        if 0 <= idx < perturbed_numerical_tensor.shape[0]:\n",
    "            # Modify the cloned tensor\n",
    "            current_hba1c_val = perturbed_numerical_tensor[idx, 3]\n",
    "            perturbed_numerical_tensor[idx, 3] = current_hba1c_val * (1 + percentage_increase / 100.0)\n",
    "            # print(f\"Individual {idx}: HbA1c changed from {current_hba1c_val.item():.2f} to {perturbed_numerical_tensor[idx, 3].item():.2f}\")\n",
    "        else:\n",
    "            print(f\"Warning: Index {idx} is out of bounds for numerical_feats (shape: {perturbed_numerical_tensor.shape}). Skipping perturbation for this index.\")\n",
    "            \n",
    "    from copy import deepcopy\n",
    "    new_feat_dict = deepcopy(batch_cov) \n",
    "    # \n",
    "    new_feat_dict.feat_dict[stype.numerical] = perturbed_numerical_tensor\n",
    "    \n",
    "    # Prepare arguments for constructing the new frame object.\n",
    "    # It's important to pass all necessary attributes from the original batch_cov\n",
    "    # that are required by its constructor (e.g., col_names_dict, col_stats).\n",
    "    \n",
    "    return new_feat_dict\n",
    "\n",
    "\n",
    "def perturb_weight_covariates(batch_cov, individual_indices, percentage_increase):\n",
    "    \"\"\"\n",
    "    Perturbs HBA1c for specified individuals in the batch_cov.\n",
    "    HBA1c is assumed to be at index 3 of the numerical features based on notebook analysis.\n",
    "    Input batch_cov is expected to be a torch_frame.MaterializedFrame object or similar.\n",
    "    Returns a new batch_cov object with perturbations; does not modify the input object.\n",
    "    \"\"\"\n",
    "    if stype.numerical not in batch_cov.feat_dict:\n",
    "        print(f\"Warning: stype.numerical ('{stype.numerical}') not found in batch_cov.feat_dict. Returning original batch_cov.\")\n",
    "        return batch_cov\n",
    "\n",
    "    # Clone the numerical features tensor to ensure modifications do not affect the original batch_cov\n",
    "    original_numerical_tensor = batch_cov.feat_dict[stype.numerical]\n",
    "    perturbed_numerical_tensor = original_numerical_tensor.clone()\n",
    "    \n",
    "    for idx in individual_indices:\n",
    "        if 0 <= idx < perturbed_numerical_tensor.shape[0]:\n",
    "            # Modify the cloned tensor\n",
    "            current_hba1c_val = perturbed_numerical_tensor[idx, 4]\n",
    "            perturbed_numerical_tensor[idx, 4] = current_hba1c_val * (1 + percentage_increase / 100.0)\n",
    "            # print(f\"Individual {idx}: HbA1c changed from {current_hba1c_val.item():.2f} to {perturbed_numerical_tensor[idx, 3].item():.2f}\")\n",
    "        else:\n",
    "            print(f\"Warning: Index {idx} is out of bounds for numerical_feats (shape: {perturbed_numerical_tensor.shape}). Skipping perturbation for this index.\")\n",
    "            \n",
    "    from copy import deepcopy\n",
    "    new_feat_dict = deepcopy(batch_cov) \n",
    "    # \n",
    "    new_feat_dict.feat_dict[stype.numerical] = perturbed_numerical_tensor\n",
    "    \n",
    "    # Prepare arguments for constructing the new frame object.\n",
    "    # It's important to pass all necessary attributes from the original batch_cov\n",
    "    # that are required by its constructor (e.g., col_names_dict, col_stats).\n",
    "    \n",
    "    return new_feat_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original batch size: 256\n",
      "Randomly selected individuals to perturb (indices): [206, 219, 161, 139, 70, 63, 224, 162, 8, 113, 121, 147, 16, 80, 69, 75, 245, 19, 233, 227, 41, 42, 212, 13, 190, 26, 172, 183, 140, 240, 232, 136, 211, 174, 119, 29, 51, 154, 248, 112, 163, 213, 71, 134, 86, 171, 95, 204, 101, 177, 28, 56, 62, 118, 246, 120, 220, 165, 138, 208, 202, 239, 72, 34, 214, 1, 5, 137, 58, 49, 43, 250, 102, 109, 148, 167, 94, 255, 66, 225, 251, 238, 21, 44, 149, 115, 196, 181, 35, 253, 182, 207, 68, 111, 45, 198, 192, 157, 194, 193, 27, 88, 2, 170, 143, 226, 90, 205, 222, 129, 23, 110, 83, 24, 25, 235, 164, 40, 93, 52, 180, 20, 199, 7, 87, 223, 11, 175, 6, 128, 74, 179, 131, 53, 22, 124, 195, 14, 4, 0, 122, 185, 117, 76, 254, 65, 61, 166, 241, 30, 32, 216, 144, 159, 234, 145, 55, 150, 229, 67, 48, 173, 215, 236, 247, 200, 133, 3, 77, 203, 64, 244, 125, 187, 168, 114, 126, 191, 237, 127, 242, 103, 100, 36, 73, 108, 230, 231, 47, 135, 132, 141, 249, 156, 189, 84, 10, 107, 105, 106, 218, 221, 186, 92, 50, 123, 46, 96, 151, 89, 97, 9, 17, 210, 209, 82, 98, 54, 37, 33, 153, 60, 152, 31, 18, 38, 12, 169, 155, 79, 176, 158, 252, 243, 39, 130, 116, 78, 201, 217, 91, 57, 160, 81, 142, 197, 99, 228, 146, 85, 184, 178, 59, 15, 104, 188]\n",
      "Shape of original sampled output (glucose only): (256, 100, 64)\n",
      "Shape of perturbed sampled output (glucose only): (256, 100, 64, 1)\n",
      "Individual 206: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 219: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 161: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 139: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 70: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 63: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 224: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 162: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 8: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 113: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 121: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 147: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 16: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 80: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 69: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 75: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 245: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 19: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 233: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 227: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 41: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 42: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 212: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 13: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 190: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 26: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 172: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 183: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 140: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 240: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 232: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 136: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 211: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 174: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 119: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 29: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 51: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 154: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 248: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 112: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 163: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 213: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 71: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 134: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 86: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 171: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 95: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 204: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 101: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 177: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 28: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 56: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 62: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 118: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 246: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 120: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 220: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 165: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 138: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 208: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 202: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 239: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 72: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 34: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 214: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 1: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 5: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 137: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 58: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 49: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 43: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 250: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 102: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 109: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 148: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 167: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 94: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 255: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 66: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 225: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 251: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 238: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 21: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 44: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 149: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 115: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 196: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 181: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 35: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 253: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 182: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 207: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 68: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 111: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 45: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 198: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 192: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 157: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 194: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 193: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 27: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 88: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 2: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 170: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 143: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 226: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 90: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 205: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 222: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 129: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 23: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 110: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 83: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 24: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 25: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 235: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 164: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 40: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 93: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 52: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 180: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 20: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 199: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 7: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 87: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 223: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 11: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 175: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 6: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 128: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 74: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 179: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 131: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 53: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 22: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 124: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 195: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 14: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 4: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 0: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 122: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 185: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 117: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 76: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 254: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 65: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 61: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 166: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 241: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 30: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 32: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 216: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 144: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 159: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 234: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 145: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 55: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 150: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 229: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 67: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 48: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 173: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 215: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 236: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 247: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 200: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 133: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 3: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 77: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 203: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 64: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 244: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 125: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 187: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 168: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 114: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 126: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 191: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 237: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 127: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 242: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 103: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 100: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 36: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 73: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 108: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 230: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 231: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 47: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 135: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 132: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 141: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 249: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 156: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 189: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 84: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 10: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 107: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 105: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 106: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 218: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 221: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 186: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 92: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 50: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 123: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 46: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 96: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 151: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 89: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 97: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 9: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 17: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 210: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 209: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 82: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 98: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 54: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 37: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 33: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 153: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 60: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 152: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 31: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 18: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 38: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 12: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 169: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 155: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 79: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 176: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 158: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 252: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 243: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 39: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 130: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 116: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 78: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 201: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 217: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 91: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 57: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 160: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 81: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 142: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 197: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 99: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 228: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 146: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 85: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 184: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n",
      "Individual 178: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 59: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 15: Original HbA1c: 7.00, Perturbed HbA1c: 7.00\n",
      "Individual 104: Original HbA1c: 6.60, Perturbed HbA1c: 6.60\n",
      "Individual 188: Original HbA1c: 7.40, Perturbed HbA1c: 7.40\n"
     ]
    }
   ],
   "source": [
    "# --- Perturbation Analysis ---\n",
    "# Select a batch for analysis (e.g., the last one processed or a specific one)\n",
    "# If model.sample_outputs is a list of outputs from trainer.test:\n",
    "# Each element in model.sample_outputs would typically be a dictionary\n",
    "# from a single batch processed by test_step.\n",
    "# We'll use the last batch's data as an example.\n",
    "# You might need to adjust which batch or how data is selected based on your exact structure.\n",
    "model.cuda()\n",
    "if not model.sample_outputs:\n",
    "    print(\"Error: model.sample_outputs is empty. Please ensure the model has processed data and populated this list.\")\n",
    "else:\n",
    "    # Assuming the structure seen in the notebook: model.sample_outputs[i]['batch']\n",
    "    # and model.sample_outputs[i]['pred'] for predictions.\n",
    "    # We need an original batch to get 'batch_x', 'batch_y', 'batch_x_mark', 'batch_y_mark', and 'batch_cov'.\n",
    "    \n",
    "    # Let's use the data from the last entry in sample_outputs for perturbation\n",
    "    # This corresponds to the data used for the last plot in the notebook (j = -1)\n",
    "    # Or you can select a specific batch index, e.g., batch_index_to_perturb = 0\n",
    "    batch_index_to_perturb = 0 # Use the last batch by default\n",
    "    \n",
    "    original_batch_data_dict = model.sample_outputs[batch_index_to_perturb]\n",
    "    original_batch_tuple = original_batch_data_dict['batch'] # This is [ (batch_x, batch_y, batch_x_mark, batch_y_mark), batch_cov ]\n",
    "    \n",
    "    batch_x_orig, batch_y_orig, batch_x_mark_orig, batch_y_mark_orig = original_batch_tuple[0]\n",
    "    batch_cov_orig = original_batch_tuple[1]\n",
    "\n",
    "    # Get original predictions (samples before perturbation)\n",
    "    # These are the 'pred' values from the model's output for this original batch\n",
    "    # Assuming 'pred' stores the 50 samples: [batch_size, num_samples, pred_len, num_features]\n",
    "    # And we are interested in the glucose feature, which is the last one (index -1 or 3 for c_out=4)\n",
    "    sampled_output_before_perturb = original_batch_data_dict['pred'][..., -1] # Taking only glucose\n",
    "\n",
    "    num_individuals_in_batch = batch_x_orig.shape[0]\n",
    "    num_to_perturb = min(256, num_individuals_in_batch) # Perturb up to 3 individuals, or fewer if batch is small\n",
    "\n",
    "    # Randomly select individuals to perturb\n",
    "    # Ensure reproducibility if desired, by setting random.seed elsewhere or here for this specific selection\n",
    "    # random.seed(42) # for reproducibility of selection\n",
    "    individuals_to_perturb_indices = random.sample(range(num_individuals_in_batch), num_to_perturb)\n",
    "    print(f\"Original batch size: {num_individuals_in_batch}\")\n",
    "    print(f\"Randomly selected individuals to perturb (indices): {individuals_to_perturb_indices}\")\n",
    "\n",
    "    # Perturb HBA1c for the selected individuals\n",
    "    percentage_increase_hba1c = 20.0\n",
    "    batch_cov_perturbed = perturb_weight_covariates(batch_cov_orig, individuals_to_perturb_indices, percentage_increase_hba1c)\n",
    "\n",
    "    # Prepare the new batch for the model's sample_step or equivalent generation function\n",
    "    # The model.sample_step(batch, batch_idx) was used in the notebook\n",
    "    # We need to simulate how samples are generated or find the appropriate generation function.\n",
    "    # If model.sample_step appends to model.sample_outputs, we need to handle that.\n",
    "    # For now, let's assume we need to call a generation function.\n",
    "    # The `sample_step` in TimeSeriesDiffusionModel takes `batch` and `batch_idx`\n",
    "    # and seems to append to `self.sample_outputs`.\n",
    "    # To get samples for the perturbed data without altering `model.sample_outputs` from original runs,\n",
    "    # we might need to call a more direct sampling/prediction method of the model if available,\n",
    "    # or temporarily store and then restore `model.sample_outputs`.\n",
    "\n",
    "    # Let's try to get new samples.\n",
    "    # The model's `predict_step` or a similar generation function is needed.\n",
    "    # In TimeSeriesDiffusionModel, `sample_step` is used during `test_step` and it appends to `self.sample_outputs`.\n",
    "    # A more direct way to get samples would be to call `model.model.sample()` (for the inner diffusion model)\n",
    "    # or `model.cond_pred_model.predict()` if it's about conditional prediction.\n",
    "    # Given the existing notebook structure, `model.sample_step` is what was used to generate `model.sample_outputs`.\n",
    "\n",
    "    # To avoid confusion with previously stored sample_outputs, we will call a direct sampling method\n",
    "    # of the underlying diffusion model if possible.\n",
    "    # The TimeSeriesDiffusionModel has a `sample` method.\n",
    "    # Signature: sample(self, batch_x, batch_x_mark, batch_y_mark, N=50, cond_scale=0.)\n",
    "    \n",
    "    # We need to get cond from batch_cov_perturbed\n",
    "    # The model has `self.cond_pred_model.encode_cond(batch_cov)`\n",
    "    # And then uses this `cond` in its own `sample` method, which calls `self.model.sample`.\n",
    "    \n",
    "    model.eval() # Ensure model is in eval mode\n",
    "    with torch.no_grad():\n",
    "        # 1. Encode covariates to get the condition\n",
    "        # The `encode_cond` method might need the batch_cov on the correct device\n",
    "        device = batch_x_orig.device # Assuming batch_x_orig is already on the correct device\n",
    "        \n",
    "        # The covariates in batch_cov_perturbed need to be on the same device as the model\n",
    "        # Typically, the data loader handles this. Here we do it manually if needed.\n",
    "        # Assuming batch_cov_perturbed.feat_dict[stype.numerical] is a tensor.\n",
    "        \n",
    "        # Create a new batch structure for the perturbed data\n",
    "        perturbed_batch_for_sampling = [\n",
    "            (batch_x_orig.to(device), batch_y_orig.to(device), batch_x_mark_orig.to(device), batch_y_mark_orig.to(device)), # Original x, y, x_mark, y_mark\n",
    "            batch_cov_perturbed # Perturbed covariates\n",
    "        ]\n",
    "\n",
    "        model.sample_step(perturbed_batch_for_sampling , 0)\n",
    "    \n",
    "    sampled_output_after_perturb = model.sample_outputs[-1]['pred']\n",
    "\n",
    "    print(f\"Shape of original sampled output (glucose only): {sampled_output_before_perturb.shape}\")\n",
    "    print(f\"Shape of perturbed sampled output (glucose only): {sampled_output_after_perturb.shape}\")\n",
    "\n",
    "    # Store HBA1c values for individuals of interest for plotting/stats\n",
    "    original_hba1c_values = {}\n",
    "    perturbed_hba1c_values = {}\n",
    "\n",
    "    for i_idx in individuals_to_perturb_indices:\n",
    "        original_hba1c_values[i_idx] = batch_cov_orig.feat_dict[stype.numerical][i_idx, 3].item()\n",
    "        perturbed_hba1c_values[i_idx] = batch_cov_perturbed.feat_dict[stype.numerical][i_idx, 3].item()\n",
    "        print(f\"Individual {i_idx}: Original HbA1c: {original_hba1c_values[i_idx]:.2f}, Perturbed HbA1c: {perturbed_hba1c_values[i_idx]:.2f}\")\n",
    "\n",
    "# Ground truth for plotting (from the original selected batch)\n",
    "groundtruth_for_plot = original_batch_data_dict['true'][..., -1]\n",
    "batch_x_for_plot = original_batch_data_dict['batch_x'][..., -1]\n",
    "sampled_output_after_perturb = model.sample_outputs[-1]['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if not model.sample_outputs or 'individuals_to_perturb_indices' not in locals():\n",
    "    print(\"Error: Ensure the perturbation analysis cell has been run and required variables are available.\")\n",
    "else:\n",
    "    # Assuming c_out was 1 or f_dim correctly selected the single glucose feature for pred_len output\n",
    "    # sampled_output_before_perturb shape: (batch_size, num_samples, pred_len)\n",
    "    # sampled_output_after_perturb shape: (batch_size, num_samples, pred_len, 1) from notebook output\n",
    "    # groundtruth_for_plot shape: (batch_size, pred_len)\n",
    "    # batch_x_for_plot shape: (batch_size, seq_len)\n",
    "    \n",
    "    seq_len = batch_x_for_plot.shape[1]\n",
    "    pred_len = groundtruth_for_plot.shape[1]\n",
    "    time_history = np.arange(seq_len)\n",
    "    time_pred = np.arange(seq_len, seq_len + pred_len)\n",
    "    \n",
    "    for idx in individuals_to_perturb_indices:\n",
    "        history_data = batch_x_for_plot[idx].cpu().numpy()\n",
    "        true_future_data = groundtruth_for_plot[idx]\n",
    "        \n",
    "        # Predictions before perturbation\n",
    "        preds_before_raw = sampled_output_before_perturb[idx] # (num_samples, pred_len)\n",
    "        mean_preds_before = np.mean(preds_before_raw, axis=0)\n",
    "        std_preds_before = np.std(preds_before_raw, axis=0)\n",
    "        \n",
    "        # Predictions after perturbation\n",
    "        # sampled_output_after_perturb has shape (batch_size, num_samples, pred_len, 1)\n",
    "        preds_after_raw = sampled_output_after_perturb[idx, ..., 0] # (num_samples, pred_len)\n",
    "        mean_preds_after = np.mean(preds_after_raw, axis=0)\n",
    "        std_preds_after = np.std(preds_after_raw, axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        \n",
    "        # Plot history\n",
    "        plt.plot(time_history, history_data, label='Input History (Glucose)', color='black', linewidth=1.5)\n",
    "        \n",
    "        # Plot true future\n",
    "        plt.plot(time_pred, true_future_data, label='Ground Truth Future (Glucose)', color='green', linestyle='--', linewidth=2)\n",
    "        \n",
    "        # Plot predictions before perturbation\n",
    "        plt.plot(time_pred, mean_preds_before, \n",
    "                 label=f'Mean Pred (Before Perturb, Orig HbA1c: {original_hba1c_values[idx]:.2f})', \n",
    "                 color='blue', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_before - std_preds_before, mean_preds_before + std_preds_before, \n",
    "                         color='blue', alpha=0.2, label='Std Dev (Before)')\n",
    "        \n",
    "        # Plot predictions after perturbation\n",
    "        plt.plot(time_pred, mean_preds_after, \n",
    "                 label=f'Mean Pred (After Perturb, New HbA1c: {perturbed_hba1c_values[idx]:.2f})', \n",
    "                 color='red', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_after - std_preds_after, mean_preds_after + std_preds_after, \n",
    "                         color='red', alpha=0.2, label='Std Dev (After)')\n",
    "        \n",
    "        plt.title(f'Glucose Prediction Perturbation Analysis for Individual {idx}', fontsize=16)\n",
    "        plt.xlabel('Time Steps', fontsize=14)\n",
    "        plt.ylabel('Glucose Value', fontsize=14)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparison of Average Standard Deviations (Time-Averaged) ---\n",
      "\n",
      "Individual 206:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7620\n",
      "  Avg. Std. Dev (After Perturbation):  0.8300\n",
      "  Avg. Mean (Before Perturbation):    0.5495\n",
      "  Avg. Mean (After Perturbation):     0.5129\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0680 after perturbation.\n",
      "-----\n",
      "Individual 219:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6402\n",
      "  Avg. Std. Dev (After Perturbation):  0.7165\n",
      "  Avg. Mean (Before Perturbation):    0.6825\n",
      "  Avg. Mean (After Perturbation):     1.6052\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0763 after perturbation.\n",
      "-----\n",
      "Individual 161:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4219\n",
      "  Avg. Std. Dev (After Perturbation):  0.4262\n",
      "  Avg. Mean (Before Perturbation):    -0.3207\n",
      "  Avg. Mean (After Perturbation):     -0.2990\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0043 after perturbation.\n",
      "-----\n",
      "Individual 139:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4263\n",
      "  Avg. Std. Dev (After Perturbation):  0.4494\n",
      "  Avg. Mean (Before Perturbation):    0.1382\n",
      "  Avg. Mean (After Perturbation):     0.2672\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0231 after perturbation.\n",
      "-----\n",
      "Individual 70:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4599\n",
      "  Avg. Std. Dev (After Perturbation):  0.4667\n",
      "  Avg. Mean (Before Perturbation):    0.0536\n",
      "  Avg. Mean (After Perturbation):     0.0770\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0068 after perturbation.\n",
      "-----\n",
      "Individual 63:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4072\n",
      "  Avg. Std. Dev (After Perturbation):  0.4205\n",
      "  Avg. Mean (Before Perturbation):    -0.2357\n",
      "  Avg. Mean (After Perturbation):     -0.2227\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0133 after perturbation.\n",
      "-----\n",
      "Individual 224:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6475\n",
      "  Avg. Std. Dev (After Perturbation):  0.7025\n",
      "  Avg. Mean (Before Perturbation):    0.5754\n",
      "  Avg. Mean (After Perturbation):     1.5069\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0550 after perturbation.\n",
      "-----\n",
      "Individual 162:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3949\n",
      "  Avg. Std. Dev (After Perturbation):  0.4209\n",
      "  Avg. Mean (Before Perturbation):    -0.3655\n",
      "  Avg. Mean (After Perturbation):     -0.3097\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0260 after perturbation.\n",
      "-----\n",
      "Individual 8:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7605\n",
      "  Avg. Std. Dev (After Perturbation):  0.6914\n",
      "  Avg. Mean (Before Perturbation):    0.2055\n",
      "  Avg. Mean (After Perturbation):     -0.1069\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0691 after perturbation.\n",
      "-----\n",
      "Individual 113:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4015\n",
      "  Avg. Std. Dev (After Perturbation):  0.4010\n",
      "  Avg. Mean (Before Perturbation):    -0.3027\n",
      "  Avg. Mean (After Perturbation):     -0.3167\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0004 after perturbation.\n",
      "-----\n",
      "Individual 121:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4300\n",
      "  Avg. Std. Dev (After Perturbation):  0.4324\n",
      "  Avg. Mean (Before Perturbation):    -0.2381\n",
      "  Avg. Mean (After Perturbation):     -0.2612\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0024 after perturbation.\n",
      "-----\n",
      "Individual 147:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4660\n",
      "  Avg. Std. Dev (After Perturbation):  0.4774\n",
      "  Avg. Mean (Before Perturbation):    0.0358\n",
      "  Avg. Mean (After Perturbation):     0.1035\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0114 after perturbation.\n",
      "-----\n",
      "Individual 16:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6556\n",
      "  Avg. Std. Dev (After Perturbation):  0.6390\n",
      "  Avg. Mean (Before Perturbation):    -0.1170\n",
      "  Avg. Mean (After Perturbation):     -0.1012\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0167 after perturbation.\n",
      "-----\n",
      "Individual 80:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4498\n",
      "  Avg. Std. Dev (After Perturbation):  0.4607\n",
      "  Avg. Mean (Before Perturbation):    -0.0662\n",
      "  Avg. Mean (After Perturbation):     -0.0475\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0108 after perturbation.\n",
      "-----\n",
      "Individual 69:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4503\n",
      "  Avg. Std. Dev (After Perturbation):  0.4567\n",
      "  Avg. Mean (Before Perturbation):    0.0406\n",
      "  Avg. Mean (After Perturbation):     0.0452\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0064 after perturbation.\n",
      "-----\n",
      "Individual 75:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4472\n",
      "  Avg. Std. Dev (After Perturbation):  0.4635\n",
      "  Avg. Mean (Before Perturbation):    0.0500\n",
      "  Avg. Mean (After Perturbation):     0.0596\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0163 after perturbation.\n",
      "-----\n",
      "Individual 245:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6038\n",
      "  Avg. Std. Dev (After Perturbation):  0.6882\n",
      "  Avg. Mean (Before Perturbation):    1.2079\n",
      "  Avg. Mean (After Perturbation):     1.8061\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0844 after perturbation.\n",
      "-----\n",
      "Individual 19:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4592\n",
      "  Avg. Std. Dev (After Perturbation):  0.4692\n",
      "  Avg. Mean (Before Perturbation):    0.6109\n",
      "  Avg. Mean (After Perturbation):     0.7194\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0099 after perturbation.\n",
      "-----\n",
      "Individual 233:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6242\n",
      "  Avg. Std. Dev (After Perturbation):  0.6935\n",
      "  Avg. Mean (Before Perturbation):    0.7626\n",
      "  Avg. Mean (After Perturbation):     1.7187\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0693 after perturbation.\n",
      "-----\n",
      "Individual 227:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6106\n",
      "  Avg. Std. Dev (After Perturbation):  0.6971\n",
      "  Avg. Mean (Before Perturbation):    0.6741\n",
      "  Avg. Mean (After Perturbation):     1.6598\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0865 after perturbation.\n",
      "-----\n",
      "Individual 41:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3914\n",
      "  Avg. Std. Dev (After Perturbation):  0.4234\n",
      "  Avg. Mean (Before Perturbation):    -0.2333\n",
      "  Avg. Mean (After Perturbation):     -0.1964\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0320 after perturbation.\n",
      "-----\n",
      "Individual 42:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3960\n",
      "  Avg. Std. Dev (After Perturbation):  0.4081\n",
      "  Avg. Mean (Before Perturbation):    -0.2563\n",
      "  Avg. Mean (After Perturbation):     -0.2243\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0120 after perturbation.\n",
      "-----\n",
      "Individual 212:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6332\n",
      "  Avg. Std. Dev (After Perturbation):  0.6998\n",
      "  Avg. Mean (Before Perturbation):    0.9061\n",
      "  Avg. Mean (After Perturbation):     1.7893\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0666 after perturbation.\n",
      "-----\n",
      "Individual 13:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7361\n",
      "  Avg. Std. Dev (After Perturbation):  0.6552\n",
      "  Avg. Mean (Before Perturbation):    0.0758\n",
      "  Avg. Mean (After Perturbation):     -0.2188\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0808 after perturbation.\n",
      "-----\n",
      "Individual 190:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4859\n",
      "  Avg. Std. Dev (After Perturbation):  0.5203\n",
      "  Avg. Mean (Before Perturbation):    -0.0193\n",
      "  Avg. Mean (After Perturbation):     -0.0174\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0344 after perturbation.\n",
      "-----\n",
      "Individual 26:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4509\n",
      "  Avg. Std. Dev (After Perturbation):  0.4566\n",
      "  Avg. Mean (Before Perturbation):    0.8304\n",
      "  Avg. Mean (After Perturbation):     0.9633\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0057 after perturbation.\n",
      "-----\n",
      "Individual 172:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4895\n",
      "  Avg. Std. Dev (After Perturbation):  0.4813\n",
      "  Avg. Mean (Before Perturbation):    0.0424\n",
      "  Avg. Mean (After Perturbation):     0.0940\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0082 after perturbation.\n",
      "-----\n",
      "Individual 183:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5351\n",
      "  Avg. Std. Dev (After Perturbation):  0.5746\n",
      "  Avg. Mean (Before Perturbation):    0.1926\n",
      "  Avg. Mean (After Perturbation):     0.2566\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0394 after perturbation.\n",
      "-----\n",
      "Individual 140:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4175\n",
      "  Avg. Std. Dev (After Perturbation):  0.4486\n",
      "  Avg. Mean (Before Perturbation):    0.1504\n",
      "  Avg. Mean (After Perturbation):     0.2887\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0311 after perturbation.\n",
      "-----\n",
      "Individual 240:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6138\n",
      "  Avg. Std. Dev (After Perturbation):  0.6744\n",
      "  Avg. Mean (Before Perturbation):    1.0418\n",
      "  Avg. Mean (After Perturbation):     1.8454\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0606 after perturbation.\n",
      "-----\n",
      "Individual 232:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6200\n",
      "  Avg. Std. Dev (After Perturbation):  0.6967\n",
      "  Avg. Mean (Before Perturbation):    0.6108\n",
      "  Avg. Mean (After Perturbation):     1.5737\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0767 after perturbation.\n",
      "-----\n",
      "Individual 136:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4214\n",
      "  Avg. Std. Dev (After Perturbation):  0.4480\n",
      "  Avg. Mean (Before Perturbation):    0.1135\n",
      "  Avg. Mean (After Perturbation):     0.2366\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0266 after perturbation.\n",
      "-----\n",
      "Individual 211:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6325\n",
      "  Avg. Std. Dev (After Perturbation):  0.6802\n",
      "  Avg. Mean (Before Perturbation):    0.9177\n",
      "  Avg. Mean (After Perturbation):     1.8101\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0477 after perturbation.\n",
      "-----\n",
      "Individual 174:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4772\n",
      "  Avg. Std. Dev (After Perturbation):  0.4739\n",
      "  Avg. Mean (Before Perturbation):    -0.1469\n",
      "  Avg. Mean (After Perturbation):     -0.0997\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0033 after perturbation.\n",
      "-----\n",
      "Individual 119:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4366\n",
      "  Avg. Std. Dev (After Perturbation):  0.4304\n",
      "  Avg. Mean (Before Perturbation):    -0.2609\n",
      "  Avg. Mean (After Perturbation):     -0.2920\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0063 after perturbation.\n",
      "-----\n",
      "Individual 29:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4518\n",
      "  Avg. Std. Dev (After Perturbation):  0.4672\n",
      "  Avg. Mean (Before Perturbation):    0.6958\n",
      "  Avg. Mean (After Perturbation):     0.8357\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0154 after perturbation.\n",
      "-----\n",
      "Individual 51:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3841\n",
      "  Avg. Std. Dev (After Perturbation):  0.3976\n",
      "  Avg. Mean (Before Perturbation):    -0.3664\n",
      "  Avg. Mean (After Perturbation):     -0.3452\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0136 after perturbation.\n",
      "-----\n",
      "Individual 154:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4231\n",
      "  Avg. Std. Dev (After Perturbation):  0.4410\n",
      "  Avg. Mean (Before Perturbation):    -0.3119\n",
      "  Avg. Mean (After Perturbation):     -0.2700\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0179 after perturbation.\n",
      "-----\n",
      "Individual 248:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6346\n",
      "  Avg. Std. Dev (After Perturbation):  0.6998\n",
      "  Avg. Mean (Before Perturbation):    1.1971\n",
      "  Avg. Mean (After Perturbation):     1.5875\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0652 after perturbation.\n",
      "-----\n",
      "Individual 112:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4205\n",
      "  Avg. Std. Dev (After Perturbation):  0.4225\n",
      "  Avg. Mean (Before Perturbation):    -0.2987\n",
      "  Avg. Mean (After Perturbation):     -0.3127\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0021 after perturbation.\n",
      "-----\n",
      "Individual 163:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4093\n",
      "  Avg. Std. Dev (After Perturbation):  0.4171\n",
      "  Avg. Mean (Before Perturbation):    -0.3816\n",
      "  Avg. Mean (After Perturbation):     -0.3250\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0078 after perturbation.\n",
      "-----\n",
      "Individual 213:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6442\n",
      "  Avg. Std. Dev (After Perturbation):  0.7048\n",
      "  Avg. Mean (Before Perturbation):    0.8568\n",
      "  Avg. Mean (After Perturbation):     1.6858\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0606 after perturbation.\n",
      "-----\n",
      "Individual 71:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4578\n",
      "  Avg. Std. Dev (After Perturbation):  0.4560\n",
      "  Avg. Mean (Before Perturbation):    0.0579\n",
      "  Avg. Mean (After Perturbation):     0.0773\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0017 after perturbation.\n",
      "-----\n",
      "Individual 134:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4260\n",
      "  Avg. Std. Dev (After Perturbation):  0.4302\n",
      "  Avg. Mean (Before Perturbation):    0.0987\n",
      "  Avg. Mean (After Perturbation):     0.2285\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0043 after perturbation.\n",
      "-----\n",
      "Individual 86:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4373\n",
      "  Avg. Std. Dev (After Perturbation):  0.4317\n",
      "  Avg. Mean (Before Perturbation):    -0.2064\n",
      "  Avg. Mean (After Perturbation):     -0.2105\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0056 after perturbation.\n",
      "-----\n",
      "Individual 171:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4949\n",
      "  Avg. Std. Dev (After Perturbation):  0.5000\n",
      "  Avg. Mean (Before Perturbation):    0.1436\n",
      "  Avg. Mean (After Perturbation):     0.1916\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0051 after perturbation.\n",
      "-----\n",
      "Individual 95:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4127\n",
      "  Avg. Std. Dev (After Perturbation):  0.4201\n",
      "  Avg. Mean (Before Perturbation):    -0.3106\n",
      "  Avg. Mean (After Perturbation):     -0.2976\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0074 after perturbation.\n",
      "-----\n",
      "Individual 204:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7399\n",
      "  Avg. Std. Dev (After Perturbation):  0.8218\n",
      "  Avg. Mean (Before Perturbation):    0.4270\n",
      "  Avg. Mean (After Perturbation):     0.4065\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0818 after perturbation.\n",
      "-----\n",
      "Individual 101:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4028\n",
      "  Avg. Std. Dev (After Perturbation):  0.4202\n",
      "  Avg. Mean (Before Perturbation):    -0.3287\n",
      "  Avg. Mean (After Perturbation):     -0.3138\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0174 after perturbation.\n",
      "-----\n",
      "Individual 177:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4625\n",
      "  Avg. Std. Dev (After Perturbation):  0.4567\n",
      "  Avg. Mean (Before Perturbation):    -0.1104\n",
      "  Avg. Mean (After Perturbation):     -0.0779\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0058 after perturbation.\n",
      "-----\n",
      "Individual 28:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4386\n",
      "  Avg. Std. Dev (After Perturbation):  0.4538\n",
      "  Avg. Mean (Before Perturbation):    0.7334\n",
      "  Avg. Mean (After Perturbation):     0.8845\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0152 after perturbation.\n",
      "-----\n",
      "Individual 56:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3838\n",
      "  Avg. Std. Dev (After Perturbation):  0.4017\n",
      "  Avg. Mean (Before Perturbation):    -0.3438\n",
      "  Avg. Mean (After Perturbation):     -0.3309\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0180 after perturbation.\n",
      "-----\n",
      "Individual 62:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4153\n",
      "  Avg. Std. Dev (After Perturbation):  0.4186\n",
      "  Avg. Mean (Before Perturbation):    -0.2244\n",
      "  Avg. Mean (After Perturbation):     -0.2236\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0034 after perturbation.\n",
      "-----\n",
      "Individual 118:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4191\n",
      "  Avg. Std. Dev (After Perturbation):  0.4373\n",
      "  Avg. Mean (Before Perturbation):    -0.2662\n",
      "  Avg. Mean (After Perturbation):     -0.2957\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0182 after perturbation.\n",
      "-----\n",
      "Individual 246:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6189\n",
      "  Avg. Std. Dev (After Perturbation):  0.6684\n",
      "  Avg. Mean (Before Perturbation):    1.2304\n",
      "  Avg. Mean (After Perturbation):     1.7485\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0496 after perturbation.\n",
      "-----\n",
      "Individual 120:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4247\n",
      "  Avg. Std. Dev (After Perturbation):  0.4318\n",
      "  Avg. Mean (Before Perturbation):    -0.2529\n",
      "  Avg. Mean (After Perturbation):     -0.2831\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0072 after perturbation.\n",
      "-----\n",
      "Individual 220:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6650\n",
      "  Avg. Std. Dev (After Perturbation):  0.7466\n",
      "  Avg. Mean (Before Perturbation):    0.6557\n",
      "  Avg. Mean (After Perturbation):     1.5955\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0816 after perturbation.\n",
      "-----\n",
      "Individual 165:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3881\n",
      "  Avg. Std. Dev (After Perturbation):  0.4102\n",
      "  Avg. Mean (Before Perturbation):    -0.4044\n",
      "  Avg. Mean (After Perturbation):     -0.3616\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0220 after perturbation.\n",
      "-----\n",
      "Individual 138:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4269\n",
      "  Avg. Std. Dev (After Perturbation):  0.4418\n",
      "  Avg. Mean (Before Perturbation):    0.1232\n",
      "  Avg. Mean (After Perturbation):     0.2623\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0149 after perturbation.\n",
      "-----\n",
      "Individual 208:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7462\n",
      "  Avg. Std. Dev (After Perturbation):  0.8319\n",
      "  Avg. Mean (Before Perturbation):    0.6749\n",
      "  Avg. Mean (After Perturbation):     0.6502\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0857 after perturbation.\n",
      "-----\n",
      "Individual 202:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7224\n",
      "  Avg. Std. Dev (After Perturbation):  0.8083\n",
      "  Avg. Mean (Before Perturbation):    0.3914\n",
      "  Avg. Mean (After Perturbation):     0.3556\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0859 after perturbation.\n",
      "-----\n",
      "Individual 239:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6208\n",
      "  Avg. Std. Dev (After Perturbation):  0.6671\n",
      "  Avg. Mean (Before Perturbation):    0.9334\n",
      "  Avg. Mean (After Perturbation):     1.7825\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0462 after perturbation.\n",
      "-----\n",
      "Individual 72:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4523\n",
      "  Avg. Std. Dev (After Perturbation):  0.4619\n",
      "  Avg. Mean (Before Perturbation):    0.0482\n",
      "  Avg. Mean (After Perturbation):     0.0547\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0096 after perturbation.\n",
      "-----\n",
      "Individual 34:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3876\n",
      "  Avg. Std. Dev (After Perturbation):  0.4252\n",
      "  Avg. Mean (Before Perturbation):    0.0335\n",
      "  Avg. Mean (After Perturbation):     0.1859\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0376 after perturbation.\n",
      "-----\n",
      "Individual 214:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6432\n",
      "  Avg. Std. Dev (After Perturbation):  0.7096\n",
      "  Avg. Mean (Before Perturbation):    0.8496\n",
      "  Avg. Mean (After Perturbation):     1.6991\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0664 after perturbation.\n",
      "-----\n",
      "Individual 1:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4159\n",
      "  Avg. Std. Dev (After Perturbation):  0.5518\n",
      "  Avg. Mean (Before Perturbation):    -0.7097\n",
      "  Avg. Mean (After Perturbation):     0.0312\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1359 after perturbation.\n",
      "-----\n",
      "Individual 5:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4313\n",
      "  Avg. Std. Dev (After Perturbation):  0.6151\n",
      "  Avg. Mean (Before Perturbation):    -0.6526\n",
      "  Avg. Mean (After Perturbation):     0.0154\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1838 after perturbation.\n",
      "-----\n",
      "Individual 137:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4293\n",
      "  Avg. Std. Dev (After Perturbation):  0.4431\n",
      "  Avg. Mean (Before Perturbation):    0.1065\n",
      "  Avg. Mean (After Perturbation):     0.2266\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0138 after perturbation.\n",
      "-----\n",
      "Individual 58:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3938\n",
      "  Avg. Std. Dev (After Perturbation):  0.4116\n",
      "  Avg. Mean (Before Perturbation):    -0.3071\n",
      "  Avg. Mean (After Perturbation):     -0.2918\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0178 after perturbation.\n",
      "-----\n",
      "Individual 49:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3708\n",
      "  Avg. Std. Dev (After Perturbation):  0.3921\n",
      "  Avg. Mean (Before Perturbation):    -0.3593\n",
      "  Avg. Mean (After Perturbation):     -0.3292\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0212 after perturbation.\n",
      "-----\n",
      "Individual 43:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4044\n",
      "  Avg. Std. Dev (After Perturbation):  0.4058\n",
      "  Avg. Mean (Before Perturbation):    -0.2665\n",
      "  Avg. Mean (After Perturbation):     -0.2435\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0014 after perturbation.\n",
      "-----\n",
      "Individual 250:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6393\n",
      "  Avg. Std. Dev (After Perturbation):  0.7391\n",
      "  Avg. Mean (Before Perturbation):    0.7570\n",
      "  Avg. Mean (After Perturbation):     1.1067\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0998 after perturbation.\n",
      "-----\n",
      "Individual 102:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4055\n",
      "  Avg. Std. Dev (After Perturbation):  0.4108\n",
      "  Avg. Mean (Before Perturbation):    -0.3284\n",
      "  Avg. Mean (After Perturbation):     -0.3310\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0053 after perturbation.\n",
      "-----\n",
      "Individual 109:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4056\n",
      "  Avg. Std. Dev (After Perturbation):  0.4042\n",
      "  Avg. Mean (Before Perturbation):    -0.3190\n",
      "  Avg. Mean (After Perturbation):     -0.3306\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0014 after perturbation.\n",
      "-----\n",
      "Individual 148:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4584\n",
      "  Avg. Std. Dev (After Perturbation):  0.4764\n",
      "  Avg. Mean (Before Perturbation):    -0.0447\n",
      "  Avg. Mean (After Perturbation):     0.0151\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0180 after perturbation.\n",
      "-----\n",
      "Individual 167:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4020\n",
      "  Avg. Std. Dev (After Perturbation):  0.4139\n",
      "  Avg. Mean (Before Perturbation):    -0.3372\n",
      "  Avg. Mean (After Perturbation):     -0.3074\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0118 after perturbation.\n",
      "-----\n",
      "Individual 94:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4088\n",
      "  Avg. Std. Dev (After Perturbation):  0.4163\n",
      "  Avg. Mean (Before Perturbation):    -0.3085\n",
      "  Avg. Mean (After Perturbation):     -0.2875\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0075 after perturbation.\n",
      "-----\n",
      "Individual 255:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5808\n",
      "  Avg. Std. Dev (After Perturbation):  0.6781\n",
      "  Avg. Mean (Before Perturbation):    -0.0581\n",
      "  Avg. Mean (After Perturbation):     0.0119\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0973 after perturbation.\n",
      "-----\n",
      "Individual 66:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4297\n",
      "  Avg. Std. Dev (After Perturbation):  0.4495\n",
      "  Avg. Mean (Before Perturbation):    -0.1098\n",
      "  Avg. Mean (After Perturbation):     -0.0952\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0199 after perturbation.\n",
      "-----\n",
      "Individual 225:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6505\n",
      "  Avg. Std. Dev (After Perturbation):  0.7259\n",
      "  Avg. Mean (Before Perturbation):    0.4900\n",
      "  Avg. Mean (After Perturbation):     1.4490\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0754 after perturbation.\n",
      "-----\n",
      "Individual 251:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6658\n",
      "  Avg. Std. Dev (After Perturbation):  0.7414\n",
      "  Avg. Mean (Before Perturbation):    0.5128\n",
      "  Avg. Mean (After Perturbation):     0.9274\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0757 after perturbation.\n",
      "-----\n",
      "Individual 238:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6307\n",
      "  Avg. Std. Dev (After Perturbation):  0.6805\n",
      "  Avg. Mean (Before Perturbation):    0.9039\n",
      "  Avg. Mean (After Perturbation):     1.7977\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0497 after perturbation.\n",
      "-----\n",
      "Individual 21:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4523\n",
      "  Avg. Std. Dev (After Perturbation):  0.4550\n",
      "  Avg. Mean (Before Perturbation):    0.7043\n",
      "  Avg. Mean (After Perturbation):     0.8262\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0027 after perturbation.\n",
      "-----\n",
      "Individual 44:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3986\n",
      "  Avg. Std. Dev (After Perturbation):  0.4180\n",
      "  Avg. Mean (Before Perturbation):    -0.2787\n",
      "  Avg. Mean (After Perturbation):     -0.2360\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0194 after perturbation.\n",
      "-----\n",
      "Individual 149:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4566\n",
      "  Avg. Std. Dev (After Perturbation):  0.4607\n",
      "  Avg. Mean (Before Perturbation):    -0.0865\n",
      "  Avg. Mean (After Perturbation):     -0.0335\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0042 after perturbation.\n",
      "-----\n",
      "Individual 115:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3948\n",
      "  Avg. Std. Dev (After Perturbation):  0.4107\n",
      "  Avg. Mean (Before Perturbation):    -0.2765\n",
      "  Avg. Mean (After Perturbation):     -0.2817\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0159 after perturbation.\n",
      "-----\n",
      "Individual 196:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5930\n",
      "  Avg. Std. Dev (After Perturbation):  0.6791\n",
      "  Avg. Mean (Before Perturbation):    -0.3494\n",
      "  Avg. Mean (After Perturbation):     -0.0864\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0861 after perturbation.\n",
      "-----\n",
      "Individual 181:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4701\n",
      "  Avg. Std. Dev (After Perturbation):  0.4732\n",
      "  Avg. Mean (Before Perturbation):    -0.0074\n",
      "  Avg. Mean (After Perturbation):     0.0232\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0031 after perturbation.\n",
      "-----\n",
      "Individual 35:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3914\n",
      "  Avg. Std. Dev (After Perturbation):  0.4371\n",
      "  Avg. Mean (Before Perturbation):    0.0334\n",
      "  Avg. Mean (After Perturbation):     0.1886\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0457 after perturbation.\n",
      "-----\n",
      "Individual 253:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6274\n",
      "  Avg. Std. Dev (After Perturbation):  0.7431\n",
      "  Avg. Mean (Before Perturbation):    0.3253\n",
      "  Avg. Mean (After Perturbation):     0.6445\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1157 after perturbation.\n",
      "-----\n",
      "Individual 182:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5278\n",
      "  Avg. Std. Dev (After Perturbation):  0.5770\n",
      "  Avg. Mean (Before Perturbation):    0.2116\n",
      "  Avg. Mean (After Perturbation):     0.3215\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0493 after perturbation.\n",
      "-----\n",
      "Individual 207:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7268\n",
      "  Avg. Std. Dev (After Perturbation):  0.8168\n",
      "  Avg. Mean (Before Perturbation):    0.6213\n",
      "  Avg. Mean (After Perturbation):     0.5776\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0900 after perturbation.\n",
      "-----\n",
      "Individual 68:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4389\n",
      "  Avg. Std. Dev (After Perturbation):  0.4529\n",
      "  Avg. Mean (Before Perturbation):    0.0033\n",
      "  Avg. Mean (After Perturbation):     0.0073\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0140 after perturbation.\n",
      "-----\n",
      "Individual 111:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4125\n",
      "  Avg. Std. Dev (After Perturbation):  0.4086\n",
      "  Avg. Mean (Before Perturbation):    -0.3115\n",
      "  Avg. Mean (After Perturbation):     -0.3301\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0039 after perturbation.\n",
      "-----\n",
      "Individual 45:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4027\n",
      "  Avg. Std. Dev (After Perturbation):  0.4060\n",
      "  Avg. Mean (Before Perturbation):    -0.2558\n",
      "  Avg. Mean (After Perturbation):     -0.2322\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0034 after perturbation.\n",
      "-----\n",
      "Individual 198:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6861\n",
      "  Avg. Std. Dev (After Perturbation):  0.7638\n",
      "  Avg. Mean (Before Perturbation):    -0.0257\n",
      "  Avg. Mean (After Perturbation):     -0.0009\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0777 after perturbation.\n",
      "-----\n",
      "Individual 192:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5075\n",
      "  Avg. Std. Dev (After Perturbation):  0.5322\n",
      "  Avg. Mean (Before Perturbation):    0.0221\n",
      "  Avg. Mean (After Perturbation):     0.0306\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0247 after perturbation.\n",
      "-----\n",
      "Individual 157:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4288\n",
      "  Avg. Std. Dev (After Perturbation):  0.4438\n",
      "  Avg. Mean (Before Perturbation):    -0.2438\n",
      "  Avg. Mean (After Perturbation):     -0.2134\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0150 after perturbation.\n",
      "-----\n",
      "Individual 194:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5033\n",
      "  Avg. Std. Dev (After Perturbation):  0.5372\n",
      "  Avg. Mean (Before Perturbation):    -0.0248\n",
      "  Avg. Mean (After Perturbation):     -0.0139\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0339 after perturbation.\n",
      "-----\n",
      "Individual 193:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5034\n",
      "  Avg. Std. Dev (After Perturbation):  0.5275\n",
      "  Avg. Mean (Before Perturbation):    -0.0023\n",
      "  Avg. Mean (After Perturbation):     0.0219\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0241 after perturbation.\n",
      "-----\n",
      "Individual 27:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4415\n",
      "  Avg. Std. Dev (After Perturbation):  0.4528\n",
      "  Avg. Mean (Before Perturbation):    0.7889\n",
      "  Avg. Mean (After Perturbation):     0.9140\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0114 after perturbation.\n",
      "-----\n",
      "Individual 88:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4149\n",
      "  Avg. Std. Dev (After Perturbation):  0.4339\n",
      "  Avg. Mean (Before Perturbation):    -0.2464\n",
      "  Avg. Mean (After Perturbation):     -0.2390\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0190 after perturbation.\n",
      "-----\n",
      "Individual 2:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4193\n",
      "  Avg. Std. Dev (After Perturbation):  0.5651\n",
      "  Avg. Mean (Before Perturbation):    -0.7023\n",
      "  Avg. Mean (After Perturbation):     0.0708\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1458 after perturbation.\n",
      "-----\n",
      "Individual 170:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4399\n",
      "  Avg. Std. Dev (After Perturbation):  0.4444\n",
      "  Avg. Mean (Before Perturbation):    -0.1066\n",
      "  Avg. Mean (After Perturbation):     -0.1010\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0045 after perturbation.\n",
      "-----\n",
      "Individual 143:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4814\n",
      "  Avg. Std. Dev (After Perturbation):  0.4884\n",
      "  Avg. Mean (Before Perturbation):    0.2791\n",
      "  Avg. Mean (After Perturbation):     0.3264\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0070 after perturbation.\n",
      "-----\n",
      "Individual 226:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6553\n",
      "  Avg. Std. Dev (After Perturbation):  0.7123\n",
      "  Avg. Mean (Before Perturbation):    0.5571\n",
      "  Avg. Mean (After Perturbation):     1.5158\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0569 after perturbation.\n",
      "-----\n",
      "Individual 90:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4280\n",
      "  Avg. Std. Dev (After Perturbation):  0.4269\n",
      "  Avg. Mean (Before Perturbation):    -0.2591\n",
      "  Avg. Mean (After Perturbation):     -0.2481\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0010 after perturbation.\n",
      "-----\n",
      "Individual 205:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7416\n",
      "  Avg. Std. Dev (After Perturbation):  0.8148\n",
      "  Avg. Mean (Before Perturbation):    0.4662\n",
      "  Avg. Mean (After Perturbation):     0.4535\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0732 after perturbation.\n",
      "-----\n",
      "Individual 222:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6564\n",
      "  Avg. Std. Dev (After Perturbation):  0.7143\n",
      "  Avg. Mean (Before Perturbation):    0.5779\n",
      "  Avg. Mean (After Perturbation):     1.5140\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0579 after perturbation.\n",
      "-----\n",
      "Individual 129:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4083\n",
      "  Avg. Std. Dev (After Perturbation):  0.4396\n",
      "  Avg. Mean (Before Perturbation):    0.0565\n",
      "  Avg. Mean (After Perturbation):     0.1634\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0313 after perturbation.\n",
      "-----\n",
      "Individual 23:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4510\n",
      "  Avg. Std. Dev (After Perturbation):  0.4578\n",
      "  Avg. Mean (Before Perturbation):    0.7258\n",
      "  Avg. Mean (After Perturbation):     0.8465\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0068 after perturbation.\n",
      "-----\n",
      "Individual 110:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4074\n",
      "  Avg. Std. Dev (After Perturbation):  0.4197\n",
      "  Avg. Mean (Before Perturbation):    -0.3147\n",
      "  Avg. Mean (After Perturbation):     -0.3207\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0122 after perturbation.\n",
      "-----\n",
      "Individual 83:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4505\n",
      "  Avg. Std. Dev (After Perturbation):  0.4582\n",
      "  Avg. Mean (Before Perturbation):    -0.0733\n",
      "  Avg. Mean (After Perturbation):     -0.0536\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0076 after perturbation.\n",
      "-----\n",
      "Individual 24:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4429\n",
      "  Avg. Std. Dev (After Perturbation):  0.4451\n",
      "  Avg. Mean (Before Perturbation):    0.7626\n",
      "  Avg. Mean (After Perturbation):     0.8795\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0022 after perturbation.\n",
      "-----\n",
      "Individual 25:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4498\n",
      "  Avg. Std. Dev (After Perturbation):  0.4454\n",
      "  Avg. Mean (Before Perturbation):    0.8136\n",
      "  Avg. Mean (After Perturbation):     0.9398\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0044 after perturbation.\n",
      "-----\n",
      "Individual 235:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6148\n",
      "  Avg. Std. Dev (After Perturbation):  0.6692\n",
      "  Avg. Mean (Before Perturbation):    0.8929\n",
      "  Avg. Mean (After Perturbation):     1.8227\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0544 after perturbation.\n",
      "-----\n",
      "Individual 164:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4091\n",
      "  Avg. Std. Dev (After Perturbation):  0.4151\n",
      "  Avg. Mean (Before Perturbation):    -0.3839\n",
      "  Avg. Mean (After Perturbation):     -0.3356\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0060 after perturbation.\n",
      "-----\n",
      "Individual 40:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3766\n",
      "  Avg. Std. Dev (After Perturbation):  0.4171\n",
      "  Avg. Mean (Before Perturbation):    -0.1884\n",
      "  Avg. Mean (After Perturbation):     -0.0420\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0406 after perturbation.\n",
      "-----\n",
      "Individual 93:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4092\n",
      "  Avg. Std. Dev (After Perturbation):  0.4280\n",
      "  Avg. Mean (Before Perturbation):    -0.2979\n",
      "  Avg. Mean (After Perturbation):     -0.2650\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0189 after perturbation.\n",
      "-----\n",
      "Individual 52:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3772\n",
      "  Avg. Std. Dev (After Perturbation):  0.3947\n",
      "  Avg. Mean (Before Perturbation):    -0.3768\n",
      "  Avg. Mean (After Perturbation):     -0.3501\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0175 after perturbation.\n",
      "-----\n",
      "Individual 180:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4716\n",
      "  Avg. Std. Dev (After Perturbation):  0.4699\n",
      "  Avg. Mean (Before Perturbation):    -0.0005\n",
      "  Avg. Mean (After Perturbation):     0.0403\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0017 after perturbation.\n",
      "-----\n",
      "Individual 20:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4623\n",
      "  Avg. Std. Dev (After Perturbation):  0.4565\n",
      "  Avg. Mean (Before Perturbation):    0.7066\n",
      "  Avg. Mean (After Perturbation):     0.8062\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0057 after perturbation.\n",
      "-----\n",
      "Individual 199:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6696\n",
      "  Avg. Std. Dev (After Perturbation):  0.7380\n",
      "  Avg. Mean (Before Perturbation):    -0.0552\n",
      "  Avg. Mean (After Perturbation):     -0.0160\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0684 after perturbation.\n",
      "-----\n",
      "Individual 7:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7702\n",
      "  Avg. Std. Dev (After Perturbation):  0.7011\n",
      "  Avg. Mean (Before Perturbation):    0.4047\n",
      "  Avg. Mean (After Perturbation):     -0.0188\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0692 after perturbation.\n",
      "-----\n",
      "Individual 87:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4277\n",
      "  Avg. Std. Dev (After Perturbation):  0.4409\n",
      "  Avg. Mean (Before Perturbation):    -0.2403\n",
      "  Avg. Mean (After Perturbation):     -0.2265\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0132 after perturbation.\n",
      "-----\n",
      "Individual 223:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6405\n",
      "  Avg. Std. Dev (After Perturbation):  0.7315\n",
      "  Avg. Mean (Before Perturbation):    0.4842\n",
      "  Avg. Mean (After Perturbation):     1.4245\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0910 after perturbation.\n",
      "-----\n",
      "Individual 11:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7480\n",
      "  Avg. Std. Dev (After Perturbation):  0.7006\n",
      "  Avg. Mean (Before Perturbation):    0.2765\n",
      "  Avg. Mean (After Perturbation):     0.0038\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0474 after perturbation.\n",
      "-----\n",
      "Individual 175:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4556\n",
      "  Avg. Std. Dev (After Perturbation):  0.4715\n",
      "  Avg. Mean (Before Perturbation):    -0.1458\n",
      "  Avg. Mean (After Perturbation):     -0.1104\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0159 after perturbation.\n",
      "-----\n",
      "Individual 6:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7836\n",
      "  Avg. Std. Dev (After Perturbation):  0.7242\n",
      "  Avg. Mean (Before Perturbation):    0.6537\n",
      "  Avg. Mean (After Perturbation):     0.1436\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0595 after perturbation.\n",
      "-----\n",
      "Individual 128:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4306\n",
      "  Avg. Std. Dev (After Perturbation):  0.4376\n",
      "  Avg. Mean (Before Perturbation):    0.0950\n",
      "  Avg. Mean (After Perturbation):     0.2054\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0070 after perturbation.\n",
      "-----\n",
      "Individual 74:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4615\n",
      "  Avg. Std. Dev (After Perturbation):  0.4636\n",
      "  Avg. Mean (Before Perturbation):    0.0319\n",
      "  Avg. Mean (After Perturbation):     0.0514\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0021 after perturbation.\n",
      "-----\n",
      "Individual 179:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4667\n",
      "  Avg. Std. Dev (After Perturbation):  0.4740\n",
      "  Avg. Mean (Before Perturbation):    -0.0328\n",
      "  Avg. Mean (After Perturbation):     0.0043\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0073 after perturbation.\n",
      "-----\n",
      "Individual 131:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4177\n",
      "  Avg. Std. Dev (After Perturbation):  0.4436\n",
      "  Avg. Mean (Before Perturbation):    0.0858\n",
      "  Avg. Mean (After Perturbation):     0.2152\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0259 after perturbation.\n",
      "-----\n",
      "Individual 53:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3867\n",
      "  Avg. Std. Dev (After Perturbation):  0.3894\n",
      "  Avg. Mean (Before Perturbation):    -0.3626\n",
      "  Avg. Mean (After Perturbation):     -0.3562\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0027 after perturbation.\n",
      "-----\n",
      "Individual 22:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4417\n",
      "  Avg. Std. Dev (After Perturbation):  0.4600\n",
      "  Avg. Mean (Before Perturbation):    0.7006\n",
      "  Avg. Mean (After Perturbation):     0.8159\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0183 after perturbation.\n",
      "-----\n",
      "Individual 124:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4344\n",
      "  Avg. Std. Dev (After Perturbation):  0.4455\n",
      "  Avg. Mean (Before Perturbation):    0.4339\n",
      "  Avg. Mean (After Perturbation):     0.5121\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0111 after perturbation.\n",
      "-----\n",
      "Individual 195:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6154\n",
      "  Avg. Std. Dev (After Perturbation):  0.6825\n",
      "  Avg. Mean (Before Perturbation):    -0.2988\n",
      "  Avg. Mean (After Perturbation):     -0.0453\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0671 after perturbation.\n",
      "-----\n",
      "Individual 14:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6559\n",
      "  Avg. Std. Dev (After Perturbation):  0.6144\n",
      "  Avg. Mean (Before Perturbation):    -0.2785\n",
      "  Avg. Mean (After Perturbation):     -0.3404\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0415 after perturbation.\n",
      "-----\n",
      "Individual 4:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4230\n",
      "  Avg. Std. Dev (After Perturbation):  0.5833\n",
      "  Avg. Mean (Before Perturbation):    -0.6791\n",
      "  Avg. Mean (After Perturbation):     -0.0077\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1603 after perturbation.\n",
      "-----\n",
      "Individual 0:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4245\n",
      "  Avg. Std. Dev (After Perturbation):  0.5789\n",
      "  Avg. Mean (Before Perturbation):    -0.7216\n",
      "  Avg. Mean (After Perturbation):     -0.0777\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1544 after perturbation.\n",
      "-----\n",
      "Individual 122:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4304\n",
      "  Avg. Std. Dev (After Perturbation):  0.4300\n",
      "  Avg. Mean (Before Perturbation):    -0.2169\n",
      "  Avg. Mean (After Perturbation):     -0.2552\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0004 after perturbation.\n",
      "-----\n",
      "Individual 185:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4974\n",
      "  Avg. Std. Dev (After Perturbation):  0.5493\n",
      "  Avg. Mean (Before Perturbation):    0.0332\n",
      "  Avg. Mean (After Perturbation):     0.0692\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0519 after perturbation.\n",
      "-----\n",
      "Individual 117:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4285\n",
      "  Avg. Std. Dev (After Perturbation):  0.4283\n",
      "  Avg. Mean (Before Perturbation):    -0.2702\n",
      "  Avg. Mean (After Perturbation):     -0.3086\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0002 after perturbation.\n",
      "-----\n",
      "Individual 76:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4545\n",
      "  Avg. Std. Dev (After Perturbation):  0.4695\n",
      "  Avg. Mean (Before Perturbation):    0.0663\n",
      "  Avg. Mean (After Perturbation):     0.0741\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0150 after perturbation.\n",
      "-----\n",
      "Individual 254:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6146\n",
      "  Avg. Std. Dev (After Perturbation):  0.6959\n",
      "  Avg. Mean (Before Perturbation):    0.1453\n",
      "  Avg. Mean (After Perturbation):     0.2101\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0813 after perturbation.\n",
      "-----\n",
      "Individual 65:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4295\n",
      "  Avg. Std. Dev (After Perturbation):  0.4494\n",
      "  Avg. Mean (Before Perturbation):    -0.1770\n",
      "  Avg. Mean (After Perturbation):     -0.1493\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0199 after perturbation.\n",
      "-----\n",
      "Individual 61:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4057\n",
      "  Avg. Std. Dev (After Perturbation):  0.4209\n",
      "  Avg. Mean (Before Perturbation):    -0.2501\n",
      "  Avg. Mean (After Perturbation):     -0.2218\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0153 after perturbation.\n",
      "-----\n",
      "Individual 166:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3921\n",
      "  Avg. Std. Dev (After Perturbation):  0.4051\n",
      "  Avg. Mean (Before Perturbation):    -0.3872\n",
      "  Avg. Mean (After Perturbation):     -0.3508\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0131 after perturbation.\n",
      "-----\n",
      "Individual 241:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6082\n",
      "  Avg. Std. Dev (After Perturbation):  0.6557\n",
      "  Avg. Mean (Before Perturbation):    1.0762\n",
      "  Avg. Mean (After Perturbation):     1.8358\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0475 after perturbation.\n",
      "-----\n",
      "Individual 30:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4384\n",
      "  Avg. Std. Dev (After Perturbation):  0.4541\n",
      "  Avg. Mean (Before Perturbation):    0.6215\n",
      "  Avg. Mean (After Perturbation):     0.7718\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0157 after perturbation.\n",
      "-----\n",
      "Individual 32:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4106\n",
      "  Avg. Std. Dev (After Perturbation):  0.4315\n",
      "  Avg. Mean (Before Perturbation):    0.2073\n",
      "  Avg. Mean (After Perturbation):     0.3449\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0209 after perturbation.\n",
      "-----\n",
      "Individual 216:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6326\n",
      "  Avg. Std. Dev (After Perturbation):  0.6902\n",
      "  Avg. Mean (Before Perturbation):    1.0204\n",
      "  Avg. Mean (After Perturbation):     1.8718\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0576 after perturbation.\n",
      "-----\n",
      "Individual 144:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4727\n",
      "  Avg. Std. Dev (After Perturbation):  0.4882\n",
      "  Avg. Mean (Before Perturbation):    0.2821\n",
      "  Avg. Mean (After Perturbation):     0.3358\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0155 after perturbation.\n",
      "-----\n",
      "Individual 159:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4201\n",
      "  Avg. Std. Dev (After Perturbation):  0.4415\n",
      "  Avg. Mean (Before Perturbation):    -0.2980\n",
      "  Avg. Mean (After Perturbation):     -0.2557\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0214 after perturbation.\n",
      "-----\n",
      "Individual 234:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6375\n",
      "  Avg. Std. Dev (After Perturbation):  0.6744\n",
      "  Avg. Mean (Before Perturbation):    0.8978\n",
      "  Avg. Mean (After Perturbation):     1.8299\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0370 after perturbation.\n",
      "-----\n",
      "Individual 145:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4761\n",
      "  Avg. Std. Dev (After Perturbation):  0.4935\n",
      "  Avg. Mean (Before Perturbation):    0.2697\n",
      "  Avg. Mean (After Perturbation):     0.3034\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0174 after perturbation.\n",
      "-----\n",
      "Individual 55:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3779\n",
      "  Avg. Std. Dev (After Perturbation):  0.4000\n",
      "  Avg. Mean (Before Perturbation):    -0.3673\n",
      "  Avg. Mean (After Perturbation):     -0.3402\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0221 after perturbation.\n",
      "-----\n",
      "Individual 150:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4397\n",
      "  Avg. Std. Dev (After Perturbation):  0.4443\n",
      "  Avg. Mean (Before Perturbation):    -0.1669\n",
      "  Avg. Mean (After Perturbation):     -0.1173\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0045 after perturbation.\n",
      "-----\n",
      "Individual 229:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6208\n",
      "  Avg. Std. Dev (After Perturbation):  0.6841\n",
      "  Avg. Mean (Before Perturbation):    0.7976\n",
      "  Avg. Mean (After Perturbation):     1.6953\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0633 after perturbation.\n",
      "-----\n",
      "Individual 67:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4401\n",
      "  Avg. Std. Dev (After Perturbation):  0.4483\n",
      "  Avg. Mean (Before Perturbation):    -0.0391\n",
      "  Avg. Mean (After Perturbation):     -0.0359\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0082 after perturbation.\n",
      "-----\n",
      "Individual 48:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3819\n",
      "  Avg. Std. Dev (After Perturbation):  0.4003\n",
      "  Avg. Mean (Before Perturbation):    -0.3266\n",
      "  Avg. Mean (After Perturbation):     -0.3123\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0184 after perturbation.\n",
      "-----\n",
      "Individual 173:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4730\n",
      "  Avg. Std. Dev (After Perturbation):  0.4892\n",
      "  Avg. Mean (Before Perturbation):    -0.0375\n",
      "  Avg. Mean (After Perturbation):     -0.0001\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0162 after perturbation.\n",
      "-----\n",
      "Individual 215:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6454\n",
      "  Avg. Std. Dev (After Perturbation):  0.6999\n",
      "  Avg. Mean (Before Perturbation):    0.9527\n",
      "  Avg. Mean (After Perturbation):     1.7965\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0545 after perturbation.\n",
      "-----\n",
      "Individual 236:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6187\n",
      "  Avg. Std. Dev (After Perturbation):  0.6624\n",
      "  Avg. Mean (Before Perturbation):    0.9175\n",
      "  Avg. Mean (After Perturbation):     1.8336\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0438 after perturbation.\n",
      "-----\n",
      "Individual 247:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6105\n",
      "  Avg. Std. Dev (After Perturbation):  0.6864\n",
      "  Avg. Mean (Before Perturbation):    1.2588\n",
      "  Avg. Mean (After Perturbation):     1.7030\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0760 after perturbation.\n",
      "-----\n",
      "Individual 200:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6915\n",
      "  Avg. Std. Dev (After Perturbation):  0.7293\n",
      "  Avg. Mean (Before Perturbation):    -0.0607\n",
      "  Avg. Mean (After Perturbation):     -0.0619\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0378 after perturbation.\n",
      "-----\n",
      "Individual 133:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4182\n",
      "  Avg. Std. Dev (After Perturbation):  0.4416\n",
      "  Avg. Mean (Before Perturbation):    0.1029\n",
      "  Avg. Mean (After Perturbation):     0.2300\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0234 after perturbation.\n",
      "-----\n",
      "Individual 3:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4171\n",
      "  Avg. Std. Dev (After Perturbation):  0.5785\n",
      "  Avg. Mean (Before Perturbation):    -0.7025\n",
      "  Avg. Mean (After Perturbation):     0.0007\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1614 after perturbation.\n",
      "-----\n",
      "Individual 77:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4479\n",
      "  Avg. Std. Dev (After Perturbation):  0.4633\n",
      "  Avg. Mean (Before Perturbation):    0.0685\n",
      "  Avg. Mean (After Perturbation):     0.0817\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0154 after perturbation.\n",
      "-----\n",
      "Individual 203:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7233\n",
      "  Avg. Std. Dev (After Perturbation):  0.7926\n",
      "  Avg. Mean (Before Perturbation):    0.3789\n",
      "  Avg. Mean (After Perturbation):     0.3196\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0693 after perturbation.\n",
      "-----\n",
      "Individual 64:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4251\n",
      "  Avg. Std. Dev (After Perturbation):  0.4307\n",
      "  Avg. Mean (Before Perturbation):    -0.2119\n",
      "  Avg. Mean (After Perturbation):     -0.1871\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0055 after perturbation.\n",
      "-----\n",
      "Individual 244:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6004\n",
      "  Avg. Std. Dev (After Perturbation):  0.6602\n",
      "  Avg. Mean (Before Perturbation):    1.1703\n",
      "  Avg. Mean (After Perturbation):     1.8357\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0598 after perturbation.\n",
      "-----\n",
      "Individual 125:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4322\n",
      "  Avg. Std. Dev (After Perturbation):  0.4370\n",
      "  Avg. Mean (Before Perturbation):    0.3597\n",
      "  Avg. Mean (After Perturbation):     0.4647\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0048 after perturbation.\n",
      "-----\n",
      "Individual 187:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4946\n",
      "  Avg. Std. Dev (After Perturbation):  0.5227\n",
      "  Avg. Mean (Before Perturbation):    -0.0417\n",
      "  Avg. Mean (After Perturbation):     -0.0131\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0280 after perturbation.\n",
      "-----\n",
      "Individual 168:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4079\n",
      "  Avg. Std. Dev (After Perturbation):  0.4246\n",
      "  Avg. Mean (Before Perturbation):    -0.2656\n",
      "  Avg. Mean (After Perturbation):     -0.2428\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0167 after perturbation.\n",
      "-----\n",
      "Individual 114:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3948\n",
      "  Avg. Std. Dev (After Perturbation):  0.4015\n",
      "  Avg. Mean (Before Perturbation):    -0.2800\n",
      "  Avg. Mean (After Perturbation):     -0.2809\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0067 after perturbation.\n",
      "-----\n",
      "Individual 126:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4220\n",
      "  Avg. Std. Dev (After Perturbation):  0.4548\n",
      "  Avg. Mean (Before Perturbation):    0.2655\n",
      "  Avg. Mean (After Perturbation):     0.3811\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0328 after perturbation.\n",
      "-----\n",
      "Individual 191:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4943\n",
      "  Avg. Std. Dev (After Perturbation):  0.5200\n",
      "  Avg. Mean (Before Perturbation):    0.0193\n",
      "  Avg. Mean (After Perturbation):     0.0263\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0258 after perturbation.\n",
      "-----\n",
      "Individual 237:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6041\n",
      "  Avg. Std. Dev (After Perturbation):  0.6521\n",
      "  Avg. Mean (Before Perturbation):    0.8861\n",
      "  Avg. Mean (After Perturbation):     1.8313\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0481 after perturbation.\n",
      "-----\n",
      "Individual 127:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4223\n",
      "  Avg. Std. Dev (After Perturbation):  0.4391\n",
      "  Avg. Mean (Before Perturbation):    0.1732\n",
      "  Avg. Mean (After Perturbation):     0.2825\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0169 after perturbation.\n",
      "-----\n",
      "Individual 242:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5971\n",
      "  Avg. Std. Dev (After Perturbation):  0.6760\n",
      "  Avg. Mean (Before Perturbation):    1.1524\n",
      "  Avg. Mean (After Perturbation):     1.8655\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0790 after perturbation.\n",
      "-----\n",
      "Individual 103:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3984\n",
      "  Avg. Std. Dev (After Perturbation):  0.4136\n",
      "  Avg. Mean (Before Perturbation):    -0.3381\n",
      "  Avg. Mean (After Perturbation):     -0.3240\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0153 after perturbation.\n",
      "-----\n",
      "Individual 100:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3990\n",
      "  Avg. Std. Dev (After Perturbation):  0.4164\n",
      "  Avg. Mean (Before Perturbation):    -0.3301\n",
      "  Avg. Mean (After Perturbation):     -0.3391\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0174 after perturbation.\n",
      "-----\n",
      "Individual 36:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3810\n",
      "  Avg. Std. Dev (After Perturbation):  0.4064\n",
      "  Avg. Mean (Before Perturbation):    -0.1052\n",
      "  Avg. Mean (After Perturbation):     0.0384\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0255 after perturbation.\n",
      "-----\n",
      "Individual 73:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4622\n",
      "  Avg. Std. Dev (After Perturbation):  0.4642\n",
      "  Avg. Mean (Before Perturbation):    0.0444\n",
      "  Avg. Mean (After Perturbation):     0.0419\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0021 after perturbation.\n",
      "-----\n",
      "Individual 108:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4032\n",
      "  Avg. Std. Dev (After Perturbation):  0.4190\n",
      "  Avg. Mean (Before Perturbation):    -0.3214\n",
      "  Avg. Mean (After Perturbation):     -0.3206\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0159 after perturbation.\n",
      "-----\n",
      "Individual 230:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6364\n",
      "  Avg. Std. Dev (After Perturbation):  0.6844\n",
      "  Avg. Mean (Before Perturbation):    0.5886\n",
      "  Avg. Mean (After Perturbation):     1.5250\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0480 after perturbation.\n",
      "-----\n",
      "Individual 231:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6237\n",
      "  Avg. Std. Dev (After Perturbation):  0.6973\n",
      "  Avg. Mean (Before Perturbation):    0.5626\n",
      "  Avg. Mean (After Perturbation):     1.5385\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0736 after perturbation.\n",
      "-----\n",
      "Individual 47:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3911\n",
      "  Avg. Std. Dev (After Perturbation):  0.4145\n",
      "  Avg. Mean (Before Perturbation):    -0.3039\n",
      "  Avg. Mean (After Perturbation):     -0.2630\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0233 after perturbation.\n",
      "-----\n",
      "Individual 135:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4284\n",
      "  Avg. Std. Dev (After Perturbation):  0.4301\n",
      "  Avg. Mean (Before Perturbation):    0.1032\n",
      "  Avg. Mean (After Perturbation):     0.2300\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0017 after perturbation.\n",
      "-----\n",
      "Individual 132:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4219\n",
      "  Avg. Std. Dev (After Perturbation):  0.4444\n",
      "  Avg. Mean (Before Perturbation):    0.0826\n",
      "  Avg. Mean (After Perturbation):     0.2072\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0225 after perturbation.\n",
      "-----\n",
      "Individual 141:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4271\n",
      "  Avg. Std. Dev (After Perturbation):  0.4530\n",
      "  Avg. Mean (Before Perturbation):    0.1917\n",
      "  Avg. Mean (After Perturbation):     0.3329\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0259 after perturbation.\n",
      "-----\n",
      "Individual 249:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6291\n",
      "  Avg. Std. Dev (After Perturbation):  0.7134\n",
      "  Avg. Mean (Before Perturbation):    0.9939\n",
      "  Avg. Mean (After Perturbation):     1.3827\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0843 after perturbation.\n",
      "-----\n",
      "Individual 156:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4310\n",
      "  Avg. Std. Dev (After Perturbation):  0.4383\n",
      "  Avg. Mean (Before Perturbation):    -0.2725\n",
      "  Avg. Mean (After Perturbation):     -0.2261\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0073 after perturbation.\n",
      "-----\n",
      "Individual 189:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4843\n",
      "  Avg. Std. Dev (After Perturbation):  0.5174\n",
      "  Avg. Mean (Before Perturbation):    -0.0323\n",
      "  Avg. Mean (After Perturbation):     -0.0311\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0331 after perturbation.\n",
      "-----\n",
      "Individual 84:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4492\n",
      "  Avg. Std. Dev (After Perturbation):  0.4557\n",
      "  Avg. Mean (Before Perturbation):    -0.1143\n",
      "  Avg. Mean (After Perturbation):     -0.0931\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0065 after perturbation.\n",
      "-----\n",
      "Individual 10:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7415\n",
      "  Avg. Std. Dev (After Perturbation):  0.6811\n",
      "  Avg. Mean (Before Perturbation):    0.0814\n",
      "  Avg. Mean (After Perturbation):     -0.1240\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0604 after perturbation.\n",
      "-----\n",
      "Individual 107:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4014\n",
      "  Avg. Std. Dev (After Perturbation):  0.4071\n",
      "  Avg. Mean (Before Perturbation):    -0.3273\n",
      "  Avg. Mean (After Perturbation):     -0.3410\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0057 after perturbation.\n",
      "-----\n",
      "Individual 105:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4056\n",
      "  Avg. Std. Dev (After Perturbation):  0.4053\n",
      "  Avg. Mean (Before Perturbation):    -0.3363\n",
      "  Avg. Mean (After Perturbation):     -0.3529\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0003 after perturbation.\n",
      "-----\n",
      "Individual 106:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4009\n",
      "  Avg. Std. Dev (After Perturbation):  0.4119\n",
      "  Avg. Mean (Before Perturbation):    -0.3427\n",
      "  Avg. Mean (After Perturbation):     -0.3492\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0109 after perturbation.\n",
      "-----\n",
      "Individual 218:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6322\n",
      "  Avg. Std. Dev (After Perturbation):  0.6870\n",
      "  Avg. Mean (Before Perturbation):    1.0462\n",
      "  Avg. Mean (After Perturbation):     1.9380\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0548 after perturbation.\n",
      "-----\n",
      "Individual 221:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6440\n",
      "  Avg. Std. Dev (After Perturbation):  0.7073\n",
      "  Avg. Mean (Before Perturbation):    0.5305\n",
      "  Avg. Mean (After Perturbation):     1.4698\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0633 after perturbation.\n",
      "-----\n",
      "Individual 186:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4797\n",
      "  Avg. Std. Dev (After Perturbation):  0.5238\n",
      "  Avg. Mean (Before Perturbation):    -0.0327\n",
      "  Avg. Mean (After Perturbation):     0.0063\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0441 after perturbation.\n",
      "-----\n",
      "Individual 92:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4262\n",
      "  Avg. Std. Dev (After Perturbation):  0.4279\n",
      "  Avg. Mean (Before Perturbation):    -0.2679\n",
      "  Avg. Mean (After Perturbation):     -0.2578\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0017 after perturbation.\n",
      "-----\n",
      "Individual 50:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3896\n",
      "  Avg. Std. Dev (After Perturbation):  0.3898\n",
      "  Avg. Mean (Before Perturbation):    -0.3599\n",
      "  Avg. Mean (After Perturbation):     -0.3374\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0002 after perturbation.\n",
      "-----\n",
      "Individual 123:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4343\n",
      "  Avg. Std. Dev (After Perturbation):  0.4338\n",
      "  Avg. Mean (Before Perturbation):    0.4470\n",
      "  Avg. Mean (After Perturbation):     0.5303\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0004 after perturbation.\n",
      "-----\n",
      "Individual 46:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3966\n",
      "  Avg. Std. Dev (After Perturbation):  0.4052\n",
      "  Avg. Mean (Before Perturbation):    -0.2706\n",
      "  Avg. Mean (After Perturbation):     -0.2375\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0087 after perturbation.\n",
      "-----\n",
      "Individual 96:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4133\n",
      "  Avg. Std. Dev (After Perturbation):  0.4177\n",
      "  Avg. Mean (Before Perturbation):    -0.3139\n",
      "  Avg. Mean (After Perturbation):     -0.2963\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0044 after perturbation.\n",
      "-----\n",
      "Individual 151:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4299\n",
      "  Avg. Std. Dev (After Perturbation):  0.4418\n",
      "  Avg. Mean (Before Perturbation):    -0.2600\n",
      "  Avg. Mean (After Perturbation):     -0.2006\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0119 after perturbation.\n",
      "-----\n",
      "Individual 89:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4132\n",
      "  Avg. Std. Dev (After Perturbation):  0.4207\n",
      "  Avg. Mean (Before Perturbation):    -0.2549\n",
      "  Avg. Mean (After Perturbation):     -0.2502\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0076 after perturbation.\n",
      "-----\n",
      "Individual 97:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4109\n",
      "  Avg. Std. Dev (After Perturbation):  0.4304\n",
      "  Avg. Mean (Before Perturbation):    -0.3208\n",
      "  Avg. Mean (After Perturbation):     -0.2973\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0195 after perturbation.\n",
      "-----\n",
      "Individual 9:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7407\n",
      "  Avg. Std. Dev (After Perturbation):  0.6621\n",
      "  Avg. Mean (Before Perturbation):    0.1488\n",
      "  Avg. Mean (After Perturbation):     -0.1310\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0787 after perturbation.\n",
      "-----\n",
      "Individual 17:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6943\n",
      "  Avg. Std. Dev (After Perturbation):  0.6632\n",
      "  Avg. Mean (Before Perturbation):    0.1049\n",
      "  Avg. Mean (After Perturbation):     0.0656\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0312 after perturbation.\n",
      "-----\n",
      "Individual 210:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6353\n",
      "  Avg. Std. Dev (After Perturbation):  0.6763\n",
      "  Avg. Mean (Before Perturbation):    0.9757\n",
      "  Avg. Mean (After Perturbation):     1.8748\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0410 after perturbation.\n",
      "-----\n",
      "Individual 209:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7263\n",
      "  Avg. Std. Dev (After Perturbation):  0.8263\n",
      "  Avg. Mean (Before Perturbation):    0.7124\n",
      "  Avg. Mean (After Perturbation):     0.6899\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.1001 after perturbation.\n",
      "-----\n",
      "Individual 82:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4485\n",
      "  Avg. Std. Dev (After Perturbation):  0.4633\n",
      "  Avg. Mean (Before Perturbation):    -0.0684\n",
      "  Avg. Mean (After Perturbation):     -0.0593\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0148 after perturbation.\n",
      "-----\n",
      "Individual 98:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4006\n",
      "  Avg. Std. Dev (After Perturbation):  0.4198\n",
      "  Avg. Mean (Before Perturbation):    -0.3265\n",
      "  Avg. Mean (After Perturbation):     -0.3199\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0193 after perturbation.\n",
      "-----\n",
      "Individual 54:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3895\n",
      "  Avg. Std. Dev (After Perturbation):  0.3880\n",
      "  Avg. Mean (Before Perturbation):    -0.3658\n",
      "  Avg. Mean (After Perturbation):     -0.3543\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0015 after perturbation.\n",
      "-----\n",
      "Individual 37:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3612\n",
      "  Avg. Std. Dev (After Perturbation):  0.4012\n",
      "  Avg. Mean (Before Perturbation):    -0.2474\n",
      "  Avg. Mean (After Perturbation):     -0.0989\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0400 after perturbation.\n",
      "-----\n",
      "Individual 33:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4111\n",
      "  Avg. Std. Dev (After Perturbation):  0.4377\n",
      "  Avg. Mean (Before Perturbation):    0.0596\n",
      "  Avg. Mean (After Perturbation):     0.1854\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0267 after perturbation.\n",
      "-----\n",
      "Individual 153:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4197\n",
      "  Avg. Std. Dev (After Perturbation):  0.4264\n",
      "  Avg. Mean (Before Perturbation):    -0.3254\n",
      "  Avg. Mean (After Perturbation):     -0.2837\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0067 after perturbation.\n",
      "-----\n",
      "Individual 60:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3974\n",
      "  Avg. Std. Dev (After Perturbation):  0.4116\n",
      "  Avg. Mean (Before Perturbation):    -0.2689\n",
      "  Avg. Mean (After Perturbation):     -0.2372\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0142 after perturbation.\n",
      "-----\n",
      "Individual 152:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4157\n",
      "  Avg. Std. Dev (After Perturbation):  0.4306\n",
      "  Avg. Mean (Before Perturbation):    -0.3205\n",
      "  Avg. Mean (After Perturbation):     -0.2846\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0149 after perturbation.\n",
      "-----\n",
      "Individual 31:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4227\n",
      "  Avg. Std. Dev (After Perturbation):  0.4459\n",
      "  Avg. Mean (Before Perturbation):    0.3760\n",
      "  Avg. Mean (After Perturbation):     0.5156\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0232 after perturbation.\n",
      "-----\n",
      "Individual 18:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6983\n",
      "  Avg. Std. Dev (After Perturbation):  0.6864\n",
      "  Avg. Mean (Before Perturbation):    0.4896\n",
      "  Avg. Mean (After Perturbation):     0.4783\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0119 after perturbation.\n",
      "-----\n",
      "Individual 38:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3470\n",
      "  Avg. Std. Dev (After Perturbation):  0.3948\n",
      "  Avg. Mean (Before Perturbation):    -0.3362\n",
      "  Avg. Mean (After Perturbation):     -0.1889\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0479 after perturbation.\n",
      "-----\n",
      "Individual 12:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7400\n",
      "  Avg. Std. Dev (After Perturbation):  0.6954\n",
      "  Avg. Mean (Before Perturbation):    0.3482\n",
      "  Avg. Mean (After Perturbation):     0.0222\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0446 after perturbation.\n",
      "-----\n",
      "Individual 169:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4293\n",
      "  Avg. Std. Dev (After Perturbation):  0.4405\n",
      "  Avg. Mean (Before Perturbation):    -0.1913\n",
      "  Avg. Mean (After Perturbation):     -0.1715\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0111 after perturbation.\n",
      "-----\n",
      "Individual 155:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4151\n",
      "  Avg. Std. Dev (After Perturbation):  0.4332\n",
      "  Avg. Mean (Before Perturbation):    -0.2978\n",
      "  Avg. Mean (After Perturbation):     -0.2516\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0181 after perturbation.\n",
      "-----\n",
      "Individual 79:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4534\n",
      "  Avg. Std. Dev (After Perturbation):  0.4572\n",
      "  Avg. Mean (Before Perturbation):    -0.0146\n",
      "  Avg. Mean (After Perturbation):     -0.0095\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0038 after perturbation.\n",
      "-----\n",
      "Individual 176:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4562\n",
      "  Avg. Std. Dev (After Perturbation):  0.4518\n",
      "  Avg. Mean (Before Perturbation):    -0.1351\n",
      "  Avg. Mean (After Perturbation):     -0.0861\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0044 after perturbation.\n",
      "-----\n",
      "Individual 158:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4254\n",
      "  Avg. Std. Dev (After Perturbation):  0.4382\n",
      "  Avg. Mean (Before Perturbation):    -0.2580\n",
      "  Avg. Mean (After Perturbation):     -0.2206\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0128 after perturbation.\n",
      "-----\n",
      "Individual 252:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6548\n",
      "  Avg. Std. Dev (After Perturbation):  0.7494\n",
      "  Avg. Mean (Before Perturbation):    0.4743\n",
      "  Avg. Mean (After Perturbation):     0.9050\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0946 after perturbation.\n",
      "-----\n",
      "Individual 243:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6026\n",
      "  Avg. Std. Dev (After Perturbation):  0.6507\n",
      "  Avg. Mean (Before Perturbation):    1.1802\n",
      "  Avg. Mean (After Perturbation):     1.8715\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0482 after perturbation.\n",
      "-----\n",
      "Individual 39:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3472\n",
      "  Avg. Std. Dev (After Perturbation):  0.3891\n",
      "  Avg. Mean (Before Perturbation):    -0.3375\n",
      "  Avg. Mean (After Perturbation):     -0.1929\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0419 after perturbation.\n",
      "-----\n",
      "Individual 130:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4074\n",
      "  Avg. Std. Dev (After Perturbation):  0.4444\n",
      "  Avg. Mean (Before Perturbation):    0.0748\n",
      "  Avg. Mean (After Perturbation):     0.2025\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0370 after perturbation.\n",
      "-----\n",
      "Individual 116:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4190\n",
      "  Avg. Std. Dev (After Perturbation):  0.4260\n",
      "  Avg. Mean (Before Perturbation):    -0.2880\n",
      "  Avg. Mean (After Perturbation):     -0.2957\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0071 after perturbation.\n",
      "-----\n",
      "Individual 78:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4464\n",
      "  Avg. Std. Dev (After Perturbation):  0.4708\n",
      "  Avg. Mean (Before Perturbation):    0.0373\n",
      "  Avg. Mean (After Perturbation):     0.0543\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0244 after perturbation.\n",
      "-----\n",
      "Individual 201:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.7157\n",
      "  Avg. Std. Dev (After Perturbation):  0.7943\n",
      "  Avg. Mean (Before Perturbation):    0.3411\n",
      "  Avg. Mean (After Perturbation):     0.3100\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0786 after perturbation.\n",
      "-----\n",
      "Individual 217:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6265\n",
      "  Avg. Std. Dev (After Perturbation):  0.6740\n",
      "  Avg. Mean (Before Perturbation):    1.0582\n",
      "  Avg. Mean (After Perturbation):     1.9388\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0474 after perturbation.\n",
      "-----\n",
      "Individual 91:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4132\n",
      "  Avg. Std. Dev (After Perturbation):  0.4178\n",
      "  Avg. Mean (Before Perturbation):    -0.2673\n",
      "  Avg. Mean (After Perturbation):     -0.2627\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0046 after perturbation.\n",
      "-----\n",
      "Individual 57:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3916\n",
      "  Avg. Std. Dev (After Perturbation):  0.4035\n",
      "  Avg. Mean (Before Perturbation):    -0.3272\n",
      "  Avg. Mean (After Perturbation):     -0.3104\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0119 after perturbation.\n",
      "-----\n",
      "Individual 160:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4288\n",
      "  Avg. Std. Dev (After Perturbation):  0.4243\n",
      "  Avg. Mean (Before Perturbation):    -0.3014\n",
      "  Avg. Mean (After Perturbation):     -0.2838\n",
      "  Comparison: Uncertainty (std dev) DECREASED by 0.0044 after perturbation.\n",
      "-----\n",
      "Individual 81:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4380\n",
      "  Avg. Std. Dev (After Perturbation):  0.4606\n",
      "  Avg. Mean (Before Perturbation):    -0.0795\n",
      "  Avg. Mean (After Perturbation):     -0.0673\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0226 after perturbation.\n",
      "-----\n",
      "Individual 142:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4728\n",
      "  Avg. Std. Dev (After Perturbation):  0.4936\n",
      "  Avg. Mean (Before Perturbation):    0.2266\n",
      "  Avg. Mean (After Perturbation):     0.2836\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0208 after perturbation.\n",
      "-----\n",
      "Individual 197:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5970\n",
      "  Avg. Std. Dev (After Perturbation):  0.6589\n",
      "  Avg. Mean (Before Perturbation):    -0.3838\n",
      "  Avg. Mean (After Perturbation):     -0.1702\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0619 after perturbation.\n",
      "-----\n",
      "Individual 99:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4081\n",
      "  Avg. Std. Dev (After Perturbation):  0.4142\n",
      "  Avg. Mean (Before Perturbation):    -0.3370\n",
      "  Avg. Mean (After Perturbation):     -0.3296\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0061 after perturbation.\n",
      "-----\n",
      "Individual 228:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.6090\n",
      "  Avg. Std. Dev (After Perturbation):  0.6748\n",
      "  Avg. Mean (Before Perturbation):    0.8644\n",
      "  Avg. Mean (After Perturbation):     1.8106\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0658 after perturbation.\n",
      "-----\n",
      "Individual 146:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4746\n",
      "  Avg. Std. Dev (After Perturbation):  0.4775\n",
      "  Avg. Mean (Before Perturbation):    0.1676\n",
      "  Avg. Mean (After Perturbation):     0.2295\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0029 after perturbation.\n",
      "-----\n",
      "Individual 85:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4322\n",
      "  Avg. Std. Dev (After Perturbation):  0.4481\n",
      "  Avg. Mean (Before Perturbation):    -0.1715\n",
      "  Avg. Mean (After Perturbation):     -0.1648\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0160 after perturbation.\n",
      "-----\n",
      "Individual 184:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5217\n",
      "  Avg. Std. Dev (After Perturbation):  0.5556\n",
      "  Avg. Mean (Before Perturbation):    0.1106\n",
      "  Avg. Mean (After Perturbation):     0.1624\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0339 after perturbation.\n",
      "-----\n",
      "Individual 178:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4408\n",
      "  Avg. Std. Dev (After Perturbation):  0.4673\n",
      "  Avg. Mean (Before Perturbation):    -0.0757\n",
      "  Avg. Mean (After Perturbation):     -0.0135\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0266 after perturbation.\n",
      "-----\n",
      "Individual 59:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.3954\n",
      "  Avg. Std. Dev (After Perturbation):  0.4028\n",
      "  Avg. Mean (Before Perturbation):    -0.2856\n",
      "  Avg. Mean (After Perturbation):     -0.2732\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0075 after perturbation.\n",
      "-----\n",
      "Individual 15:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.5996\n",
      "  Avg. Std. Dev (After Perturbation):  0.6001\n",
      "  Avg. Mean (Before Perturbation):    -0.4121\n",
      "  Avg. Mean (After Perturbation):     -0.3897\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0004 after perturbation.\n",
      "-----\n",
      "Individual 104:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4013\n",
      "  Avg. Std. Dev (After Perturbation):  0.4118\n",
      "  Avg. Mean (Before Perturbation):    -0.3314\n",
      "  Avg. Mean (After Perturbation):     -0.3331\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0106 after perturbation.\n",
      "-----\n",
      "Individual 188:\n",
      "  Avg. Std. Dev (Before Perturbation): 0.4986\n",
      "  Avg. Std. Dev (After Perturbation):  0.5242\n",
      "  Avg. Mean (Before Perturbation):    -0.0237\n",
      "  Avg. Mean (After Perturbation):     -0.0215\n",
      "  Comparison: Uncertainty (std dev) INCREASED by 0.0257 after perturbation.\n",
      "-----\n",
      "\n",
      "Overall Average Across Perturbed Individuals:\n",
      "  Overall Avg. Std. Dev (Before): 0.4954\n",
      "  Overall Avg. Std. Dev (After):  0.5226\n",
      "  Overall Avg. Mean (Before):     0.1018\n",
      "  Overall Avg. Mean (After):      0.2780\n",
      "  Overall: Uncertainty INCREASED by 0.0272\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if 'individuals_to_perturb_indices' not in locals() or \\\n",
    "   'sampled_output_before_perturb' not in locals() or \\\n",
    "   'sampled_output_after_perturb' not in locals():\n",
    "    print(\"Error: Ensure the perturbation analysis and plotting cells have been run, and variables are available.\")\n",
    "else:\n",
    "    print(\"\\n--- Comparison of Average Standard Deviations (Time-Averaged) ---\\n\")\n",
    "    avg_std_devs_before_list = []\n",
    "    avg_std_devs_after_list = []\n",
    "\n",
    "    avg_std_devs_before_list = []\n",
    "    avg_std_devs_after_list = []\n",
    "    avg_means_before_list = []\n",
    "    avg_means_after_list = []\n",
    "\n",
    "    for idx in individuals_to_perturb_indices:\n",
    "        # Predictions before perturbation: shape (num_samples, pred_len)\n",
    "        preds_before_raw = sampled_output_before_perturb[idx]\n",
    "        # Std dev across samples for each time step: shape (pred_len,)\n",
    "        std_dev_over_samples_before = np.std(preds_before_raw, axis=0)\n",
    "        # Mean across samples for each time step: shape (pred_len,)\n",
    "        mean_over_samples_before = np.mean(preds_before_raw, axis=0)\n",
    "        # Average this std dev and mean over the prediction length\n",
    "        avg_std_before = np.mean(std_dev_over_samples_before)\n",
    "        avg_mean_before = np.mean(mean_over_samples_before)\n",
    "        avg_std_devs_before_list.append(avg_std_before)\n",
    "        avg_means_before_list.append(avg_mean_before)\n",
    "\n",
    "        # Predictions after perturbation: shape (num_samples, pred_len) after [..., 0] slicing\n",
    "        preds_after_raw = sampled_output_after_perturb[idx, ..., 0]\n",
    "        # Std dev across samples for each time step: shape (pred_len,)\n",
    "        std_dev_over_samples_after = np.std(preds_after_raw, axis=0)\n",
    "        # Mean across samples for each time step: shape (pred_len,)\n",
    "        mean_over_samples_after = np.mean(preds_after_raw, axis=0)\n",
    "        # Average this std dev and mean over the prediction length\n",
    "        avg_std_after = np.mean(std_dev_over_samples_after)\n",
    "        avg_mean_after = np.mean(mean_over_samples_after)\n",
    "        avg_std_devs_after_list.append(avg_std_after)\n",
    "        avg_means_after_list.append(avg_mean_after)\n",
    "\n",
    "        print(f\"Individual {idx}:\")\n",
    "        print(f\"  Avg. Std. Dev (Before Perturbation): {avg_std_before:.4f}\")\n",
    "        print(f\"  Avg. Std. Dev (After Perturbation):  {avg_std_after:.4f}\")\n",
    "        print(f\"  Avg. Mean (Before Perturbation):    {avg_mean_before:.4f}\")\n",
    "        print(f\"  Avg. Mean (After Perturbation):     {avg_mean_after:.4f}\")\n",
    "        if avg_std_after > avg_std_before:\n",
    "            print(f\"  Comparison: Uncertainty (std dev) INCREASED by {avg_std_after - avg_std_before:.4f} after perturbation.\")\n",
    "        elif avg_std_after < avg_std_before:\n",
    "            print(f\"  Comparison: Uncertainty (std dev) DECREASED by {avg_std_before - avg_std_after:.4f} after perturbation.\")\n",
    "        else:\n",
    "            print(f\"  Comparison: Uncertainty (std dev) remained the same after perturbation.\")\n",
    "        print(\"-----\")\n",
    "\n",
    "    # Overall average if desired\n",
    "    if avg_std_devs_before_list and avg_std_devs_after_list and avg_means_before_list and avg_means_after_list:\n",
    "        overall_avg_std_before = np.mean(avg_std_devs_before_list)\n",
    "        overall_avg_std_after = np.mean(avg_std_devs_after_list)\n",
    "        overall_avg_mean_before = np.mean(avg_means_before_list)\n",
    "        overall_avg_mean_after = np.mean(avg_means_after_list)\n",
    "        print(\"\\nOverall Average Across Perturbed Individuals:\")\n",
    "        print(f\"  Overall Avg. Std. Dev (Before): {overall_avg_std_before:.4f}\")\n",
    "        print(f\"  Overall Avg. Std. Dev (After):  {overall_avg_std_after:.4f}\")\n",
    "        print(f\"  Overall Avg. Mean (Before):     {overall_avg_mean_before:.4f}\")\n",
    "        print(f\"  Overall Avg. Mean (After):      {overall_avg_mean_after:.4f}\")\n",
    "        if overall_avg_std_after > overall_avg_std_before:\n",
    "            print(f\"  Overall: Uncertainty INCREASED by {overall_avg_std_after - overall_avg_std_before:.4f}\")\n",
    "        elif overall_avg_std_after < overall_avg_std_before:\n",
    "            print(f\"  Overall: Uncertainty DECREASED by {overall_avg_std_before - overall_avg_std_after:.4f}\")\n",
    "        else:\n",
    "            print(f\"  Overall: Uncertainty remained the same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_steps_batch_x(original_data_tuple, individual_indices, percentage_increase):\n",
    "    \"\"\"\n",
    "    Perturbs 'steps' for specified individuals in batch_x.\n",
    "    'steps' are derived from batch_x[:, :, STEPS_FEATURE_INDEX_IN_BATCH_X] using a specific formula.\n",
    "    This function assumes batch_x is the first element of original_data_tuple:\n",
    "    original_data_tuple = (batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "    Returns a new data_tuple with batch_x perturbed; does not modify the input tuple or its tensors.\n",
    "    \"\"\"\n",
    "    # Constants for step calculation, as provided\n",
    "    STEPS_SCALE = 20.84327263\n",
    "    STEPS_OFFSET = 6.53019535e+00\n",
    "    STEPS_FEATURE_INDEX_IN_BATCH_X = 1 # 0-indexed\n",
    "\n",
    "\n",
    "    original_batch_x = original_data_tuple[0]\n",
    "    perturbed_batch_x = original_batch_x.clone() # Ensure we don't modify the original tensor\n",
    "\n",
    "    for idx in individual_indices:\n",
    "        # Extract the scaled feature series for steps for the specific individual\n",
    "        scaled_steps_series = perturbed_batch_x[idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X]\n",
    "\n",
    "        # Calculate current \"true\" step values (element-wise for the series)\n",
    "        current_true_steps = scaled_steps_series * STEPS_SCALE + STEPS_OFFSET\n",
    "\n",
    "        # Perturb the \"true\" step values\n",
    "        perturbed_true_steps = current_true_steps * 0\n",
    "        # Convert perturbed \"true\" steps back to scaled values for storage in batch_x\n",
    "        new_scaled_steps_series = (perturbed_true_steps - STEPS_OFFSET) / STEPS_SCALE\n",
    "\n",
    "        # Update the cloned batch_x with the new scaled step series\n",
    "        perturbed_batch_x[idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X] = new_scaled_steps_series\n",
    "\n",
    "\n",
    "    # Reconstruct the data tuple with the perturbed batch_x\n",
    "    new_data_list = list(original_data_tuple)\n",
    "    new_data_list[0] = perturbed_batch_x\n",
    "    new_data_tuple = tuple(new_data_list)\n",
    "    \n",
    "    return new_data_tuple\n",
    "\n",
    "def perturb_steps_and_hr_batch_x(original_data_tuple, individual_indices, percentage_increase, time_steps_to_perturb_start, time_steps_to_perturb_end):\n",
    "    \"\"\"\n",
    "    Perturbs both steps AND heart rate together to maintain physiological correlation\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    STEPS_SCALE = 20.84327263\n",
    "    STEPS_OFFSET = 6.53019535e+00\n",
    "    STEPS_FEATURE_INDEX = 1\n",
    "    \n",
    "    HR_SCALE = 79.3461185\n",
    "    HR_OFFSET = 20.41707644  \n",
    "    HR_FEATURE_INDEX = 0\n",
    "    \n",
    "    original_batch_x = original_data_tuple[0]\n",
    "    perturbed_batch_x = original_batch_x.clone()\n",
    "\n",
    "    for idx in individual_indices:\n",
    "        # Perturb steps\n",
    "        scaled_steps = perturbed_batch_x[idx, time_steps_to_perturb_start:time_steps_to_perturb_end, STEPS_FEATURE_INDEX]\n",
    "        true_steps = scaled_steps * STEPS_SCALE + STEPS_OFFSET\n",
    "\n",
    "        perturbed_true_steps = true_steps * (1 + percentage_increase / 100.0)\n",
    "        new_scaled_steps = (perturbed_true_steps - STEPS_OFFSET) / STEPS_SCALE\n",
    "        perturbed_batch_x[idx, time_steps_to_perturb_start:time_steps_to_perturb_end, STEPS_FEATURE_INDEX] = new_scaled_steps\n",
    "        \n",
    "        # Perturb heart rate proportionally (maybe smaller increase, e.g., 50% of steps increase)\n",
    "        scaled_hr = perturbed_batch_x[idx, time_steps_to_perturb_start:time_steps_to_perturb_end, HR_FEATURE_INDEX]\n",
    "        true_hr = scaled_hr * HR_SCALE + HR_OFFSET\n",
    "        # fit a linear model to the hr and steps and use this to calculate the hr_percentage_increase\n",
    "        # Fit a linear model (least squares) between true_steps and true_hr for this individual\n",
    "        # Only use nonzero steps to avoid spurious correlation with rest periods\n",
    "        import numpy as np\n",
    "\n",
    "        steps_np = true_steps.cpu().numpy() if hasattr(true_steps, \"cpu\") else true_steps.numpy()\n",
    "        hr_np = true_hr.cpu().numpy() if hasattr(true_hr, \"cpu\") else true_hr.numpy()\n",
    "        nonzero_mask = steps_np > 0\n",
    "\n",
    "        if np.sum(nonzero_mask) > 1:\n",
    "            # Fit: hr = a * steps + b\n",
    "            a, b = np.polyfit(steps_np[nonzero_mask], hr_np[nonzero_mask], 1)\n",
    "            # Predict new HR increase based on the increase in steps\n",
    "            avg_steps = np.mean(steps_np[nonzero_mask])\n",
    "            avg_hr = np.mean(hr_np[nonzero_mask])\n",
    "            # Estimate expected HR increase for the given steps increase\n",
    "            expected_hr_increase = a * avg_steps * (percentage_increase / 100.0)\n",
    "            hr_percentage_increase = (expected_hr_increase / avg_hr) * 100 if avg_hr != 0 else percentage_increase * 0.5\n",
    "        else:\n",
    "            hr_percentage_increase = percentage_increase * 0.5  # fallback if not enough data\n",
    "        \n",
    "        hr_percentage_increase = percentage_increase * 0.5  # Adjust this ratio as needed\n",
    "        perturbed_true_hr = true_hr * (1 + hr_percentage_increase / 100.0)\n",
    "        # perturbed_true_hr[~true_steps_zero_mask] = true_hr[~true_steps_zero_mask] * (1 + 30 / 100.0)\n",
    "        new_scaled_hr = (perturbed_true_hr - HR_OFFSET) / HR_SCALE\n",
    "        perturbed_batch_x[idx, time_steps_to_perturb_start:time_steps_to_perturb_end, HR_FEATURE_INDEX] = new_scaled_hr\n",
    "\n",
    "    # Reconstruct tuple\n",
    "    new_data_list = list(original_data_tuple)\n",
    "    new_data_list[0] = perturbed_batch_x\n",
    "    return tuple(new_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original batch size: 256\n",
      "Randomly selected individuals to perturb (indices): [122, 245, 225, 60, 148, 86, 19, 35, 174, 177, 20, 169, 231, 238, 164, 29, 178, 126, 217, 137, 70, 176, 240, 34, 185, 244, 179, 144, 81, 110, 173, 111, 133, 119, 222, 130, 241, 199, 0, 94, 11, 195, 43, 251, 25, 18, 80, 17, 55, 187, 184, 82, 83, 100, 87, 166, 156, 51, 221, 149, 162, 4, 71, 135, 232, 99, 243, 196, 75, 31, 124, 6, 72, 98, 53, 182, 140, 112, 229, 209, 114, 84, 30, 56, 171, 210, 13, 1, 175, 192, 136, 21, 7, 24, 249, 27, 50, 95, 146, 239, 165, 64, 49, 47, 142, 92, 141, 230, 44, 32, 207, 153, 224, 234, 109, 54, 78, 168, 101, 189, 76, 128, 204, 68, 150, 254, 117, 85, 197, 103, 186, 139, 163, 208, 121, 10, 66, 236, 2, 203, 255, 206, 14, 215, 36, 118, 69, 233, 74, 193, 9, 3, 22, 201, 181, 123, 40, 226, 46, 155, 172, 246, 147, 213, 191, 91, 89, 200, 129, 227, 211, 45, 180, 202, 38, 158, 131, 134, 220, 223, 247, 242, 41, 15, 167, 23, 252, 183, 57, 102, 198, 188, 237, 235, 26, 39, 59, 61, 48, 5, 93, 65, 33, 88, 28, 12, 219, 132, 205, 37, 97, 63, 104, 52, 16, 116, 113, 212, 248, 161, 127, 90, 151, 218, 73, 160, 77, 152, 115, 138, 79, 170, 159, 190, 214, 216, 62, 125, 106, 154, 67, 157, 108, 228, 42, 58, 107, 96, 8, 120, 253, 194, 105, 143, 250, 145]\n",
      "Individual 122: Original Steps: 7.23, Perturbed Steps: 28.93\n",
      "Individual 245: Original Steps: 2.58, Perturbed Steps: 10.34\n",
      "Individual 225: Original Steps: 7.76, Perturbed Steps: 31.04\n",
      "Individual 60: Original Steps: 1.05, Perturbed Steps: 4.19\n",
      "Individual 148: Original Steps: 12.43, Perturbed Steps: 49.73\n",
      "Individual 86: Original Steps: 3.26, Perturbed Steps: 13.05\n",
      "Individual 19: Original Steps: 9.68, Perturbed Steps: 38.72\n",
      "Individual 35: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 174: Original Steps: 1.22, Perturbed Steps: 4.87\n",
      "Individual 177: Original Steps: 9.03, Perturbed Steps: 36.11\n",
      "Individual 20: Original Steps: 9.22, Perturbed Steps: 36.86\n",
      "Individual 169: Original Steps: 0.76, Perturbed Steps: 3.05\n",
      "Individual 231: Original Steps: 5.48, Perturbed Steps: 21.90\n",
      "Individual 238: Original Steps: 5.84, Perturbed Steps: 23.36\n",
      "Individual 164: Original Steps: 3.47, Perturbed Steps: 13.90\n",
      "Individual 29: Original Steps: 3.34, Perturbed Steps: 13.35\n",
      "Individual 178: Original Steps: 7.35, Perturbed Steps: 29.40\n",
      "Individual 126: Original Steps: 3.33, Perturbed Steps: 13.33\n",
      "Individual 217: Original Steps: 1.88, Perturbed Steps: 7.52\n",
      "Individual 137: Original Steps: 0.16, Perturbed Steps: 0.64\n",
      "Individual 70: Original Steps: 0.70, Perturbed Steps: 2.82\n",
      "Individual 176: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 240: Original Steps: 1.22, Perturbed Steps: 4.87\n",
      "Individual 34: Original Steps: 1.71, Perturbed Steps: 6.84\n",
      "Individual 185: Original Steps: 17.03, Perturbed Steps: 68.13\n",
      "Individual 244: Original Steps: 5.71, Perturbed Steps: 22.86\n",
      "Individual 179: Original Steps: 0.57, Perturbed Steps: 2.28\n",
      "Individual 144: Original Steps: 7.95, Perturbed Steps: 31.79\n",
      "Individual 81: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 110: Original Steps: 3.07, Perturbed Steps: 12.28\n",
      "Individual 173: Original Steps: 8.47, Perturbed Steps: 33.87\n",
      "Individual 111: Original Steps: 2.86, Perturbed Steps: 11.46\n",
      "Individual 133: Original Steps: 4.21, Perturbed Steps: 16.85\n",
      "Individual 119: Original Steps: 0.18, Perturbed Steps: 0.72\n",
      "Individual 222: Original Steps: 0.16, Perturbed Steps: 0.64\n",
      "Individual 130: Original Steps: 0.82, Perturbed Steps: 3.27\n",
      "Individual 241: Original Steps: 1.67, Perturbed Steps: 6.66\n",
      "Individual 199: Original Steps: 5.90, Perturbed Steps: 23.58\n",
      "Individual 0: Original Steps: 12.42, Perturbed Steps: 49.68\n",
      "Individual 94: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 11: Original Steps: 3.62, Perturbed Steps: 14.48\n",
      "Individual 195: Original Steps: 4.74, Perturbed Steps: 18.97\n",
      "Individual 43: Original Steps: 17.26, Perturbed Steps: 69.05\n",
      "Individual 251: Original Steps: 6.24, Perturbed Steps: 24.95\n",
      "Individual 25: Original Steps: 3.11, Perturbed Steps: 12.45\n",
      "Individual 18: Original Steps: 0.21, Perturbed Steps: 0.85\n",
      "Individual 80: Original Steps: 0.34, Perturbed Steps: 1.37\n",
      "Individual 17: Original Steps: 0.20, Perturbed Steps: 0.78\n",
      "Individual 55: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 187: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 184: Original Steps: 3.09, Perturbed Steps: 12.37\n",
      "Individual 82: Original Steps: 2.74, Perturbed Steps: 10.96\n",
      "Individual 83: Original Steps: 4.63, Perturbed Steps: 18.51\n",
      "Individual 100: Original Steps: 2.34, Perturbed Steps: 9.34\n",
      "Individual 87: Original Steps: 0.43, Perturbed Steps: 1.73\n",
      "Individual 166: Original Steps: 3.18, Perturbed Steps: 12.70\n",
      "Individual 156: Original Steps: 20.73, Perturbed Steps: 82.90\n",
      "Individual 51: Original Steps: 15.65, Perturbed Steps: 62.61\n",
      "Individual 221: Original Steps: 1.89, Perturbed Steps: 7.56\n",
      "Individual 149: Original Steps: 2.21, Perturbed Steps: 8.85\n",
      "Individual 162: Original Steps: 6.83, Perturbed Steps: 27.31\n",
      "Individual 4: Original Steps: 67.07, Perturbed Steps: 268.30\n",
      "Individual 71: Original Steps: 0.62, Perturbed Steps: 2.47\n",
      "Individual 135: Original Steps: 4.74, Perturbed Steps: 18.97\n",
      "Individual 232: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 99: Original Steps: 0.71, Perturbed Steps: 2.83\n",
      "Individual 243: Original Steps: 0.57, Perturbed Steps: 2.26\n",
      "Individual 196: Original Steps: 1.55, Perturbed Steps: 6.22\n",
      "Individual 75: Original Steps: 0.19, Perturbed Steps: 0.75\n",
      "Individual 31: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 124: Original Steps: 7.73, Perturbed Steps: 30.91\n",
      "Individual 6: Original Steps: 1.88, Perturbed Steps: 7.52\n",
      "Individual 72: Original Steps: 5.27, Perturbed Steps: 21.09\n",
      "Individual 98: Original Steps: 6.11, Perturbed Steps: 24.43\n",
      "Individual 53: Original Steps: 3.79, Perturbed Steps: 15.17\n",
      "Individual 182: Original Steps: 8.72, Perturbed Steps: 34.87\n",
      "Individual 140: Original Steps: 3.26, Perturbed Steps: 13.05\n",
      "Individual 112: Original Steps: 3.80, Perturbed Steps: 15.20\n",
      "Individual 229: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 209: Original Steps: 0.71, Perturbed Steps: 2.85\n",
      "Individual 114: Original Steps: 5.76, Perturbed Steps: 23.02\n",
      "Individual 84: Original Steps: 5.71, Perturbed Steps: 22.86\n",
      "Individual 30: Original Steps: 7.20, Perturbed Steps: 28.81\n",
      "Individual 56: Original Steps: 2.15, Perturbed Steps: 8.61\n",
      "Individual 171: Original Steps: 0.57, Perturbed Steps: 2.29\n",
      "Individual 210: Original Steps: 8.66, Perturbed Steps: 34.63\n",
      "Individual 13: Original Steps: 23.47, Perturbed Steps: 93.87\n",
      "Individual 1: Original Steps: 16.45, Perturbed Steps: 65.81\n",
      "Individual 175: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 192: Original Steps: 4.96, Perturbed Steps: 19.84\n",
      "Individual 136: Original Steps: 7.16, Perturbed Steps: 28.63\n",
      "Individual 21: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 7: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 24: Original Steps: 3.38, Perturbed Steps: 13.53\n",
      "Individual 249: Original Steps: 3.62, Perturbed Steps: 14.48\n",
      "Individual 27: Original Steps: 2.41, Perturbed Steps: 9.65\n",
      "Individual 50: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 95: Original Steps: 5.13, Perturbed Steps: 20.51\n",
      "Individual 146: Original Steps: 1.13, Perturbed Steps: 4.50\n",
      "Individual 239: Original Steps: 1.22, Perturbed Steps: 4.86\n",
      "Individual 165: Original Steps: 12.38, Perturbed Steps: 49.54\n",
      "Individual 64: Original Steps: 8.05, Perturbed Steps: 32.20\n",
      "Individual 49: Original Steps: 0.46, Perturbed Steps: 1.83\n",
      "Individual 47: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 142: Original Steps: 5.71, Perturbed Steps: 22.86\n",
      "Individual 92: Original Steps: 0.27, Perturbed Steps: 1.09\n",
      "Individual 141: Original Steps: 0.84, Perturbed Steps: 3.37\n",
      "Individual 230: Original Steps: 0.62, Perturbed Steps: 2.47\n",
      "Individual 44: Original Steps: 34.88, Perturbed Steps: 139.54\n",
      "Individual 32: Original Steps: 2.11, Perturbed Steps: 8.43\n",
      "Individual 207: Original Steps: 5.37, Perturbed Steps: 21.49\n",
      "Individual 153: Original Steps: 3.48, Perturbed Steps: 13.93\n",
      "Individual 224: Original Steps: 8.51, Perturbed Steps: 34.03\n",
      "Individual 234: Original Steps: 0.99, Perturbed Steps: 3.97\n",
      "Individual 109: Original Steps: 0.62, Perturbed Steps: 2.47\n",
      "Individual 54: Original Steps: 8.44, Perturbed Steps: 33.75\n",
      "Individual 78: Original Steps: 3.96, Perturbed Steps: 15.83\n",
      "Individual 168: Original Steps: 7.16, Perturbed Steps: 28.64\n",
      "Individual 101: Original Steps: 7.25, Perturbed Steps: 29.00\n",
      "Individual 189: Original Steps: 1.11, Perturbed Steps: 4.42\n",
      "Individual 76: Original Steps: 7.52, Perturbed Steps: 30.09\n",
      "Individual 128: Original Steps: 1.01, Perturbed Steps: 4.05\n",
      "Individual 204: Original Steps: 17.03, Perturbed Steps: 68.11\n",
      "Individual 68: Original Steps: 33.80, Perturbed Steps: 135.19\n",
      "Individual 150: Original Steps: 0.12, Perturbed Steps: 0.49\n",
      "Individual 254: Original Steps: 8.03, Perturbed Steps: 32.12\n",
      "Individual 117: Original Steps: 1.02, Perturbed Steps: 4.09\n",
      "Individual 85: Original Steps: 3.38, Perturbed Steps: 13.53\n",
      "Individual 197: Original Steps: 11.46, Perturbed Steps: 45.82\n",
      "Individual 103: Original Steps: 4.98, Perturbed Steps: 19.93\n",
      "Individual 186: Original Steps: 5.84, Perturbed Steps: 23.37\n",
      "Individual 139: Original Steps: 3.91, Perturbed Steps: 15.65\n",
      "Individual 163: Original Steps: 7.37, Perturbed Steps: 29.50\n",
      "Individual 208: Original Steps: 4.63, Perturbed Steps: 18.51\n",
      "Individual 121: Original Steps: 1.17, Perturbed Steps: 4.68\n",
      "Individual 10: Original Steps: 1.13, Perturbed Steps: 4.50\n",
      "Individual 66: Original Steps: 4.76, Perturbed Steps: 19.03\n",
      "Individual 236: Original Steps: 1.05, Perturbed Steps: 4.19\n",
      "Individual 2: Original Steps: 1.38, Perturbed Steps: 5.52\n",
      "Individual 203: Original Steps: 3.55, Perturbed Steps: 14.20\n",
      "Individual 255: Original Steps: 0.85, Perturbed Steps: 3.40\n",
      "Individual 206: Original Steps: 7.95, Perturbed Steps: 31.78\n",
      "Individual 14: Original Steps: 2.86, Perturbed Steps: 11.45\n",
      "Individual 215: Original Steps: 0.32, Perturbed Steps: 1.26\n",
      "Individual 36: Original Steps: 1.02, Perturbed Steps: 4.09\n",
      "Individual 118: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 69: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 233: Original Steps: 0.00, Perturbed Steps: 0.00\n",
      "Individual 74: Original Steps: 4.41, Perturbed Steps: 17.62\n",
      "Individual 193: Original Steps: 3.31, Perturbed Steps: 13.25\n",
      "Individual 9: Original Steps: 19.70, Perturbed Steps: 78.82\n",
      "Individual 3: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 22: Original Steps: 1.61, Perturbed Steps: 6.43\n",
      "Individual 201: Original Steps: 5.93, Perturbed Steps: 23.74\n",
      "Individual 181: Original Steps: 5.71, Perturbed Steps: 22.86\n",
      "Individual 123: Original Steps: 13.82, Perturbed Steps: 55.29\n",
      "Individual 40: Original Steps: 31.23, Perturbed Steps: 124.90\n",
      "Individual 226: Original Steps: 5.37, Perturbed Steps: 21.49\n",
      "Individual 46: Original Steps: 1.02, Perturbed Steps: 4.09\n",
      "Individual 155: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 172: Original Steps: 9.90, Perturbed Steps: 39.58\n",
      "Individual 246: Original Steps: 1.10, Perturbed Steps: 4.42\n",
      "Individual 147: Original Steps: 12.71, Perturbed Steps: 50.85\n",
      "Individual 213: Original Steps: 4.87, Perturbed Steps: 19.49\n",
      "Individual 191: Original Steps: 0.47, Perturbed Steps: 1.88\n",
      "Individual 91: Original Steps: 10.38, Perturbed Steps: 41.53\n",
      "Individual 89: Original Steps: 8.61, Perturbed Steps: 34.46\n",
      "Individual 200: Original Steps: 2.91, Perturbed Steps: 11.65\n",
      "Individual 129: Original Steps: 1.65, Perturbed Steps: 6.59\n",
      "Individual 227: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 211: Original Steps: 0.99, Perturbed Steps: 3.97\n",
      "Individual 45: Original Steps: 7.40, Perturbed Steps: 29.60\n",
      "Individual 180: Original Steps: 34.35, Perturbed Steps: 137.41\n",
      "Individual 202: Original Steps: 7.16, Perturbed Steps: 28.63\n",
      "Individual 38: Original Steps: 6.16, Perturbed Steps: 24.63\n",
      "Individual 158: Original Steps: 2.99, Perturbed Steps: 11.95\n",
      "Individual 131: Original Steps: 2.65, Perturbed Steps: 10.61\n",
      "Individual 134: Original Steps: 13.01, Perturbed Steps: 52.03\n",
      "Individual 220: Original Steps: 0.20, Perturbed Steps: 0.78\n",
      "Individual 223: Original Steps: 0.73, Perturbed Steps: 2.93\n",
      "Individual 247: Original Steps: 2.41, Perturbed Steps: 9.65\n",
      "Individual 242: Original Steps: 3.09, Perturbed Steps: 12.37\n",
      "Individual 41: Original Steps: 2.33, Perturbed Steps: 9.31\n",
      "Individual 15: Original Steps: 3.97, Perturbed Steps: 15.88\n",
      "Individual 167: Original Steps: 2.41, Perturbed Steps: 9.65\n",
      "Individual 23: Original Steps: 7.50, Perturbed Steps: 29.99\n",
      "Individual 252: Original Steps: 8.12, Perturbed Steps: 32.49\n",
      "Individual 183: Original Steps: 0.32, Perturbed Steps: 1.28\n",
      "Individual 57: Original Steps: 1.16, Perturbed Steps: 4.64\n",
      "Individual 102: Original Steps: 0.69, Perturbed Steps: 2.75\n",
      "Individual 198: Original Steps: 5.30, Perturbed Steps: 21.19\n",
      "Individual 188: Original Steps: 6.01, Perturbed Steps: 24.02\n",
      "Individual 237: Original Steps: 1.00, Perturbed Steps: 4.01\n",
      "Individual 235: Original Steps: 4.76, Perturbed Steps: 19.06\n",
      "Individual 26: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 39: Original Steps: 4.05, Perturbed Steps: 16.20\n",
      "Individual 59: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 61: Original Steps: 5.37, Perturbed Steps: 21.49\n",
      "Individual 48: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 5: Original Steps: 1.22, Perturbed Steps: 4.90\n",
      "Individual 93: Original Steps: 1.13, Perturbed Steps: 4.50\n",
      "Individual 65: Original Steps: 3.09, Perturbed Steps: 12.36\n",
      "Individual 33: Original Steps: 2.83, Perturbed Steps: 11.33\n",
      "Individual 88: Original Steps: 4.76, Perturbed Steps: 19.06\n",
      "Individual 28: Original Steps: 15.33, Perturbed Steps: 61.30\n",
      "Individual 12: Original Steps: 2.41, Perturbed Steps: 9.65\n",
      "Individual 219: Original Steps: 2.38, Perturbed Steps: 9.52\n",
      "Individual 132: Original Steps: 0.35, Perturbed Steps: 1.39\n",
      "Individual 205: Original Steps: 0.45, Perturbed Steps: 1.79\n",
      "Individual 37: Original Steps: 0.45, Perturbed Steps: 1.79\n",
      "Individual 97: Original Steps: 12.98, Perturbed Steps: 51.94\n",
      "Individual 63: Original Steps: 4.31, Perturbed Steps: 17.25\n",
      "Individual 104: Original Steps: 23.20, Perturbed Steps: 92.80\n",
      "Individual 52: Original Steps: 2.89, Perturbed Steps: 11.56\n",
      "Individual 16: Original Steps: 6.91, Perturbed Steps: 27.63\n",
      "Individual 116: Original Steps: 2.73, Perturbed Steps: 10.90\n",
      "Individual 113: Original Steps: 11.75, Perturbed Steps: 47.01\n",
      "Individual 212: Original Steps: 13.90, Perturbed Steps: 55.61\n",
      "Individual 248: Original Steps: 1.38, Perturbed Steps: 5.52\n",
      "Individual 161: Original Steps: 8.12, Perturbed Steps: 32.49\n",
      "Individual 127: Original Steps: 0.98, Perturbed Steps: 3.90\n",
      "Individual 90: Original Steps: 16.45, Perturbed Steps: 65.81\n",
      "Individual 151: Original Steps: 6.32, Perturbed Steps: 25.30\n",
      "Individual 218: Original Steps: 10.51, Perturbed Steps: 42.04\n",
      "Individual 73: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 160: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 77: Original Steps: 33.80, Perturbed Steps: 135.19\n",
      "Individual 152: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 115: Original Steps: 0.71, Perturbed Steps: 2.85\n",
      "Individual 138: Original Steps: 4.76, Perturbed Steps: 19.06\n",
      "Individual 79: Original Steps: 0.74, Perturbed Steps: 2.94\n",
      "Individual 170: Original Steps: 0.70, Perturbed Steps: 2.82\n",
      "Individual 159: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 190: Original Steps: 0.98, Perturbed Steps: 3.90\n",
      "Individual 214: Original Steps: 2.34, Perturbed Steps: 9.38\n",
      "Individual 216: Original Steps: 1.44, Perturbed Steps: 5.77\n",
      "Individual 62: Original Steps: 0.87, Perturbed Steps: 3.47\n",
      "Individual 125: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 106: Original Steps: 8.24, Perturbed Steps: 32.95\n",
      "Individual 154: Original Steps: 13.45, Perturbed Steps: 53.79\n",
      "Individual 67: Original Steps: 4.76, Perturbed Steps: 19.06\n",
      "Individual 157: Original Steps: 21.22, Perturbed Steps: 84.86\n",
      "Individual 108: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 228: Original Steps: 19.15, Perturbed Steps: 76.62\n",
      "Individual 42: Original Steps: 0.20, Perturbed Steps: 0.81\n",
      "Individual 58: Original Steps: 8.50, Perturbed Steps: 33.99\n",
      "Individual 107: Original Steps: 2.74, Perturbed Steps: 10.96\n",
      "Individual 96: Original Steps: 14.45, Perturbed Steps: 57.81\n",
      "Individual 8: Original Steps: -0.00, Perturbed Steps: -0.00\n",
      "Individual 120: Original Steps: 1.67, Perturbed Steps: 6.68\n",
      "Individual 253: Original Steps: 2.70, Perturbed Steps: 10.82\n",
      "Individual 194: Original Steps: 0.81, Perturbed Steps: 3.26\n",
      "Individual 105: Original Steps: 3.42, Perturbed Steps: 13.69\n",
      "Individual 143: Original Steps: 2.78, Perturbed Steps: 11.10\n",
      "Individual 250: Original Steps: 11.24, Perturbed Steps: 44.96\n",
      "Individual 145: Original Steps: 4.62, Perturbed Steps: 18.47\n",
      "\n",
      "Shape of original sampled output (glucose only): (256, 100, 64)\n",
      "Shape of perturbed sampled output (glucose only): (256, 100, 64)\n"
     ]
    }
   ],
   "source": [
    "# Steps Perturbation Analysis\n",
    "# Using the last batch from model.sample_outputs for perturbation analysis\n",
    "model.cuda()\n",
    "if not model.sample_outputs:\n",
    "    print(\"Error: model.sample_outputs is empty. Please ensure the model has processed data.\")\n",
    "else:\n",
    "    # Use the last batch for perturbation\n",
    "    batch_index_to_perturb = 0\n",
    "    original_batch_data_dict = model.sample_outputs[batch_index_to_perturb]\n",
    "    original_batch_tuple = original_batch_data_dict['batch']\n",
    "    \n",
    "    batch_x_orig, batch_y_orig, batch_x_mark_orig, batch_y_mark_orig = original_batch_tuple[0]\n",
    "    batch_cov_orig = original_batch_tuple[1]\n",
    "    \n",
    "    # Get original predictions before perturbation\n",
    "    sampled_output_before_perturb = original_batch_data_dict['pred'][..., -1]  # Glucose channel only\n",
    "    \n",
    "    num_individuals_in_batch = batch_x_orig.shape[0]\n",
    "    num_to_perturb = min(256, num_individuals_in_batch)\n",
    "    \n",
    "    # Randomly select individuals to perturb\n",
    "    individuals_to_perturb_indices = random.sample(range(num_individuals_in_batch), num_to_perturb)\n",
    "    print(f\"Original batch size: {num_individuals_in_batch}\")\n",
    "    print(f\"Randomly selected individuals to perturb (indices): {individuals_to_perturb_indices}\")\n",
    "    \n",
    "    # Apply steps perturbation with 50% increase\n",
    "    percentage_increase_steps = 300\n",
    "    perturbed_batch_tuple = perturb_steps_and_hr_batch_x(original_batch_tuple[0], individuals_to_perturb_indices, percentage_increase_steps, 0,72)\n",
    "    \n",
    "    # Calculate original and perturbed steps values for comparison\n",
    "    STEPS_SCALE = 20.84327263\n",
    "    STEPS_OFFSET = 6.53019535e+00\n",
    "    STEPS_FEATURE_INDEX_IN_BATCH_X = 1\n",
    "    \n",
    "    original_steps_values = {}\n",
    "    perturbed_steps_values = {}\n",
    "    \n",
    "    for i_idx in individuals_to_perturb_indices:\n",
    "        # Calculate original steps (average across time series)\n",
    "        orig_scaled = batch_x_orig[i_idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X].mean().item()\n",
    "        orig_true_steps = orig_scaled * STEPS_SCALE + STEPS_OFFSET\n",
    "        \n",
    "        # Calculate perturbed steps\n",
    "        pert_scaled = perturbed_batch_tuple[0][i_idx, :, STEPS_FEATURE_INDEX_IN_BATCH_X].mean().item()\n",
    "        pert_true_steps = pert_scaled * STEPS_SCALE + STEPS_OFFSET\n",
    "        \n",
    "        original_steps_values[i_idx] = orig_true_steps\n",
    "        perturbed_steps_values[i_idx] = pert_true_steps\n",
    "        \n",
    "        print(f\"Individual {i_idx}: Original Steps: {orig_true_steps:.2f}, Perturbed Steps: {pert_true_steps:.2f}\")\n",
    "    \n",
    "    # Create perturbed batch for model inference\n",
    "    perturbed_batch_for_sampling = [\n",
    "        perturbed_batch_tuple,\n",
    "        batch_cov_orig\n",
    "    ]\n",
    "    \n",
    "    # Run model inference with perturbed data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model.sample_step(perturbed_batch_for_sampling, 1)\n",
    "    \n",
    "    # Get perturbed predictions\n",
    "    sampled_output_after_perturb = model.sample_outputs[-1]['pred'][..., -1]\n",
    "    \n",
    "    print(f\"\\nShape of original sampled output (glucose only): {sampled_output_before_perturb.shape}\")\n",
    "    print(f\"Shape of perturbed sampled output (glucose only): {sampled_output_after_perturb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation on Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Individual Statistics ===\n",
      "\n",
      "Individual 122:\n",
      "  Steps: 7.23 → 28.93 (300% increase)\n",
      "  Pred Mean: 0.011 → 0.091\n",
      "  Pred Std:  0.487 → 0.585\n",
      "\n",
      "Individual 245:\n",
      "  Steps: 2.58 → 10.34 (300% increase)\n",
      "  Pred Mean: -0.282 → -0.290\n",
      "  Pred Std:  0.415 → 0.417\n",
      "\n",
      "Individual 225:\n",
      "  Steps: 7.76 → 31.04 (300% increase)\n",
      "  Pred Mean: -0.271 → -0.101\n",
      "  Pred Std:  0.415 → 0.565\n",
      "\n",
      "Individual 60:\n",
      "  Steps: 1.05 → 4.19 (300% increase)\n",
      "  Pred Mean: 0.068 → 0.269\n",
      "  Pred Std:  0.756 → 0.859\n",
      "\n",
      "Individual 148:\n",
      "  Steps: 12.43 → 49.73 (300% increase)\n",
      "  Pred Mean: -0.445 → -0.155\n",
      "  Pred Std:  0.424 → 0.554\n",
      "\n",
      "Individual 86:\n",
      "  Steps: 3.26 → 13.05 (300% increase)\n",
      "  Pred Mean: 0.101 → 0.276\n",
      "  Pred Std:  0.450 → 0.538\n",
      "\n",
      "Individual 19:\n",
      "  Steps: 9.68 → 38.72 (300% increase)\n",
      "  Pred Mean: 2.345 → 2.297\n",
      "  Pred Std:  0.958 → 1.070\n",
      "\n",
      "Individual 35:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.191 → -0.157\n",
      "  Pred Std:  0.394 → 0.416\n",
      "\n",
      "Individual 174:\n",
      "  Steps: 1.22 → 4.87 (300% increase)\n",
      "  Pred Mean: -1.175 → -0.970\n",
      "  Pred Std:  0.294 → 0.368\n",
      "\n",
      "Individual 177:\n",
      "  Steps: 9.03 → 36.11 (300% increase)\n",
      "  Pred Mean: 1.946 → 2.257\n",
      "  Pred Std:  0.826 → 0.856\n",
      "\n",
      "Individual 20:\n",
      "  Steps: 9.22 → 36.86 (300% increase)\n",
      "  Pred Mean: -0.743 → -0.926\n",
      "  Pred Std:  0.494 → 0.392\n",
      "\n",
      "Individual 169:\n",
      "  Steps: 0.76 → 3.05 (300% increase)\n",
      "  Pred Mean: -0.754 → -0.852\n",
      "  Pred Std:  0.476 → 0.467\n",
      "\n",
      "Individual 231:\n",
      "  Steps: 5.48 → 21.90 (300% increase)\n",
      "  Pred Mean: 1.169 → 1.145\n",
      "  Pred Std:  0.810 → 0.937\n",
      "\n",
      "Individual 238:\n",
      "  Steps: 5.84 → 23.36 (300% increase)\n",
      "  Pred Mean: 0.521 → 0.669\n",
      "  Pred Std:  0.649 → 0.801\n",
      "\n",
      "Individual 164:\n",
      "  Steps: 3.47 → 13.90 (300% increase)\n",
      "  Pred Mean: 1.057 → 0.785\n",
      "  Pred Std:  0.625 → 0.638\n",
      "\n",
      "Individual 29:\n",
      "  Steps: 3.34 → 13.35 (300% increase)\n",
      "  Pred Mean: 1.019 → 0.339\n",
      "  Pred Std:  0.669 → 0.712\n",
      "\n",
      "Individual 178:\n",
      "  Steps: 7.35 → 29.40 (300% increase)\n",
      "  Pred Mean: 0.228 → 0.225\n",
      "  Pred Std:  0.485 → 0.614\n",
      "\n",
      "Individual 126:\n",
      "  Steps: 3.33 → 13.33 (300% increase)\n",
      "  Pred Mean: 0.640 → -0.008\n",
      "  Pred Std:  0.868 → 0.732\n",
      "\n",
      "Individual 217:\n",
      "  Steps: 1.88 → 7.52 (300% increase)\n",
      "  Pred Mean: 0.289 → 0.113\n",
      "  Pred Std:  0.396 → 0.396\n",
      "\n",
      "Individual 137:\n",
      "  Steps: 0.16 → 0.64 (300% increase)\n",
      "  Pred Mean: -1.056 → -1.050\n",
      "  Pred Std:  0.368 → 0.345\n",
      "\n",
      "Individual 70:\n",
      "  Steps: 0.70 → 2.82 (300% increase)\n",
      "  Pred Mean: 0.843 → 1.399\n",
      "  Pred Std:  0.658 → 0.807\n",
      "\n",
      "Individual 176:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: 0.682 → 0.730\n",
      "  Pred Std:  0.683 → 0.670\n",
      "\n",
      "Individual 240:\n",
      "  Steps: 1.22 → 4.87 (300% increase)\n",
      "  Pred Mean: -0.652 → -0.510\n",
      "  Pred Std:  0.429 → 0.518\n",
      "\n",
      "Individual 34:\n",
      "  Steps: 1.71 → 6.84 (300% increase)\n",
      "  Pred Mean: 0.607 → 0.177\n",
      "  Pred Std:  0.712 → 0.681\n",
      "\n",
      "Individual 185:\n",
      "  Steps: 17.03 → 68.13 (300% increase)\n",
      "  Pred Mean: 0.498 → -0.474\n",
      "  Pred Std:  0.697 → 0.633\n",
      "\n",
      "Individual 244:\n",
      "  Steps: 5.71 → 22.86 (300% increase)\n",
      "  Pred Mean: 0.441 → 0.283\n",
      "  Pred Std:  0.784 → 0.771\n",
      "\n",
      "Individual 179:\n",
      "  Steps: 0.57 → 2.28 (300% increase)\n",
      "  Pred Mean: -0.091 → -0.027\n",
      "  Pred Std:  0.505 → 0.509\n",
      "\n",
      "Individual 144:\n",
      "  Steps: 7.95 → 31.79 (300% increase)\n",
      "  Pred Mean: -0.033 → -0.037\n",
      "  Pred Std:  0.590 → 0.699\n",
      "\n",
      "Individual 81:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.188 → -0.191\n",
      "  Pred Std:  0.382 → 0.401\n",
      "\n",
      "Individual 110:\n",
      "  Steps: 3.07 → 12.28 (300% increase)\n",
      "  Pred Mean: 0.162 → 0.334\n",
      "  Pred Std:  0.528 → 0.624\n",
      "\n",
      "Individual 173:\n",
      "  Steps: 8.47 → 33.87 (300% increase)\n",
      "  Pred Mean: 0.600 → 0.816\n",
      "  Pred Std:  0.640 → 0.834\n",
      "\n",
      "Individual 111:\n",
      "  Steps: 2.86 → 11.46 (300% increase)\n",
      "  Pred Mean: -0.381 → -0.264\n",
      "  Pred Std:  0.550 → 0.639\n",
      "\n",
      "Individual 133:\n",
      "  Steps: 4.21 → 16.85 (300% increase)\n",
      "  Pred Mean: -0.178 → -0.051\n",
      "  Pred Std:  0.658 → 0.700\n",
      "\n",
      "Individual 119:\n",
      "  Steps: 0.18 → 0.72 (300% increase)\n",
      "  Pred Mean: -0.301 → -0.105\n",
      "  Pred Std:  0.462 → 0.515\n",
      "\n",
      "Individual 222:\n",
      "  Steps: 0.16 → 0.64 (300% increase)\n",
      "  Pred Mean: -0.929 → -0.913\n",
      "  Pred Std:  0.408 → 0.397\n",
      "\n",
      "Individual 130:\n",
      "  Steps: 0.82 → 3.27 (300% increase)\n",
      "  Pred Mean: -0.351 → -0.305\n",
      "  Pred Std:  0.491 → 0.561\n",
      "\n",
      "Individual 241:\n",
      "  Steps: 1.67 → 6.66 (300% increase)\n",
      "  Pred Mean: -0.782 → -0.767\n",
      "  Pred Std:  0.422 → 0.450\n",
      "\n",
      "Individual 199:\n",
      "  Steps: 5.90 → 23.58 (300% increase)\n",
      "  Pred Mean: 0.553 → 1.338\n",
      "  Pred Std:  0.620 → 0.702\n",
      "\n",
      "Individual 0:\n",
      "  Steps: 12.42 → 49.68 (300% increase)\n",
      "  Pred Mean: 0.542 → 0.929\n",
      "  Pred Std:  0.705 → 0.726\n",
      "\n",
      "Individual 94:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: 0.697 → 0.762\n",
      "  Pred Std:  0.507 → 0.528\n",
      "\n",
      "Individual 11:\n",
      "  Steps: 3.62 → 14.48 (300% increase)\n",
      "  Pred Mean: 0.925 → 0.197\n",
      "  Pred Std:  0.671 → 0.711\n",
      "\n",
      "Individual 195:\n",
      "  Steps: 4.74 → 18.97 (300% increase)\n",
      "  Pred Mean: -0.389 → -0.326\n",
      "  Pred Std:  0.328 → 0.369\n",
      "\n",
      "Individual 43:\n",
      "  Steps: 17.26 → 69.05 (300% increase)\n",
      "  Pred Mean: 0.290 → 0.418\n",
      "  Pred Std:  0.752 → 0.932\n",
      "\n",
      "Individual 251:\n",
      "  Steps: 6.24 → 24.95 (300% increase)\n",
      "  Pred Mean: 0.485 → -0.395\n",
      "  Pred Std:  0.661 → 0.600\n",
      "\n",
      "Individual 25:\n",
      "  Steps: 3.11 → 12.45 (300% increase)\n",
      "  Pred Mean: 0.602 → 0.286\n",
      "  Pred Std:  0.650 → 0.613\n",
      "\n",
      "Individual 18:\n",
      "  Steps: 0.21 → 0.85 (300% increase)\n",
      "  Pred Mean: 0.601 → 0.658\n",
      "  Pred Std:  0.708 → 0.728\n",
      "\n",
      "Individual 80:\n",
      "  Steps: 0.34 → 1.37 (300% increase)\n",
      "  Pred Mean: -0.689 → -0.632\n",
      "  Pred Std:  0.348 → 0.384\n",
      "\n",
      "Individual 17:\n",
      "  Steps: 0.20 → 0.78 (300% increase)\n",
      "  Pred Mean: 0.005 → 0.059\n",
      "  Pred Std:  0.750 → 0.741\n",
      "\n",
      "Individual 55:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: 0.442 → 0.493\n",
      "  Pred Std:  0.623 → 0.655\n",
      "\n",
      "Individual 187:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.312 → -0.298\n",
      "  Pred Std:  0.576 → 0.598\n",
      "\n",
      "Individual 184:\n",
      "  Steps: 3.09 → 12.37 (300% increase)\n",
      "  Pred Mean: -0.554 → -0.587\n",
      "  Pred Std:  0.310 → 0.333\n",
      "\n",
      "Individual 82:\n",
      "  Steps: 2.74 → 10.96 (300% increase)\n",
      "  Pred Mean: 0.099 → -0.388\n",
      "  Pred Std:  0.838 → 0.717\n",
      "\n",
      "Individual 83:\n",
      "  Steps: 4.63 → 18.51 (300% increase)\n",
      "  Pred Mean: -0.282 → -0.021\n",
      "  Pred Std:  0.617 → 0.696\n",
      "\n",
      "Individual 100:\n",
      "  Steps: 2.34 → 9.34 (300% increase)\n",
      "  Pred Mean: 0.156 → -0.060\n",
      "  Pred Std:  0.580 → 0.582\n",
      "\n",
      "Individual 87:\n",
      "  Steps: 0.43 → 1.73 (300% increase)\n",
      "  Pred Mean: -0.575 → -0.643\n",
      "  Pred Std:  0.538 → 0.522\n",
      "\n",
      "Individual 166:\n",
      "  Steps: 3.18 → 12.70 (300% increase)\n",
      "  Pred Mean: -0.427 → 0.376\n",
      "  Pred Std:  0.461 → 0.620\n",
      "\n",
      "Individual 156:\n",
      "  Steps: 20.73 → 82.90 (300% increase)\n",
      "  Pred Mean: 0.371 → 0.348\n",
      "  Pred Std:  0.665 → 0.730\n",
      "\n",
      "Individual 51:\n",
      "  Steps: 15.65 → 62.61 (300% increase)\n",
      "  Pred Mean: -0.050 → -0.077\n",
      "  Pred Std:  0.654 → 0.725\n",
      "\n",
      "Individual 221:\n",
      "  Steps: 1.89 → 7.56 (300% increase)\n",
      "  Pred Mean: 0.005 → -0.297\n",
      "  Pred Std:  0.589 → 0.511\n",
      "\n",
      "Individual 149:\n",
      "  Steps: 2.21 → 8.85 (300% increase)\n",
      "  Pred Mean: -0.199 → -0.361\n",
      "  Pred Std:  0.387 → 0.379\n",
      "\n",
      "Individual 162:\n",
      "  Steps: 6.83 → 27.31 (300% increase)\n",
      "  Pred Mean: 3.241 → 3.741\n",
      "  Pred Std:  0.956 → 1.085\n",
      "\n",
      "Individual 4:\n",
      "  Steps: 67.07 → 268.30 (300% increase)\n",
      "  Pred Mean: -0.380 → -0.326\n",
      "  Pred Std:  0.410 → 0.475\n",
      "\n",
      "Individual 71:\n",
      "  Steps: 0.62 → 2.47 (300% increase)\n",
      "  Pred Mean: -0.428 → -0.332\n",
      "  Pred Std:  0.428 → 0.467\n",
      "\n",
      "Individual 135:\n",
      "  Steps: 4.74 → 18.97 (300% increase)\n",
      "  Pred Mean: -0.385 → -0.376\n",
      "  Pred Std:  0.330 → 0.369\n",
      "\n",
      "Individual 232:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: 1.450 → 1.520\n",
      "  Pred Std:  0.641 → 0.661\n",
      "\n",
      "Individual 99:\n",
      "  Steps: 0.71 → 2.83 (300% increase)\n",
      "  Pred Mean: 0.157 → 0.372\n",
      "  Pred Std:  0.810 → 0.873\n",
      "\n",
      "Individual 243:\n",
      "  Steps: 0.57 → 2.26 (300% increase)\n",
      "  Pred Mean: -0.035 → -0.117\n",
      "  Pred Std:  0.342 → 0.342\n",
      "\n",
      "Individual 196:\n",
      "  Steps: 1.55 → 6.22 (300% increase)\n",
      "  Pred Mean: 0.724 → 0.615\n",
      "  Pred Std:  0.675 → 0.829\n",
      "\n",
      "Individual 75:\n",
      "  Steps: 0.19 → 0.75 (300% increase)\n",
      "  Pred Mean: -0.245 → -0.116\n",
      "  Pred Std:  0.500 → 0.566\n",
      "\n",
      "Individual 31:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.284 → -0.312\n",
      "  Pred Std:  0.425 → 0.414\n",
      "\n",
      "Individual 124:\n",
      "  Steps: 7.73 → 30.91 (300% increase)\n",
      "  Pred Mean: 1.751 → 0.198\n",
      "  Pred Std:  0.796 → 0.611\n",
      "\n",
      "Individual 6:\n",
      "  Steps: 1.88 → 7.52 (300% increase)\n",
      "  Pred Mean: 0.168 → 0.053\n",
      "  Pred Std:  0.396 → 0.400\n",
      "\n",
      "Individual 72:\n",
      "  Steps: 5.27 → 21.09 (300% increase)\n",
      "  Pred Mean: 0.443 → 0.543\n",
      "  Pred Std:  0.765 → 0.834\n",
      "\n",
      "Individual 98:\n",
      "  Steps: 6.11 → 24.43 (300% increase)\n",
      "  Pred Mean: 0.243 → -0.129\n",
      "  Pred Std:  0.666 → 0.668\n",
      "\n",
      "Individual 53:\n",
      "  Steps: 3.79 → 15.17 (300% increase)\n",
      "  Pred Mean: -0.010 → 0.082\n",
      "  Pred Std:  0.459 → 0.532\n",
      "\n",
      "Individual 182:\n",
      "  Steps: 8.72 → 34.87 (300% increase)\n",
      "  Pred Mean: -0.272 → -0.365\n",
      "  Pred Std:  0.391 → 0.443\n",
      "\n",
      "Individual 140:\n",
      "  Steps: 3.26 → 13.05 (300% increase)\n",
      "  Pred Mean: 0.038 → 0.209\n",
      "  Pred Std:  0.425 → 0.525\n",
      "\n",
      "Individual 112:\n",
      "  Steps: 3.80 → 15.20 (300% increase)\n",
      "  Pred Mean: 0.857 → 1.185\n",
      "  Pred Std:  0.847 → 0.936\n",
      "\n",
      "Individual 229:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.416 → -0.387\n",
      "  Pred Std:  0.307 → 0.325\n",
      "\n",
      "Individual 209:\n",
      "  Steps: 0.71 → 2.85 (300% increase)\n",
      "  Pred Mean: -0.043 → -0.001\n",
      "  Pred Std:  0.421 → 0.459\n",
      "\n",
      "Individual 114:\n",
      "  Steps: 5.76 → 23.02 (300% increase)\n",
      "  Pred Mean: -0.314 → -0.327\n",
      "  Pred Std:  0.407 → 0.473\n",
      "\n",
      "Individual 84:\n",
      "  Steps: 5.71 → 22.86 (300% increase)\n",
      "  Pred Mean: 0.536 → 0.309\n",
      "  Pred Std:  0.827 → 0.791\n",
      "\n",
      "Individual 30:\n",
      "  Steps: 7.20 → 28.81 (300% increase)\n",
      "  Pred Mean: 0.602 → 0.095\n",
      "  Pred Std:  0.623 → 0.712\n",
      "\n",
      "Individual 56:\n",
      "  Steps: 2.15 → 8.61 (300% increase)\n",
      "  Pred Mean: 0.628 → 0.571\n",
      "  Pred Std:  0.857 → 0.846\n",
      "\n",
      "Individual 171:\n",
      "  Steps: 0.57 → 2.29 (300% increase)\n",
      "  Pred Mean: -0.450 → -0.482\n",
      "  Pred Std:  0.549 → 0.514\n",
      "\n",
      "Individual 210:\n",
      "  Steps: 8.66 → 34.63 (300% increase)\n",
      "  Pred Mean: 1.485 → 1.963\n",
      "  Pred Std:  0.843 → 0.895\n",
      "\n",
      "Individual 13:\n",
      "  Steps: 23.47 → 93.87 (300% increase)\n",
      "  Pred Mean: -0.098 → 0.654\n",
      "  Pred Std:  0.615 → 0.763\n",
      "\n",
      "Individual 1:\n",
      "  Steps: 16.45 → 65.81 (300% increase)\n",
      "  Pred Mean: -0.333 → 0.103\n",
      "  Pred Std:  0.406 → 0.520\n",
      "\n",
      "Individual 175:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.335 → -0.230\n",
      "  Pred Std:  0.565 → 0.589\n",
      "\n",
      "Individual 192:\n",
      "  Steps: 4.96 → 19.84 (300% increase)\n",
      "  Pred Mean: -0.090 → -0.022\n",
      "  Pred Std:  0.438 → 0.507\n",
      "\n",
      "Individual 136:\n",
      "  Steps: 7.16 → 28.63 (300% increase)\n",
      "  Pred Mean: -0.305 → 0.139\n",
      "  Pred Std:  0.417 → 0.598\n",
      "\n",
      "Individual 21:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.162 → -0.234\n",
      "  Pred Std:  0.646 → 0.639\n",
      "\n",
      "Individual 7:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.202 → -0.234\n",
      "  Pred Std:  0.387 → 0.376\n",
      "\n",
      "Individual 24:\n",
      "  Steps: 3.38 → 13.53 (300% increase)\n",
      "  Pred Mean: 1.370 → 1.664\n",
      "  Pred Std:  0.754 → 0.774\n",
      "\n",
      "Individual 249:\n",
      "  Steps: 3.62 → 14.48 (300% increase)\n",
      "  Pred Mean: 0.779 → 0.312\n",
      "  Pred Std:  0.679 → 0.714\n",
      "\n",
      "Individual 27:\n",
      "  Steps: 2.41 → 9.65 (300% increase)\n",
      "  Pred Mean: -0.063 → -0.277\n",
      "  Pred Std:  0.633 → 0.587\n",
      "\n",
      "Individual 50:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: 0.010 → 0.061\n",
      "  Pred Std:  0.528 → 0.516\n",
      "\n",
      "Individual 95:\n",
      "  Steps: 5.13 → 20.51 (300% increase)\n",
      "  Pred Mean: -0.774 → -0.210\n",
      "  Pred Std:  0.479 → 0.596\n",
      "\n",
      "Individual 146:\n",
      "  Steps: 1.13 → 4.50 (300% increase)\n",
      "  Pred Mean: 1.378 → 1.785\n",
      "  Pred Std:  0.453 → 0.493\n",
      "\n",
      "Individual 239:\n",
      "  Steps: 1.22 → 4.86 (300% increase)\n",
      "  Pred Mean: 0.388 → -0.008\n",
      "  Pred Std:  0.732 → 0.663\n",
      "\n",
      "Individual 165:\n",
      "  Steps: 12.38 → 49.54 (300% increase)\n",
      "  Pred Mean: 0.014 → -0.115\n",
      "  Pred Std:  0.478 → 0.535\n",
      "\n",
      "Individual 64:\n",
      "  Steps: 8.05 → 32.20 (300% increase)\n",
      "  Pred Mean: 1.083 → 0.262\n",
      "  Pred Std:  0.614 → 0.707\n",
      "\n",
      "Individual 49:\n",
      "  Steps: 0.46 → 1.83 (300% increase)\n",
      "  Pred Mean: -0.757 → -0.818\n",
      "  Pred Std:  0.460 → 0.452\n",
      "\n",
      "Individual 47:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.208 → -0.170\n",
      "  Pred Std:  0.456 → 0.501\n",
      "\n",
      "Individual 142:\n",
      "  Steps: 5.71 → 22.86 (300% increase)\n",
      "  Pred Mean: 0.547 → 0.277\n",
      "  Pred Std:  0.799 → 0.770\n",
      "\n",
      "Individual 92:\n",
      "  Steps: 0.27 → 1.09 (300% increase)\n",
      "  Pred Mean: 0.768 → 0.842\n",
      "  Pred Std:  0.705 → 0.708\n",
      "\n",
      "Individual 141:\n",
      "  Steps: 0.84 → 3.37 (300% increase)\n",
      "  Pred Mean: 1.214 → 1.026\n",
      "  Pred Std:  0.673 → 0.652\n",
      "\n",
      "Individual 230:\n",
      "  Steps: 0.62 → 2.47 (300% increase)\n",
      "  Pred Mean: -0.318 → -0.230\n",
      "  Pred Std:  0.451 → 0.487\n",
      "\n",
      "Individual 44:\n",
      "  Steps: 34.88 → 139.54 (300% increase)\n",
      "  Pred Mean: 1.533 → 2.051\n",
      "  Pred Std:  0.716 → 0.730\n",
      "\n",
      "Individual 32:\n",
      "  Steps: 2.11 → 8.43 (300% increase)\n",
      "  Pred Mean: -0.252 → -0.190\n",
      "  Pred Std:  0.722 → 0.755\n",
      "\n",
      "Individual 207:\n",
      "  Steps: 5.37 → 21.49 (300% increase)\n",
      "  Pred Mean: -0.328 → -0.360\n",
      "  Pred Std:  0.402 → 0.482\n",
      "\n",
      "Individual 153:\n",
      "  Steps: 3.48 → 13.93 (300% increase)\n",
      "  Pred Mean: 0.665 → -0.328\n",
      "  Pred Std:  0.891 → 0.703\n",
      "\n",
      "Individual 224:\n",
      "  Steps: 8.51 → 34.03 (300% increase)\n",
      "  Pred Mean: -0.257 → -0.300\n",
      "  Pred Std:  0.425 → 0.501\n",
      "\n",
      "Individual 234:\n",
      "  Steps: 0.99 → 3.97 (300% increase)\n",
      "  Pred Mean: -0.670 → -0.629\n",
      "  Pred Std:  0.433 → 0.407\n",
      "\n",
      "Individual 109:\n",
      "  Steps: 0.62 → 2.47 (300% increase)\n",
      "  Pred Mean: -0.266 → -0.153\n",
      "  Pred Std:  0.452 → 0.505\n",
      "\n",
      "Individual 54:\n",
      "  Steps: 8.44 → 33.75 (300% increase)\n",
      "  Pred Mean: -0.034 → -0.030\n",
      "  Pred Std:  0.681 → 0.796\n",
      "\n",
      "Individual 78:\n",
      "  Steps: 3.96 → 15.83 (300% increase)\n",
      "  Pred Mean: -0.591 → -0.563\n",
      "  Pred Std:  0.444 → 0.513\n",
      "\n",
      "Individual 168:\n",
      "  Steps: 7.16 → 28.64 (300% increase)\n",
      "  Pred Mean: 0.234 → 0.551\n",
      "  Pred Std:  0.474 → 0.619\n",
      "\n",
      "Individual 101:\n",
      "  Steps: 7.25 → 29.00 (300% increase)\n",
      "  Pred Mean: 0.577 → 1.209\n",
      "  Pred Std:  0.830 → 0.900\n",
      "\n",
      "Individual 189:\n",
      "  Steps: 1.11 → 4.42 (300% increase)\n",
      "  Pred Mean: 1.929 → 2.301\n",
      "  Pred Std:  0.513 → 0.602\n",
      "\n",
      "Individual 76:\n",
      "  Steps: 7.52 → 30.09 (300% increase)\n",
      "  Pred Mean: 0.632 → 1.198\n",
      "  Pred Std:  0.890 → 0.955\n",
      "\n",
      "Individual 128:\n",
      "  Steps: 1.01 → 4.05 (300% increase)\n",
      "  Pred Mean: 0.612 → -0.045\n",
      "  Pred Std:  0.701 → 0.671\n",
      "\n",
      "Individual 204:\n",
      "  Steps: 17.03 → 68.11 (300% increase)\n",
      "  Pred Mean: 0.351 → 0.463\n",
      "  Pred Std:  0.750 → 0.948\n",
      "\n",
      "Individual 68:\n",
      "  Steps: 33.80 → 135.19 (300% increase)\n",
      "  Pred Mean: -0.259 → -0.238\n",
      "  Pred Std:  0.395 → 0.545\n",
      "\n",
      "Individual 150:\n",
      "  Steps: 0.12 → 0.49 (300% increase)\n",
      "  Pred Mean: 0.896 → 0.985\n",
      "  Pred Std:  0.708 → 0.710\n",
      "\n",
      "Individual 254:\n",
      "  Steps: 8.03 → 32.12 (300% increase)\n",
      "  Pred Mean: 0.199 → -0.110\n",
      "  Pred Std:  0.655 → 0.705\n",
      "\n",
      "Individual 117:\n",
      "  Steps: 1.02 → 4.09 (300% increase)\n",
      "  Pred Mean: 0.275 → 0.142\n",
      "  Pred Std:  0.653 → 0.759\n",
      "\n",
      "Individual 85:\n",
      "  Steps: 3.38 → 13.53 (300% increase)\n",
      "  Pred Mean: 1.309 → 1.662\n",
      "  Pred Std:  0.769 → 0.787\n",
      "\n",
      "Individual 197:\n",
      "  Steps: 11.46 → 45.82 (300% increase)\n",
      "  Pred Mean: 2.760 → 2.736\n",
      "  Pred Std:  0.889 → 0.997\n",
      "\n",
      "Individual 103:\n",
      "  Steps: 4.98 → 19.93 (300% increase)\n",
      "  Pred Mean: 1.654 → 1.614\n",
      "  Pred Std:  0.669 → 0.750\n",
      "\n",
      "Individual 186:\n",
      "  Steps: 5.84 → 23.37 (300% increase)\n",
      "  Pred Mean: 0.337 → 0.504\n",
      "  Pred Std:  0.626 → 0.836\n",
      "\n",
      "Individual 139:\n",
      "  Steps: 3.91 → 15.65 (300% increase)\n",
      "  Pred Mean: -0.090 → 0.030\n",
      "  Pred Std:  0.459 → 0.549\n",
      "\n",
      "Individual 163:\n",
      "  Steps: 7.37 → 29.50 (300% increase)\n",
      "  Pred Mean: -0.280 → -0.352\n",
      "  Pred Std:  0.404 → 0.440\n",
      "\n",
      "Individual 208:\n",
      "  Steps: 4.63 → 18.51 (300% increase)\n",
      "  Pred Mean: -0.054 → 0.547\n",
      "  Pred Std:  0.594 → 0.672\n",
      "\n",
      "Individual 121:\n",
      "  Steps: 1.17 → 4.68 (300% increase)\n",
      "  Pred Mean: 2.387 → 1.443\n",
      "  Pred Std:  0.541 → 0.593\n",
      "\n",
      "Individual 10:\n",
      "  Steps: 1.13 → 4.50 (300% increase)\n",
      "  Pred Mean: 0.283 → 0.714\n",
      "  Pred Std:  0.499 → 0.589\n",
      "\n",
      "Individual 66:\n",
      "  Steps: 4.76 → 19.03 (300% increase)\n",
      "  Pred Mean: -0.039 → 0.122\n",
      "  Pred Std:  0.446 → 0.522\n",
      "\n",
      "Individual 236:\n",
      "  Steps: 1.05 → 4.19 (300% increase)\n",
      "  Pred Mean: 0.352 → 0.524\n",
      "  Pred Std:  0.826 → 0.895\n",
      "\n",
      "Individual 2:\n",
      "  Steps: 1.38 → 5.52 (300% increase)\n",
      "  Pred Mean: -0.760 → -0.594\n",
      "  Pred Std:  0.262 → 0.322\n",
      "\n",
      "Individual 203:\n",
      "  Steps: 3.55 → 14.20 (300% increase)\n",
      "  Pred Mean: 0.181 → -0.089\n",
      "  Pred Std:  0.423 → 0.428\n",
      "\n",
      "Individual 255:\n",
      "  Steps: 0.85 → 3.40 (300% increase)\n",
      "  Pred Mean: -0.563 → -0.540\n",
      "  Pred Std:  0.419 → 0.437\n",
      "\n",
      "Individual 206:\n",
      "  Steps: 7.95 → 31.78 (300% increase)\n",
      "  Pred Mean: -0.206 → -0.062\n",
      "  Pred Std:  0.575 → 0.667\n",
      "\n",
      "Individual 14:\n",
      "  Steps: 2.86 → 11.45 (300% increase)\n",
      "  Pred Mean: -0.105 → -0.237\n",
      "  Pred Std:  0.345 → 0.368\n",
      "\n",
      "Individual 215:\n",
      "  Steps: 0.32 → 1.26 (300% increase)\n",
      "  Pred Mean: -0.401 → -0.437\n",
      "  Pred Std:  0.405 → 0.411\n",
      "\n",
      "Individual 36:\n",
      "  Steps: 1.02 → 4.09 (300% increase)\n",
      "  Pred Mean: 0.460 → 0.440\n",
      "  Pred Std:  0.591 → 0.678\n",
      "\n",
      "Individual 118:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.904 → -0.860\n",
      "  Pred Std:  0.371 → 0.409\n",
      "\n",
      "Individual 69:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.127 → -0.140\n",
      "  Pred Std:  0.657 → 0.650\n",
      "\n",
      "Individual 233:\n",
      "  Steps: 0.00 → 0.00 (300% increase)\n",
      "  Pred Mean: 1.244 → 1.284\n",
      "  Pred Std:  0.659 → 0.674\n",
      "\n",
      "Individual 74:\n",
      "  Steps: 4.41 → 17.62 (300% increase)\n",
      "  Pred Mean: 2.140 → 0.765\n",
      "  Pred Std:  0.855 → 0.784\n",
      "\n",
      "Individual 193:\n",
      "  Steps: 3.31 → 13.25 (300% increase)\n",
      "  Pred Mean: -0.667 → -0.568\n",
      "  Pred Std:  0.348 → 0.445\n",
      "\n",
      "Individual 9:\n",
      "  Steps: 19.70 → 78.82 (300% increase)\n",
      "  Pred Mean: -0.115 → -0.091\n",
      "  Pred Std:  0.621 → 0.771\n",
      "\n",
      "Individual 3:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.390 → -0.366\n",
      "  Pred Std:  0.503 → 0.523\n",
      "\n",
      "Individual 22:\n",
      "  Steps: 1.61 → 6.43 (300% increase)\n",
      "  Pred Mean: -0.358 → -0.411\n",
      "  Pred Std:  0.472 → 0.486\n",
      "\n",
      "Individual 201:\n",
      "  Steps: 5.93 → 23.74 (300% increase)\n",
      "  Pred Mean: 1.468 → 2.295\n",
      "  Pred Std:  0.893 → 1.190\n",
      "\n",
      "Individual 181:\n",
      "  Steps: 5.71 → 22.86 (300% increase)\n",
      "  Pred Mean: 0.596 → 0.388\n",
      "  Pred Std:  0.809 → 0.784\n",
      "\n",
      "Individual 123:\n",
      "  Steps: 13.82 → 55.29 (300% increase)\n",
      "  Pred Mean: -0.310 → -0.259\n",
      "  Pred Std:  0.519 → 0.599\n",
      "\n",
      "Individual 40:\n",
      "  Steps: 31.23 → 124.90 (300% increase)\n",
      "  Pred Mean: -0.206 → -0.139\n",
      "  Pred Std:  0.580 → 0.710\n",
      "\n",
      "Individual 226:\n",
      "  Steps: 5.37 → 21.49 (300% increase)\n",
      "  Pred Mean: -0.247 → -0.307\n",
      "  Pred Std:  0.428 → 0.473\n",
      "\n",
      "Individual 46:\n",
      "  Steps: 1.02 → 4.09 (300% increase)\n",
      "  Pred Mean: 1.224 → 0.691\n",
      "  Pred Std:  0.664 → 0.833\n",
      "\n",
      "Individual 155:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.010 → 0.053\n",
      "  Pred Std:  0.471 → 0.498\n",
      "\n",
      "Individual 172:\n",
      "  Steps: 9.90 → 39.58 (300% increase)\n",
      "  Pred Mean: 1.772 → 0.749\n",
      "  Pred Std:  0.809 → 0.796\n",
      "\n",
      "Individual 246:\n",
      "  Steps: 1.10 → 4.42 (300% increase)\n",
      "  Pred Mean: 1.936 → 2.282\n",
      "  Pred Std:  0.525 → 0.592\n",
      "\n",
      "Individual 147:\n",
      "  Steps: 12.71 → 50.85 (300% increase)\n",
      "  Pred Mean: -0.646 → -0.856\n",
      "  Pred Std:  0.539 → 0.543\n",
      "\n",
      "Individual 213:\n",
      "  Steps: 4.87 → 19.49 (300% increase)\n",
      "  Pred Mean: 0.874 → 1.334\n",
      "  Pred Std:  0.633 → 0.749\n",
      "\n",
      "Individual 191:\n",
      "  Steps: 0.47 → 1.88 (300% increase)\n",
      "  Pred Mean: -0.586 → -0.612\n",
      "  Pred Std:  0.422 → 0.422\n",
      "\n",
      "Individual 91:\n",
      "  Steps: 10.38 → 41.53 (300% increase)\n",
      "  Pred Mean: -0.371 → -0.399\n",
      "  Pred Std:  0.408 → 0.462\n",
      "\n",
      "Individual 89:\n",
      "  Steps: 8.61 → 34.46 (300% increase)\n",
      "  Pred Mean: 0.360 → -0.262\n",
      "  Pred Std:  0.624 → 0.597\n",
      "\n",
      "Individual 200:\n",
      "  Steps: 2.91 → 11.65 (300% increase)\n",
      "  Pred Mean: 1.424 → 0.766\n",
      "  Pred Std:  0.615 → 0.669\n",
      "\n",
      "Individual 129:\n",
      "  Steps: 1.65 → 6.59 (300% increase)\n",
      "  Pred Mean: -0.298 → -0.525\n",
      "  Pred Std:  0.594 → 0.580\n",
      "\n",
      "Individual 227:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.274 → -0.311\n",
      "  Pred Std:  0.410 → 0.418\n",
      "\n",
      "Individual 211:\n",
      "  Steps: 0.99 → 3.97 (300% increase)\n",
      "  Pred Mean: -0.686 → -0.617\n",
      "  Pred Std:  0.416 → 0.415\n",
      "\n",
      "Individual 45:\n",
      "  Steps: 7.40 → 29.60 (300% increase)\n",
      "  Pred Mean: 0.881 → 1.072\n",
      "  Pred Std:  0.635 → 0.781\n",
      "\n",
      "Individual 180:\n",
      "  Steps: 34.35 → 137.41 (300% increase)\n",
      "  Pred Mean: 0.071 → 0.239\n",
      "  Pred Std:  0.416 → 0.619\n",
      "\n",
      "Individual 202:\n",
      "  Steps: 7.16 → 28.63 (300% increase)\n",
      "  Pred Mean: -0.249 → 0.071\n",
      "  Pred Std:  0.420 → 0.587\n",
      "\n",
      "Individual 38:\n",
      "  Steps: 6.16 → 24.63 (300% increase)\n",
      "  Pred Mean: 0.785 → 0.280\n",
      "  Pred Std:  0.612 → 0.751\n",
      "\n",
      "Individual 158:\n",
      "  Steps: 2.99 → 11.95 (300% increase)\n",
      "  Pred Mean: 0.388 → -0.006\n",
      "  Pred Std:  0.676 → 0.679\n",
      "\n",
      "Individual 131:\n",
      "  Steps: 2.65 → 10.61 (300% increase)\n",
      "  Pred Mean: -0.265 → -0.253\n",
      "  Pred Std:  0.339 → 0.365\n",
      "\n",
      "Individual 134:\n",
      "  Steps: 13.01 → 52.03 (300% increase)\n",
      "  Pred Mean: -0.055 → -0.141\n",
      "  Pred Std:  0.589 → 0.633\n",
      "\n",
      "Individual 220:\n",
      "  Steps: 0.20 → 0.78 (300% increase)\n",
      "  Pred Mean: -0.099 → -0.063\n",
      "  Pred Std:  0.709 → 0.728\n",
      "\n",
      "Individual 223:\n",
      "  Steps: 0.73 → 2.93 (300% increase)\n",
      "  Pred Mean: -0.625 → -0.655\n",
      "  Pred Std:  0.395 → 0.411\n",
      "\n",
      "Individual 247:\n",
      "  Steps: 2.41 → 9.65 (300% increase)\n",
      "  Pred Mean: -0.044 → -0.309\n",
      "  Pred Std:  0.636 → 0.560\n",
      "\n",
      "Individual 242:\n",
      "  Steps: 3.09 → 12.37 (300% increase)\n",
      "  Pred Mean: -0.557 → -0.579\n",
      "  Pred Std:  0.300 → 0.337\n",
      "\n",
      "Individual 41:\n",
      "  Steps: 2.33 → 9.31 (300% increase)\n",
      "  Pred Mean: 0.713 → 0.762\n",
      "  Pred Std:  0.902 → 0.997\n",
      "\n",
      "Individual 15:\n",
      "  Steps: 3.97 → 15.88 (300% increase)\n",
      "  Pred Mean: -0.318 → -0.371\n",
      "  Pred Std:  0.329 → 0.339\n",
      "\n",
      "Individual 167:\n",
      "  Steps: 2.41 → 9.65 (300% increase)\n",
      "  Pred Mean: 0.207 → -0.412\n",
      "  Pred Std:  0.656 → 0.531\n",
      "\n",
      "Individual 23:\n",
      "  Steps: 7.50 → 29.99 (300% increase)\n",
      "  Pred Mean: -0.003 → 0.228\n",
      "  Pred Std:  0.459 → 0.538\n",
      "\n",
      "Individual 252:\n",
      "  Steps: 8.12 → 32.49 (300% increase)\n",
      "  Pred Mean: -0.215 → -0.505\n",
      "  Pred Std:  0.565 → 0.540\n",
      "\n",
      "Individual 183:\n",
      "  Steps: 0.32 → 1.28 (300% increase)\n",
      "  Pred Mean: -0.730 → -0.709\n",
      "  Pred Std:  0.369 → 0.383\n",
      "\n",
      "Individual 57:\n",
      "  Steps: 1.16 → 4.64 (300% increase)\n",
      "  Pred Mean: -0.361 → -0.412\n",
      "  Pred Std:  0.460 → 0.492\n",
      "\n",
      "Individual 102:\n",
      "  Steps: 0.69 → 2.75 (300% increase)\n",
      "  Pred Mean: -0.387 → -0.241\n",
      "  Pred Std:  0.431 → 0.523\n",
      "\n",
      "Individual 198:\n",
      "  Steps: 5.30 → 21.19 (300% increase)\n",
      "  Pred Mean: 0.023 → 0.100\n",
      "  Pred Std:  0.474 → 0.585\n",
      "\n",
      "Individual 188:\n",
      "  Steps: 6.01 → 24.02 (300% increase)\n",
      "  Pred Mean: 0.921 → 0.072\n",
      "  Pred Std:  0.619 → 0.630\n",
      "\n",
      "Individual 237:\n",
      "  Steps: 1.00 → 4.01 (300% increase)\n",
      "  Pred Mean: 0.642 → 0.025\n",
      "  Pred Std:  0.592 → 0.608\n",
      "\n",
      "Individual 235:\n",
      "  Steps: 4.76 → 19.06 (300% increase)\n",
      "  Pred Mean: 0.896 → 0.171\n",
      "  Pred Std:  0.612 → 0.637\n",
      "\n",
      "Individual 26:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.547 → -0.437\n",
      "  Pred Std:  0.542 → 0.572\n",
      "\n",
      "Individual 39:\n",
      "  Steps: 4.05 → 16.20 (300% increase)\n",
      "  Pred Mean: 0.581 → -0.081\n",
      "  Pred Std:  0.653 → 0.724\n",
      "\n",
      "Individual 59:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.631 → -0.661\n",
      "  Pred Std:  0.467 → 0.474\n",
      "\n",
      "Individual 61:\n",
      "  Steps: 5.37 → 21.49 (300% increase)\n",
      "  Pred Mean: -0.335 → -0.375\n",
      "  Pred Std:  0.405 → 0.452\n",
      "\n",
      "Individual 48:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.220 → -0.202\n",
      "  Pred Std:  0.485 → 0.491\n",
      "\n",
      "Individual 5:\n",
      "  Steps: 1.22 → 4.90 (300% increase)\n",
      "  Pred Mean: -0.264 → -0.280\n",
      "  Pred Std:  0.396 → 0.434\n",
      "\n",
      "Individual 93:\n",
      "  Steps: 1.13 → 4.50 (300% increase)\n",
      "  Pred Mean: 0.394 → 0.812\n",
      "  Pred Std:  0.482 → 0.557\n",
      "\n",
      "Individual 65:\n",
      "  Steps: 3.09 → 12.36 (300% increase)\n",
      "  Pred Mean: -0.030 → 0.092\n",
      "  Pred Std:  0.463 → 0.533\n",
      "\n",
      "Individual 33:\n",
      "  Steps: 2.83 → 11.33 (300% increase)\n",
      "  Pred Mean: -0.685 → -0.608\n",
      "  Pred Std:  0.348 → 0.437\n",
      "\n",
      "Individual 88:\n",
      "  Steps: 4.76 → 19.06 (300% increase)\n",
      "  Pred Mean: 1.221 → 0.544\n",
      "  Pred Std:  0.598 → 0.661\n",
      "\n",
      "Individual 28:\n",
      "  Steps: 15.33 → 61.30 (300% increase)\n",
      "  Pred Mean: -0.321 → -0.384\n",
      "  Pred Std:  0.439 → 0.474\n",
      "\n",
      "Individual 12:\n",
      "  Steps: 2.41 → 9.65 (300% increase)\n",
      "  Pred Mean: 0.393 → -0.296\n",
      "  Pred Std:  0.656 → 0.574\n",
      "\n",
      "Individual 219:\n",
      "  Steps: 2.38 → 9.52 (300% increase)\n",
      "  Pred Mean: -0.191 → -0.080\n",
      "  Pred Std:  0.534 → 0.579\n",
      "\n",
      "Individual 132:\n",
      "  Steps: 0.35 → 1.39 (300% increase)\n",
      "  Pred Mean: -0.073 → -0.015\n",
      "  Pred Std:  0.406 → 0.426\n",
      "\n",
      "Individual 205:\n",
      "  Steps: 0.45 → 1.79 (300% increase)\n",
      "  Pred Mean: -0.371 → -0.411\n",
      "  Pred Std:  0.469 → 0.454\n",
      "\n",
      "Individual 37:\n",
      "  Steps: 0.45 → 1.79 (300% increase)\n",
      "  Pred Mean: -0.296 → -0.361\n",
      "  Pred Std:  0.481 → 0.479\n",
      "\n",
      "Individual 97:\n",
      "  Steps: 12.98 → 51.94 (300% increase)\n",
      "  Pred Mean: -0.424 → -0.551\n",
      "  Pred Std:  0.555 → 0.563\n",
      "\n",
      "Individual 63:\n",
      "  Steps: 4.31 → 17.25 (300% increase)\n",
      "  Pred Mean: -0.363 → -0.039\n",
      "  Pred Std:  0.452 → 0.580\n",
      "\n",
      "Individual 104:\n",
      "  Steps: 23.20 → 92.80 (300% increase)\n",
      "  Pred Mean: 0.055 → 0.336\n",
      "  Pred Std:  0.627 → 0.761\n",
      "\n",
      "Individual 52:\n",
      "  Steps: 2.89 → 11.56 (300% increase)\n",
      "  Pred Mean: -0.408 → -0.492\n",
      "  Pred Std:  0.480 → 0.564\n",
      "\n",
      "Individual 16:\n",
      "  Steps: 6.91 → 27.63 (300% increase)\n",
      "  Pred Mean: -0.382 → -0.305\n",
      "  Pred Std:  0.342 → 0.392\n",
      "\n",
      "Individual 116:\n",
      "  Steps: 2.73 → 10.90 (300% increase)\n",
      "  Pred Mean: -0.673 → -0.529\n",
      "  Pred Std:  0.360 → 0.462\n",
      "\n",
      "Individual 113:\n",
      "  Steps: 11.75 → 47.01 (300% increase)\n",
      "  Pred Mean: 1.786 → 1.759\n",
      "  Pred Std:  0.911 → 0.953\n",
      "\n",
      "Individual 212:\n",
      "  Steps: 13.90 → 55.61 (300% increase)\n",
      "  Pred Mean: 0.200 → 0.616\n",
      "  Pred Std:  0.653 → 0.744\n",
      "\n",
      "Individual 248:\n",
      "  Steps: 1.38 → 5.52 (300% increase)\n",
      "  Pred Mean: -0.819 → -0.636\n",
      "  Pred Std:  0.268 → 0.317\n",
      "\n",
      "Individual 161:\n",
      "  Steps: 8.12 → 32.49 (300% increase)\n",
      "  Pred Mean: -0.146 → -0.466\n",
      "  Pred Std:  0.585 → 0.561\n",
      "\n",
      "Individual 127:\n",
      "  Steps: 0.98 → 3.90 (300% increase)\n",
      "  Pred Mean: 2.478 → 1.868\n",
      "  Pred Std:  0.547 → 0.554\n",
      "\n",
      "Individual 90:\n",
      "  Steps: 16.45 → 65.81 (300% increase)\n",
      "  Pred Mean: -0.332 → 0.138\n",
      "  Pred Std:  0.415 → 0.535\n",
      "\n",
      "Individual 151:\n",
      "  Steps: 6.32 → 25.30 (300% increase)\n",
      "  Pred Mean: -0.231 → -0.136\n",
      "  Pred Std:  0.552 → 0.677\n",
      "\n",
      "Individual 218:\n",
      "  Steps: 10.51 → 42.04 (300% increase)\n",
      "  Pred Mean: 0.755 → -0.102\n",
      "  Pred Std:  0.802 → 0.639\n",
      "\n",
      "Individual 73:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.071 → -0.060\n",
      "  Pred Std:  0.699 → 0.690\n",
      "\n",
      "Individual 160:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: 0.328 → 0.362\n",
      "  Pred Std:  0.576 → 0.583\n",
      "\n",
      "Individual 77:\n",
      "  Steps: 33.80 → 135.19 (300% increase)\n",
      "  Pred Mean: -0.273 → -0.280\n",
      "  Pred Std:  0.398 → 0.516\n",
      "\n",
      "Individual 152:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.335 → -0.352\n",
      "  Pred Std:  0.407 → 0.393\n",
      "\n",
      "Individual 115:\n",
      "  Steps: 0.71 → 2.85 (300% increase)\n",
      "  Pred Mean: -0.043 → -0.006\n",
      "  Pred Std:  0.416 → 0.450\n",
      "\n",
      "Individual 138:\n",
      "  Steps: 4.76 → 19.06 (300% increase)\n",
      "  Pred Mean: 0.756 → 0.536\n",
      "  Pred Std:  0.643 → 0.669\n",
      "\n",
      "Individual 79:\n",
      "  Steps: 0.74 → 2.94 (300% increase)\n",
      "  Pred Mean: -0.249 → -0.099\n",
      "  Pred Std:  0.502 → 0.542\n",
      "\n",
      "Individual 170:\n",
      "  Steps: 0.70 → 2.82 (300% increase)\n",
      "  Pred Mean: 0.357 → 1.241\n",
      "  Pred Std:  0.638 → 0.783\n",
      "\n",
      "Individual 159:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.477 → -0.446\n",
      "  Pred Std:  0.537 → 0.540\n",
      "\n",
      "Individual 190:\n",
      "  Steps: 0.98 → 3.90 (300% increase)\n",
      "  Pred Mean: -0.071 → -0.022\n",
      "  Pred Std:  0.416 → 0.460\n",
      "\n",
      "Individual 214:\n",
      "  Steps: 2.34 → 9.38 (300% increase)\n",
      "  Pred Mean: 0.708 → 0.128\n",
      "  Pred Std:  0.680 → 0.590\n",
      "\n",
      "Individual 216:\n",
      "  Steps: 1.44 → 5.77 (300% increase)\n",
      "  Pred Mean: -0.398 → -0.430\n",
      "  Pred Std:  0.530 → 0.554\n",
      "\n",
      "Individual 62:\n",
      "  Steps: 0.87 → 3.47 (300% increase)\n",
      "  Pred Mean: 0.754 → 0.814\n",
      "  Pred Std:  0.444 → 0.465\n",
      "\n",
      "Individual 125:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.548 → -0.530\n",
      "  Pred Std:  0.282 → 0.286\n",
      "\n",
      "Individual 106:\n",
      "  Steps: 8.24 → 32.95 (300% increase)\n",
      "  Pred Mean: 0.352 → 0.513\n",
      "  Pred Std:  0.633 → 0.806\n",
      "\n",
      "Individual 154:\n",
      "  Steps: 13.45 → 53.79 (300% increase)\n",
      "  Pred Mean: 0.276 → 0.390\n",
      "  Pred Std:  0.649 → 0.766\n",
      "\n",
      "Individual 67:\n",
      "  Steps: 4.76 → 19.06 (300% increase)\n",
      "  Pred Mean: 1.237 → 0.585\n",
      "  Pred Std:  0.596 → 0.675\n",
      "\n",
      "Individual 157:\n",
      "  Steps: 21.22 → 84.86 (300% increase)\n",
      "  Pred Mean: 0.282 → 0.040\n",
      "  Pred Std:  0.734 → 0.916\n",
      "\n",
      "Individual 108:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: -0.195 → -0.306\n",
      "  Pred Std:  0.631 → 0.613\n",
      "\n",
      "Individual 228:\n",
      "  Steps: 19.15 → 76.62 (300% increase)\n",
      "  Pred Mean: -0.307 → -0.052\n",
      "  Pred Std:  0.341 → 0.491\n",
      "\n",
      "Individual 42:\n",
      "  Steps: 0.20 → 0.81 (300% increase)\n",
      "  Pred Mean: -0.634 → -0.640\n",
      "  Pred Std:  0.310 → 0.302\n",
      "\n",
      "Individual 58:\n",
      "  Steps: 8.50 → 33.99 (300% increase)\n",
      "  Pred Mean: -0.688 → -0.578\n",
      "  Pred Std:  0.312 → 0.395\n",
      "\n",
      "Individual 107:\n",
      "  Steps: 2.74 → 10.96 (300% increase)\n",
      "  Pred Mean: -0.402 → -0.839\n",
      "  Pred Std:  0.685 → 0.538\n",
      "\n",
      "Individual 96:\n",
      "  Steps: 14.45 → 57.81 (300% increase)\n",
      "  Pred Mean: -0.378 → -0.363\n",
      "  Pred Std:  0.504 → 0.558\n",
      "\n",
      "Individual 8:\n",
      "  Steps: -0.00 → -0.00 (300% increase)\n",
      "  Pred Mean: 0.150 → 0.199\n",
      "  Pred Std:  0.554 → 0.565\n",
      "\n",
      "Individual 120:\n",
      "  Steps: 1.67 → 6.68 (300% increase)\n",
      "  Pred Mean: -0.061 → -0.217\n",
      "  Pred Std:  0.352 → 0.355\n",
      "\n",
      "Individual 253:\n",
      "  Steps: 2.70 → 10.82 (300% increase)\n",
      "  Pred Mean: -0.605 → -0.606\n",
      "  Pred Std:  0.293 → 0.327\n",
      "\n",
      "Individual 194:\n",
      "  Steps: 0.81 → 3.26 (300% increase)\n",
      "  Pred Mean: 0.147 → 0.362\n",
      "  Pred Std:  0.511 → 0.554\n",
      "\n",
      "Individual 105:\n",
      "  Steps: 3.42 → 13.69 (300% increase)\n",
      "  Pred Mean: 1.604 → 1.525\n",
      "  Pred Std:  0.573 → 0.626\n",
      "\n",
      "Individual 143:\n",
      "  Steps: 2.78 → 11.10 (300% increase)\n",
      "  Pred Mean: -0.416 → -0.434\n",
      "  Pred Std:  0.326 → 0.343\n",
      "\n",
      "Individual 250:\n",
      "  Steps: 11.24 → 44.96 (300% increase)\n",
      "  Pred Mean: 1.699 → 2.331\n",
      "  Pred Std:  0.840 → 0.963\n",
      "\n",
      "Individual 145:\n",
      "  Steps: 4.62 → 18.47 (300% increase)\n",
      "  Pred Mean: -0.052 → -0.272\n",
      "  Pred Std:  0.585 → 0.615\n",
      "\n",
      "=== Overall Statistics ===\n",
      "Overall prediction mean change: 0.169 → 0.141\n",
      "Overall prediction std change:  0.556 → 0.600\n",
      "\n",
      "=== Summary Analysis ===\n",
      "Average steps increase applied: 300%\n",
      "Number of individuals perturbed: 256\n",
      "Average glucose prediction change (perturbed): -0.0280\n",
      "Average glucose prediction change (control): nan\n",
      "Differential effect: nan\n"
     ]
    }
   ],
   "source": [
    "# Plotting and Statistical Analysis of Steps Perturbation Results\n",
    "\n",
    "# Calculate prediction statistics\n",
    "pred_mean_before = sampled_output_before_perturb.mean(axis=1)  # Mean across samples\n",
    "pred_std_before = sampled_output_before_perturb.std(axis=1)    # Std across samples\n",
    "pred_mean_after = sampled_output_after_perturb.mean(axis=1)   # Mean across samples  \n",
    "pred_std_after = sampled_output_after_perturb.std(axis=1)     # Std across samples\n",
    "\n",
    "# Print individual statistics for perturbed individuals\n",
    "print(\"\\n=== Individual Statistics ===\")\n",
    "for i_idx in individuals_to_perturb_indices:\n",
    "    print(f\"\\nIndividual {i_idx}:\")\n",
    "    print(f\"  Steps: {original_steps_values[i_idx]:.2f} → {perturbed_steps_values[i_idx]:.2f} ({percentage_increase_steps}% increase)\")\n",
    "    print(f\"  Pred Mean: {pred_mean_before[i_idx].mean():.3f} → {pred_mean_after[i_idx].mean():.3f}\")\n",
    "    print(f\"  Pred Std:  {pred_std_before[i_idx].mean():.3f} → {pred_std_after[i_idx].mean():.3f}\")\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\n=== Overall Statistics ===\")\n",
    "print(f\"Overall prediction mean change: {pred_mean_before.mean():.3f} → {pred_mean_after.mean():.3f}\")\n",
    "print(f\"Overall prediction std change:  {pred_std_before.mean():.3f} → {pred_std_after.mean():.3f}\")\n",
    "\n",
    "# Create plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Steps Perturbation Analysis Results', fontsize=16)\n",
    "\n",
    "# Plot 1: Individual glucose predictions before/after for selected individuals\n",
    "ax1 = axes[0, 0]\n",
    "n_individuals_to_plot = min(3, len(individuals_to_perturb_indices))\n",
    "for plot_idx, i_idx in enumerate(individuals_to_perturb_indices[:n_individuals_to_plot]):\n",
    "    time_steps = range(pred_mean_before.shape[1])\n",
    "    ax1.plot(time_steps, pred_mean_before[i_idx], 'b-', alpha=0.7, label=f'Before (Ind {i_idx})' if plot_idx == 0 else \"\")\n",
    "    ax1.plot(time_steps, pred_mean_after[i_idx], 'r--', alpha=0.7, label=f'After (Ind {i_idx})' if plot_idx == 0 else \"\")\n",
    "\n",
    "ax1.set_title('Individual Glucose Predictions')\n",
    "ax1.set_xlabel('Time Steps')\n",
    "ax1.set_ylabel('Glucose Level')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Average prediction change across all perturbed individuals\n",
    "ax2 = axes[0, 1]\n",
    "perturbed_before = pred_mean_before[individuals_to_perturb_indices]\n",
    "perturbed_after = pred_mean_after[individuals_to_perturb_indices]\n",
    "time_steps = range(pred_mean_before.shape[1])\n",
    "ax2.plot(time_steps, perturbed_before.mean(axis=0), 'b-', linewidth=2, label='Before Perturbation')\n",
    "ax2.plot(time_steps, perturbed_after.mean(axis=0), 'r-', linewidth=2, label='After Perturbation')\n",
    "ax2.fill_between(time_steps, \n",
    "                 perturbed_before.mean(axis=0) - perturbed_before.std(axis=0),\n",
    "                 perturbed_before.mean(axis=0) + perturbed_before.std(axis=0),\n",
    "                 alpha=0.2, color='blue')\n",
    "ax2.fill_between(time_steps,\n",
    "                 perturbed_after.mean(axis=0) - perturbed_after.std(axis=0), \n",
    "                 perturbed_after.mean(axis=0) + perturbed_after.std(axis=0),\n",
    "                 alpha=0.2, color='red')\n",
    "ax2.set_title('Average Glucose Predictions (Perturbed Individuals)')\n",
    "ax2.set_xlabel('Time Steps')\n",
    "ax2.set_ylabel('Glucose Level')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Steps values comparison\n",
    "ax3 = axes[1, 0]\n",
    "individuals_plot = list(individuals_to_perturb_indices[:5])  # Show first 5\n",
    "orig_steps = [original_steps_values[i] for i in individuals_plot]\n",
    "pert_steps = [perturbed_steps_values[i] for i in individuals_plot]\n",
    "x_pos = range(len(individuals_plot))\n",
    "width = 0.35\n",
    "ax3.bar([x - width/2 for x in x_pos], orig_steps, width, label='Original Steps', alpha=0.7)\n",
    "ax3.bar([x + width/2 for x in x_pos], pert_steps, width, label='Perturbed Steps', alpha=0.7)\n",
    "ax3.set_title('Steps Values: Before vs After Perturbation')\n",
    "ax3.set_xlabel('Individual Index')\n",
    "ax3.set_ylabel('Steps Value')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([f'Ind {i}' for i in individuals_plot])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Prediction difference distribution\n",
    "ax4 = axes[1, 1]\n",
    "pred_diff = pred_mean_after - pred_mean_before\n",
    "perturbed_diff = pred_diff[individuals_to_perturb_indices].flatten()\n",
    "control_diff = np.delete(pred_diff, individuals_to_perturb_indices, axis=0).flatten()\n",
    "ax4.hist(perturbed_diff, bins=30, alpha=0.7, label='Perturbed Individuals', color='red')\n",
    "ax4.hist(control_diff, bins=30, alpha=0.7, label='Control Individuals', color='blue')\n",
    "ax4.set_title('Distribution of Prediction Changes')\n",
    "ax4.set_xlabel('Glucose Prediction Change')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary analysis\n",
    "print(f\"\\n=== Summary Analysis ===\")\n",
    "print(f\"Average steps increase applied: {percentage_increase_steps}%\")\n",
    "print(f\"Number of individuals perturbed: {len(individuals_to_perturb_indices)}\")\n",
    "mean_pred_change_perturbed = pred_diff[individuals_to_perturb_indices].mean()\n",
    "mean_pred_change_control = np.delete(pred_diff, individuals_to_perturb_indices, axis=0).mean()\n",
    "print(f\"Average glucose prediction change (perturbed): {mean_pred_change_perturbed:.4f}\")\n",
    "print(f\"Average glucose prediction change (control): {mean_pred_change_control:.4f}\")\n",
    "print(f\"Differential effect: {mean_pred_change_perturbed - mean_pred_change_control:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Steps Perturbation Summary Analysis ===\n",
      "Perturbation applied: 300% change in steps\n",
      "Number of individuals perturbed: 256\n",
      "Average 95 %-CI width change (perturbed individuals): +0.0086\n",
      "Average 95 %-CI width change (control individuals)  : +0.0000\n",
      "Average glucose prediction change  (perturbed) : -0.0280\n",
      "Average glucose prediction change  (control)   : +0.0000\n",
      "Differential effect of steps perturbation      : -0.0280\n",
      "\n",
      "=== Individual Results (|Δµ| ≥ 0.1) ===\n",
      "Individual 122:\n",
      "  CI change: 0.019194925799456024\n",
      "  Steps change: 7.2 → 28.9 (+21.7)\n",
      "before pred: 0.010781013530374209\n",
      "after pred: 0.09090202083488372\n",
      "  Avg glucose prediction change: +0.0350\n",
      "Individual 245:\n",
      "  CI change: 0.0004849335887726035\n",
      "  Steps change: 2.6 → 10.3 (+7.8)\n",
      "before pred: -0.2817430885760418\n",
      "after pred: -0.29020369639684634\n",
      "  Avg glucose prediction change: -0.0331\n",
      "Individual 225:\n",
      "  CI change: 0.029444911996425772\n",
      "  Steps change: 7.8 → 31.0 (+23.3)\n",
      "before pred: -0.27128292935868115\n",
      "after pred: -0.10107372709691531\n",
      "  Avg glucose prediction change: -0.3088\n",
      "Individual 60:\n",
      "  CI change: 0.020147837152859987\n",
      "  Steps change: 1.0 → 4.2 (+3.1)\n",
      "before pred: 0.06827696011681023\n",
      "after pred: 0.26930580053827247\n",
      "  Avg glucose prediction change: +0.1532\n",
      "Individual 148:\n",
      "  CI change: 0.02553799163761259\n",
      "  Steps change: 12.4 → 49.7 (+37.3)\n",
      "before pred: -0.4447648747467174\n",
      "after pred: -0.15546581290425676\n",
      "  Avg glucose prediction change: +0.1630\n",
      "Individual 86:\n",
      "  CI change: 0.0173011236677884\n",
      "  Steps change: 3.3 → 13.0 (+9.8)\n",
      "before pred: 0.10087504870118846\n",
      "after pred: 0.276065886648444\n",
      "  Avg glucose prediction change: +0.1106\n",
      "Individual 19:\n",
      "  CI change: 0.02197613842635375\n",
      "  Steps change: 9.7 → 38.7 (+29.0)\n",
      "before pred: 2.3451275347735923\n",
      "after pred: 2.2973181153937463\n",
      "  Avg glucose prediction change: -0.0571\n",
      "Individual 174:\n",
      "  CI change: 0.014499187605480818\n",
      "  Steps change: 1.2 → 4.9 (+3.7)\n",
      "before pred: -1.174865329349894\n",
      "after pred: -0.9696573967763003\n",
      "  Avg glucose prediction change: +0.0941\n",
      "Individual 177:\n",
      "  CI change: 0.005800908643383276\n",
      "  Steps change: 9.0 → 36.1 (+27.1)\n",
      "before pred: 1.9459785186863174\n",
      "after pred: 2.2572755034638403\n",
      "  Avg glucose prediction change: +0.8248\n",
      "Individual 20:\n",
      "  CI change: -0.020046264329198593\n",
      "  Steps change: 9.2 → 36.9 (+27.6)\n",
      "before pred: -0.7430477285536393\n",
      "after pred: -0.9263002821328141\n",
      "  Avg glucose prediction change: +0.0126\n",
      "Individual 169:\n",
      "  CI change: -0.0018577400509378762\n",
      "  Steps change: 0.8 → 3.1 (+2.3)\n",
      "before pred: -0.7541928966564432\n",
      "after pred: -0.85229869951819\n",
      "  Avg glucose prediction change: +0.0297\n",
      "Individual 231:\n",
      "  CI change: 0.024813397033626724\n",
      "  Steps change: 5.5 → 21.9 (+16.4)\n",
      "before pred: 1.1692582964572447\n",
      "after pred: 1.1452528305881766\n",
      "  Avg glucose prediction change: -0.1345\n",
      "Individual 238:\n",
      "  CI change: 0.02978331381667287\n",
      "  Steps change: 5.8 → 23.4 (+17.5)\n",
      "before pred: 0.5207645846796174\n",
      "after pred: 0.6692810262241312\n",
      "  Avg glucose prediction change: +0.0795\n",
      "Individual 164:\n",
      "  CI change: 0.0024370457474298937\n",
      "  Steps change: 3.5 → 13.9 (+10.4)\n",
      "before pred: 1.056915279242986\n",
      "after pred: 0.7854611510566734\n",
      "  Avg glucose prediction change: -0.2282\n",
      "Individual 29:\n",
      "  CI change: 0.00852020000588495\n",
      "  Steps change: 3.3 → 13.3 (+10.0)\n",
      "before pred: 1.0193803502581322\n",
      "after pred: 0.33854493069000235\n",
      "  Avg glucose prediction change: -0.7914\n",
      "Individual 178:\n",
      "  CI change: 0.0253341695452221\n",
      "  Steps change: 7.4 → 29.4 (+22.1)\n",
      "before pred: 0.22771494594549338\n",
      "after pred: 0.22505270413134912\n",
      "  Avg glucose prediction change: +0.0685\n",
      "Individual 126:\n",
      "  CI change: -0.02669587048957108\n",
      "  Steps change: 3.3 → 13.3 (+10.0)\n",
      "before pred: 0.6401883317845154\n",
      "after pred: -0.008448544089972754\n",
      "  Avg glucose prediction change: -0.2603\n",
      "Individual 217:\n",
      "  CI change: 5.1159281600438554e-05\n",
      "  Steps change: 1.9 → 7.5 (+5.6)\n",
      "before pred: 0.28877964772666276\n",
      "after pred: 0.11327814014364115\n",
      "  Avg glucose prediction change: +0.0623\n",
      "Individual 70:\n",
      "  CI change: 0.02923434838858167\n",
      "  Steps change: 0.7 → 2.8 (+2.1)\n",
      "before pred: 0.8425242224330602\n",
      "after pred: 1.3994016275680339\n",
      "  Avg glucose prediction change: +0.3679\n",
      "Individual 240:\n",
      "  CI change: 0.017355544827582333\n",
      "  Steps change: 1.2 → 4.9 (+3.7)\n",
      "before pred: -0.6518638283198198\n",
      "after pred: -0.5101946478504953\n",
      "  Avg glucose prediction change: +0.1196\n",
      "Individual 34:\n",
      "  CI change: -0.0060411587730450755\n",
      "  Steps change: 1.7 → 6.8 (+5.1)\n",
      "before pred: 0.6065479027870777\n",
      "after pred: 0.17722494166072428\n",
      "  Avg glucose prediction change: -0.4363\n",
      "Individual 185:\n",
      "  CI change: -0.01263741686291037\n",
      "  Steps change: 17.0 → 68.1 (+51.1)\n",
      "before pred: 0.49810165134958195\n",
      "after pred: -0.473725654515202\n",
      "  Avg glucose prediction change: -1.0708\n",
      "Individual 244:\n",
      "  CI change: -0.002553879760145708\n",
      "  Steps change: 5.7 → 22.9 (+17.1)\n",
      "before pred: 0.44094905244053006\n",
      "after pred: 0.2825515278493893\n",
      "  Avg glucose prediction change: -0.0993\n",
      "Individual 179:\n",
      "  CI change: 0.0007232173492987828\n",
      "  Steps change: 0.6 → 2.3 (+1.7)\n",
      "before pred: -0.09112242426882675\n",
      "after pred: -0.027018573400439023\n",
      "  Avg glucose prediction change: +0.0026\n",
      "Individual 144:\n",
      "  CI change: 0.021328446153480694\n",
      "  Steps change: 7.9 → 31.8 (+23.8)\n",
      "before pred: -0.03296477347323794\n",
      "after pred: -0.037304514986297874\n",
      "  Avg glucose prediction change: -0.1645\n",
      "Individual 110:\n",
      "  CI change: 0.018816332595506826\n",
      "  Steps change: 3.1 → 12.3 (+9.2)\n",
      "before pred: 0.161522927449867\n",
      "after pred: 0.33381514108631616\n",
      "  Avg glucose prediction change: +0.2561\n",
      "Individual 173:\n",
      "  CI change: 0.03806231613675171\n",
      "  Steps change: 8.5 → 33.9 (+25.4)\n",
      "before pred: 0.6004809571053611\n",
      "after pred: 0.8158858715916293\n",
      "  Avg glucose prediction change: +0.3458\n",
      "Individual 111:\n",
      "  CI change: 0.017390133287466355\n",
      "  Steps change: 2.9 → 11.5 (+8.6)\n",
      "before pred: -0.3810542931297552\n",
      "after pred: -0.2642514302922339\n",
      "  Avg glucose prediction change: +0.0526\n",
      "Individual 133:\n",
      "  CI change: 0.00822083543447465\n",
      "  Steps change: 4.2 → 16.8 (+12.6)\n",
      "before pred: -0.1779696921743415\n",
      "after pred: -0.0508872156187606\n",
      "  Avg glucose prediction change: +0.1189\n",
      "Individual 130:\n",
      "  CI change: 0.01381017700016392\n",
      "  Steps change: 0.8 → 3.3 (+2.5)\n",
      "before pred: -0.35077071738362986\n",
      "after pred: -0.3047987814772135\n",
      "  Avg glucose prediction change: +0.1334\n",
      "Individual 241:\n",
      "  CI change: 0.00559134639904052\n",
      "  Steps change: 1.7 → 6.7 (+5.0)\n",
      "before pred: -0.7815507980869125\n",
      "after pred: -0.7670209702111195\n",
      "  Avg glucose prediction change: -0.2431\n",
      "Individual 199:\n",
      "  CI change: 0.01599318048331521\n",
      "  Steps change: 5.9 → 23.6 (+17.7)\n",
      "before pred: 0.5532445548935482\n",
      "after pred: 1.338267122854234\n",
      "  Avg glucose prediction change: +0.8410\n",
      "Individual 0:\n",
      "  CI change: 0.004034037982233703\n",
      "  Steps change: 12.4 → 49.7 (+37.3)\n",
      "before pred: 0.5416422294648974\n",
      "after pred: 0.9293937541275408\n",
      "  Avg glucose prediction change: +0.2814\n",
      "Individual 11:\n",
      "  CI change: 0.007913036201334277\n",
      "  Steps change: 3.6 → 14.5 (+10.9)\n",
      "before pred: 0.924969515130508\n",
      "after pred: 0.1974180657820601\n",
      "  Avg glucose prediction change: -1.4015\n",
      "Individual 195:\n",
      "  CI change: 0.00809635475323265\n",
      "  Steps change: 4.7 → 19.0 (+14.2)\n",
      "before pred: -0.38885566681183004\n",
      "after pred: -0.32570260102325704\n",
      "  Avg glucose prediction change: +0.0617\n",
      "Individual 43:\n",
      "  CI change: 0.035323563733788726\n",
      "  Steps change: 17.3 → 69.0 (+51.8)\n",
      "before pred: 0.28972832027736906\n",
      "after pred: 0.4178601343320983\n",
      "  Avg glucose prediction change: +0.1441\n",
      "Individual 251:\n",
      "  CI change: -0.011803022387995032\n",
      "  Steps change: 6.2 → 25.0 (+18.7)\n",
      "before pred: 0.4846443760198965\n",
      "after pred: -0.3952953663352041\n",
      "  Avg glucose prediction change: -0.5653\n",
      "Individual 25:\n",
      "  CI change: -0.007192815643387158\n",
      "  Steps change: 3.1 → 12.4 (+9.3)\n",
      "before pred: 0.6017328189423417\n",
      "after pred: 0.286312889716557\n",
      "  Avg glucose prediction change: -0.5135\n",
      "Individual 80:\n",
      "  CI change: 0.0072048632490887745\n",
      "  Steps change: 0.3 → 1.4 (+1.0)\n",
      "before pred: -0.6885697283370911\n",
      "after pred: -0.6316443548561694\n",
      "  Avg glucose prediction change: +0.0002\n",
      "Individual 184:\n",
      "  CI change: 0.004515430654413678\n",
      "  Steps change: 3.1 → 12.4 (+9.3)\n",
      "before pred: -0.5536991759822465\n",
      "after pred: -0.5872786133163561\n",
      "  Avg glucose prediction change: -0.0726\n",
      "Individual 82:\n",
      "  CI change: -0.023864701066789756\n",
      "  Steps change: 2.7 → 11.0 (+8.2)\n",
      "before pred: 0.0989848200791087\n",
      "after pred: -0.38766175159204297\n",
      "  Avg glucose prediction change: -0.5446\n",
      "Individual 83:\n",
      "  CI change: 0.015606008495161184\n",
      "  Steps change: 4.6 → 18.5 (+13.9)\n",
      "before pred: -0.28214160053387455\n",
      "after pred: -0.02130820917427137\n",
      "  Avg glucose prediction change: +0.2093\n",
      "Individual 100:\n",
      "  CI change: 0.0002999322650789442\n",
      "  Steps change: 2.3 → 9.3 (+7.0)\n",
      "before pred: 0.15625684526714212\n",
      "after pred: -0.06017413033155797\n",
      "  Avg glucose prediction change: -0.1551\n",
      "Individual 87:\n",
      "  CI change: -0.0030823929406842117\n",
      "  Steps change: 0.4 → 1.7 (+1.3)\n",
      "before pred: -0.5748112056261923\n",
      "after pred: -0.643403983271363\n",
      "  Avg glucose prediction change: -0.2016\n",
      "Individual 166:\n",
      "  CI change: 0.031141792533170384\n",
      "  Steps change: 3.2 → 12.7 (+9.5)\n",
      "before pred: -0.42650612523849624\n",
      "after pred: 0.3760410441837647\n",
      "  Avg glucose prediction change: +0.9736\n",
      "Individual 156:\n",
      "  CI change: 0.012778692270023932\n",
      "  Steps change: 20.7 → 82.9 (+62.2)\n",
      "before pred: 0.3712277764078501\n",
      "after pred: 0.3484823830635876\n",
      "  Avg glucose prediction change: -0.0148\n",
      "Individual 51:\n",
      "  CI change: 0.013973402243894272\n",
      "  Steps change: 15.7 → 62.6 (+47.0)\n",
      "before pred: -0.049950476736923655\n",
      "after pred: -0.07736943623865913\n",
      "  Avg glucose prediction change: +0.0046\n",
      "Individual 221:\n",
      "  CI change: -0.01535497042961901\n",
      "  Steps change: 1.9 → 7.6 (+5.7)\n",
      "before pred: 0.005137988589971443\n",
      "after pred: -0.2974066093235823\n",
      "  Avg glucose prediction change: -0.6172\n",
      "Individual 149:\n",
      "  CI change: -0.0015716232318457482\n",
      "  Steps change: 2.2 → 8.9 (+6.6)\n",
      "before pred: -0.19912467178602433\n",
      "after pred: -0.36067329941228216\n",
      "  Avg glucose prediction change: -0.2595\n",
      "Individual 162:\n",
      "  CI change: 0.02512081260164277\n",
      "  Steps change: 6.8 → 27.3 (+20.5)\n",
      "before pred: 3.2414879870821602\n",
      "after pred: 3.7407683451548976\n",
      "  Avg glucose prediction change: +0.4968\n",
      "Individual 4:\n",
      "  CI change: 0.012607851538955554\n",
      "  Steps change: 67.1 → 268.3 (+201.2)\n",
      "before pred: -0.38016331081250077\n",
      "after pred: -0.32608085326842584\n",
      "  Avg glucose prediction change: -0.1240\n",
      "Individual 71:\n",
      "  CI change: 0.00747859388542982\n",
      "  Steps change: 0.6 → 2.5 (+1.8)\n",
      "before pred: -0.42801863931274853\n",
      "after pred: -0.33167660191355175\n",
      "  Avg glucose prediction change: +0.1119\n",
      "Individual 135:\n",
      "  CI change: 0.0076449732630843965\n",
      "  Steps change: 4.7 → 19.0 (+14.2)\n",
      "before pred: -0.38502533673022643\n",
      "after pred: -0.375624551925676\n",
      "  Avg glucose prediction change: -0.0533\n",
      "Individual 99:\n",
      "  CI change: 0.01246481970351385\n",
      "  Steps change: 0.7 → 2.8 (+2.1)\n",
      "before pred: 0.15728062068831727\n",
      "after pred: 0.3722909623522229\n",
      "  Avg glucose prediction change: +0.3269\n",
      "Individual 243:\n",
      "  CI change: -0.00015351779067199287\n",
      "  Steps change: 0.6 → 2.3 (+1.7)\n",
      "before pred: -0.03511315820310031\n",
      "after pred: -0.11691913488267303\n",
      "  Avg glucose prediction change: -0.0994\n",
      "Individual 196:\n",
      "  CI change: 0.030199633958856546\n",
      "  Steps change: 1.6 → 6.2 (+4.7)\n",
      "before pred: 0.7238808968204484\n",
      "after pred: 0.6148666721125323\n",
      "  Avg glucose prediction change: -0.1028\n",
      "Individual 124:\n",
      "  CI change: -0.03636844881934985\n",
      "  Steps change: 7.7 → 30.9 (+23.2)\n",
      "before pred: 1.751054916917645\n",
      "after pred: 0.19827070213473277\n",
      "  Avg glucose prediction change: -1.4192\n",
      "Individual 6:\n",
      "  CI change: 0.0008842502879041272\n",
      "  Steps change: 1.9 → 7.5 (+5.6)\n",
      "before pred: 0.16813374237875872\n",
      "after pred: 0.052552347587170284\n",
      "  Avg glucose prediction change: +0.0361\n",
      "Individual 72:\n",
      "  CI change: 0.013447032214459576\n",
      "  Steps change: 5.3 → 21.1 (+15.8)\n",
      "before pred: 0.4431796335305093\n",
      "after pred: 0.5431829946539692\n",
      "  Avg glucose prediction change: -0.2010\n",
      "Individual 98:\n",
      "  CI change: 0.0004584436573041911\n",
      "  Steps change: 6.1 → 24.4 (+18.3)\n",
      "before pred: 0.24319203378280252\n",
      "after pred: -0.12910847436054643\n",
      "  Avg glucose prediction change: -0.2685\n",
      "Individual 53:\n",
      "  CI change: 0.014236046855554265\n",
      "  Steps change: 3.8 → 15.2 (+11.4)\n",
      "before pred: -0.009938631765773564\n",
      "after pred: 0.08226185413745328\n",
      "  Avg glucose prediction change: +0.0281\n",
      "Individual 182:\n",
      "  CI change: 0.010230793097948523\n",
      "  Steps change: 8.7 → 34.9 (+26.2)\n",
      "before pred: -0.27233197726113967\n",
      "after pred: -0.3651930851918823\n",
      "  Avg glucose prediction change: -0.1572\n",
      "Individual 140:\n",
      "  CI change: 0.019656381644203653\n",
      "  Steps change: 3.3 → 13.0 (+9.8)\n",
      "before pred: 0.03845237744396623\n",
      "after pred: 0.20866307813469853\n",
      "  Avg glucose prediction change: +0.1525\n",
      "Individual 112:\n",
      "  CI change: 0.017284937958556505\n",
      "  Steps change: 3.8 → 15.2 (+11.4)\n",
      "before pred: 0.8573405740243282\n",
      "after pred: 1.1849869431236588\n",
      "  Avg glucose prediction change: +0.1374\n",
      "Individual 209:\n",
      "  CI change: 0.007341693788409425\n",
      "  Steps change: 0.7 → 2.9 (+2.1)\n",
      "before pred: -0.042728697494144485\n",
      "after pred: -0.0010066798319067738\n",
      "  Avg glucose prediction change: -0.0335\n",
      "Individual 114:\n",
      "  CI change: 0.012810170786072815\n",
      "  Steps change: 5.8 → 23.0 (+17.3)\n",
      "before pred: -0.3136273802391604\n",
      "after pred: -0.32658828248112215\n",
      "  Avg glucose prediction change: +0.0030\n",
      "Individual 84:\n",
      "  CI change: -0.007080015535910585\n",
      "  Steps change: 5.7 → 22.9 (+17.1)\n",
      "before pred: 0.535979960642134\n",
      "after pred: 0.3093018558891035\n",
      "  Avg glucose prediction change: -0.2325\n",
      "Individual 30:\n",
      "  CI change: 0.017487004322059796\n",
      "  Steps change: 7.2 → 28.8 (+21.6)\n",
      "before pred: 0.6015854864346766\n",
      "after pred: 0.09495944870530323\n",
      "  Avg glucose prediction change: -0.5671\n",
      "Individual 56:\n",
      "  CI change: -0.0022456355968542407\n",
      "  Steps change: 2.2 → 8.6 (+6.5)\n",
      "before pred: 0.6276824644142218\n",
      "after pred: 0.5707775444323524\n",
      "  Avg glucose prediction change: -0.0878\n",
      "Individual 171:\n",
      "  CI change: -0.006730163627422997\n",
      "  Steps change: 0.6 → 2.3 (+1.7)\n",
      "before pred: -0.4504941807536787\n",
      "after pred: -0.482147786843409\n",
      "  Avg glucose prediction change: -0.0035\n",
      "Individual 210:\n",
      "  CI change: 0.010140631497363118\n",
      "  Steps change: 8.7 → 34.6 (+26.0)\n",
      "before pred: 1.484923765467496\n",
      "after pred: 1.963094859386388\n",
      "  Avg glucose prediction change: +1.0785\n",
      "Individual 13:\n",
      "  CI change: 0.02909558241989486\n",
      "  Steps change: 23.5 → 93.9 (+70.4)\n",
      "before pred: -0.09813787819835487\n",
      "after pred: 0.6543713226119636\n",
      "  Avg glucose prediction change: +0.9047\n",
      "Individual 1:\n",
      "  CI change: 0.022341220546604833\n",
      "  Steps change: 16.5 → 65.8 (+49.4)\n",
      "before pred: -0.3325593248535115\n",
      "after pred: 0.10298334922040658\n",
      "  Avg glucose prediction change: +0.4769\n",
      "Individual 192:\n",
      "  CI change: 0.013654425650063865\n",
      "  Steps change: 5.0 → 19.8 (+14.9)\n",
      "before pred: -0.08965702853157688\n",
      "after pred: -0.02157367272897982\n",
      "  Avg glucose prediction change: -0.0885\n",
      "Individual 136:\n",
      "  CI change: 0.03541024307187499\n",
      "  Steps change: 7.2 → 28.6 (+21.5)\n",
      "before pred: -0.305353422267158\n",
      "after pred: 0.13859569928657217\n",
      "  Avg glucose prediction change: +0.4975\n",
      "Individual 24:\n",
      "  CI change: 0.0038802917376907337\n",
      "  Steps change: 3.4 → 13.5 (+10.1)\n",
      "before pred: 1.369811753791013\n",
      "after pred: 1.6644152517726958\n",
      "  Avg glucose prediction change: +0.4543\n",
      "Individual 249:\n",
      "  CI change: 0.006832882340414288\n",
      "  Steps change: 3.6 → 14.5 (+10.9)\n",
      "before pred: 0.7793260895373979\n",
      "after pred: 0.31165728225446604\n",
      "  Avg glucose prediction change: -1.1243\n",
      "Individual 27:\n",
      "  CI change: -0.009067852378736996\n",
      "  Steps change: 2.4 → 9.7 (+7.2)\n",
      "before pred: -0.0626720055149999\n",
      "after pred: -0.27678953910357185\n",
      "  Avg glucose prediction change: -0.3120\n",
      "Individual 95:\n",
      "  CI change: 0.022991229762485205\n",
      "  Steps change: 5.1 → 20.5 (+15.4)\n",
      "before pred: -0.774207505274839\n",
      "after pred: -0.20993805556147316\n",
      "  Avg glucose prediction change: +0.6220\n",
      "Individual 146:\n",
      "  CI change: 0.007804391946468998\n",
      "  Steps change: 1.1 → 4.5 (+3.4)\n",
      "before pred: 1.37760481106494\n",
      "after pred: 1.7853485390455717\n",
      "  Avg glucose prediction change: +0.4797\n",
      "Individual 239:\n",
      "  CI change: -0.013567353886784985\n",
      "  Steps change: 1.2 → 4.9 (+3.6)\n",
      "before pred: 0.38772188218820874\n",
      "after pred: -0.008271978432364206\n",
      "  Avg glucose prediction change: -0.5752\n",
      "Individual 165:\n",
      "  CI change: 0.011135706698878796\n",
      "  Steps change: 12.4 → 49.5 (+37.2)\n",
      "before pred: 0.013914807860199396\n",
      "after pred: -0.11493976046963628\n",
      "  Avg glucose prediction change: -0.1468\n",
      "Individual 64:\n",
      "  CI change: 0.018227844340588713\n",
      "  Steps change: 8.1 → 32.2 (+24.2)\n",
      "before pred: 1.0833785826370854\n",
      "after pred: 0.2622598318219866\n",
      "  Avg glucose prediction change: -0.3514\n",
      "Individual 49:\n",
      "  CI change: -0.0015349158040895618\n",
      "  Steps change: 0.5 → 1.8 (+1.4)\n",
      "before pred: -0.7565162256355762\n",
      "after pred: -0.8177752008390078\n",
      "  Avg glucose prediction change: -0.1938\n",
      "Individual 142:\n",
      "  CI change: -0.005626351112739196\n",
      "  Steps change: 5.7 → 22.9 (+17.1)\n",
      "before pred: 0.5471581544499426\n",
      "after pred: 0.2765068467375928\n",
      "  Avg glucose prediction change: -0.2556\n",
      "Individual 141:\n",
      "  CI change: -0.0041389212207344275\n",
      "  Steps change: 0.8 → 3.4 (+2.5)\n",
      "before pred: 1.214486129989019\n",
      "after pred: 1.0257628587468204\n",
      "  Avg glucose prediction change: -0.4510\n",
      "Individual 230:\n",
      "  CI change: 0.007055766463100471\n",
      "  Steps change: 0.6 → 2.5 (+1.8)\n",
      "before pred: -0.3182689167006877\n",
      "after pred: -0.23041896086752386\n",
      "  Avg glucose prediction change: +0.1068\n",
      "Individual 44:\n",
      "  CI change: 0.0027371433012599207\n",
      "  Steps change: 34.9 → 139.5 (+104.7)\n",
      "before pred: 1.5331969596490616\n",
      "after pred: 2.0513146908849844\n",
      "  Avg glucose prediction change: +0.5680\n",
      "Individual 32:\n",
      "  CI change: 0.006475033784443628\n",
      "  Steps change: 2.1 → 8.4 (+6.3)\n",
      "before pred: -0.25249761603163345\n",
      "after pred: -0.18998844625975653\n",
      "  Avg glucose prediction change: -0.0480\n",
      "Individual 207:\n",
      "  CI change: 0.015620713529532353\n",
      "  Steps change: 5.4 → 21.5 (+16.1)\n",
      "before pred: -0.32762636235101333\n",
      "after pred: -0.35979950055231075\n",
      "  Avg glucose prediction change: -0.0894\n",
      "Individual 153:\n",
      "  CI change: -0.03687977558576812\n",
      "  Steps change: 3.5 → 13.9 (+10.4)\n",
      "before pred: 0.6650573765678859\n",
      "after pred: -0.3277973685675472\n",
      "  Avg glucose prediction change: -1.4139\n",
      "Individual 224:\n",
      "  CI change: 0.014914379773211302\n",
      "  Steps change: 8.5 → 34.0 (+25.5)\n",
      "before pred: -0.2574117279095285\n",
      "after pred: -0.29956929209276384\n",
      "  Avg glucose prediction change: -0.2208\n",
      "Individual 234:\n",
      "  CI change: -0.005113171491543222\n",
      "  Steps change: 1.0 → 4.0 (+3.0)\n",
      "before pred: -0.6697313199673804\n",
      "after pred: -0.6293557604450488\n",
      "  Avg glucose prediction change: -0.1503\n",
      "Individual 109:\n",
      "  CI change: 0.010373539956584608\n",
      "  Steps change: 0.6 → 2.5 (+1.8)\n",
      "before pred: -0.2660227103134961\n",
      "after pred: -0.1528730448606939\n",
      "  Avg glucose prediction change: +0.0987\n",
      "Individual 54:\n",
      "  CI change: 0.022556396876335337\n",
      "  Steps change: 8.4 → 33.8 (+25.3)\n",
      "before pred: -0.03416810130031218\n",
      "after pred: -0.029553423739435997\n",
      "  Avg glucose prediction change: +0.0981\n",
      "Individual 78:\n",
      "  CI change: 0.013551955799272587\n",
      "  Steps change: 4.0 → 15.8 (+11.9)\n",
      "before pred: -0.5911277261927275\n",
      "after pred: -0.5630765228540802\n",
      "  Avg glucose prediction change: -0.0680\n",
      "Individual 168:\n",
      "  CI change: 0.02852595777641179\n",
      "  Steps change: 7.2 → 28.6 (+21.5)\n",
      "before pred: 0.23439073042602226\n",
      "after pred: 0.5513060089757987\n",
      "  Avg glucose prediction change: +0.3978\n",
      "Individual 101:\n",
      "  CI change: 0.013777663647910415\n",
      "  Steps change: 7.2 → 29.0 (+21.7)\n",
      "before pred: 0.5773512241733635\n",
      "after pred: 1.2088420212841293\n",
      "  Avg glucose prediction change: +0.5057\n",
      "Individual 189:\n",
      "  CI change: 0.01748210263591019\n",
      "  Steps change: 1.1 → 4.4 (+3.3)\n",
      "before pred: 1.9289941778275592\n",
      "after pred: 2.300819521850489\n",
      "  Avg glucose prediction change: +0.4808\n",
      "Individual 76:\n",
      "  CI change: 0.012757153823086105\n",
      "  Steps change: 7.5 → 30.1 (+22.6)\n",
      "before pred: 0.6324090355984958\n",
      "after pred: 1.1981619586967833\n",
      "  Avg glucose prediction change: +0.0485\n",
      "Individual 128:\n",
      "  CI change: -0.005835597649366759\n",
      "  Steps change: 1.0 → 4.1 (+3.0)\n",
      "before pred: 0.6124752350691182\n",
      "after pred: -0.04456717627198859\n",
      "  Avg glucose prediction change: -0.6365\n",
      "Individual 204:\n",
      "  CI change: 0.03869310372843253\n",
      "  Steps change: 17.0 → 68.1 (+51.1)\n",
      "before pred: 0.3512597826601811\n",
      "after pred: 0.4626667237402501\n",
      "  Avg glucose prediction change: -0.0181\n",
      "Individual 68:\n",
      "  CI change: 0.029341541696887026\n",
      "  Steps change: 33.8 → 135.2 (+101.4)\n",
      "before pred: -0.2591585921567824\n",
      "after pred: -0.23756690339914138\n",
      "  Avg glucose prediction change: +0.0653\n",
      "Individual 254:\n",
      "  CI change: 0.009842209329451537\n",
      "  Steps change: 8.0 → 32.1 (+24.1)\n",
      "before pred: 0.19939739830887632\n",
      "after pred: -0.11045673971956456\n",
      "  Avg glucose prediction change: -0.4460\n",
      "Individual 117:\n",
      "  CI change: 0.02067988596079208\n",
      "  Steps change: 1.0 → 4.1 (+3.1)\n",
      "before pred: 0.27481536183448224\n",
      "after pred: 0.14167524957779826\n",
      "  Avg glucose prediction change: -0.1023\n",
      "Individual 85:\n",
      "  CI change: 0.003375452768049563\n",
      "  Steps change: 3.4 → 13.5 (+10.1)\n",
      "before pred: 1.309173062922794\n",
      "after pred: 1.6622984036020285\n",
      "  Avg glucose prediction change: +0.4723\n",
      "Individual 197:\n",
      "  CI change: 0.021299796873430414\n",
      "  Steps change: 11.5 → 45.8 (+34.4)\n",
      "before pred: 2.7595112403699638\n",
      "after pred: 2.735786934114592\n",
      "  Avg glucose prediction change: -0.1405\n",
      "Individual 103:\n",
      "  CI change: 0.01587826658114428\n",
      "  Steps change: 5.0 → 19.9 (+14.9)\n",
      "before pred: 1.654491984133874\n",
      "after pred: 1.613871005399151\n",
      "  Avg glucose prediction change: +0.0884\n",
      "Individual 186:\n",
      "  CI change: 0.04105192762243452\n",
      "  Steps change: 5.8 → 23.4 (+17.5)\n",
      "before pred: 0.3366763553746517\n",
      "after pred: 0.504093427638892\n",
      "  Avg glucose prediction change: +0.2149\n",
      "Individual 139:\n",
      "  CI change: 0.017547740336205937\n",
      "  Steps change: 3.9 → 15.7 (+11.7)\n",
      "before pred: -0.09017955370638475\n",
      "after pred: 0.029981000642661466\n",
      "  Avg glucose prediction change: +0.1080\n",
      "Individual 163:\n",
      "  CI change: 0.006935405051607141\n",
      "  Steps change: 7.4 → 29.5 (+22.1)\n",
      "before pred: -0.2796548613926537\n",
      "after pred: -0.352086448300567\n",
      "  Avg glucose prediction change: -0.1602\n",
      "Individual 208:\n",
      "  CI change: 0.015255239595035372\n",
      "  Steps change: 4.6 → 18.5 (+13.9)\n",
      "before pred: -0.05407497038796627\n",
      "after pred: 0.5465120614754113\n",
      "  Avg glucose prediction change: +0.7691\n",
      "Individual 121:\n",
      "  CI change: 0.010076606022032225\n",
      "  Steps change: 1.2 → 4.7 (+3.5)\n",
      "before pred: 2.3872704998347323\n",
      "after pred: 1.442590316429082\n",
      "  Avg glucose prediction change: -1.3735\n",
      "Individual 10:\n",
      "  CI change: 0.01769409281801541\n",
      "  Steps change: 1.1 → 4.5 (+3.4)\n",
      "before pred: 0.28257286462567266\n",
      "after pred: 0.7144073033614677\n",
      "  Avg glucose prediction change: +0.3496\n",
      "Individual 66:\n",
      "  CI change: 0.01498831463925892\n",
      "  Steps change: 4.8 → 19.0 (+14.3)\n",
      "before pred: -0.039379546568540716\n",
      "after pred: 0.12239801448311448\n",
      "  Avg glucose prediction change: +0.2656\n",
      "Individual 236:\n",
      "  CI change: 0.013516995514978506\n",
      "  Steps change: 1.0 → 4.2 (+3.1)\n",
      "before pred: 0.35231298464019345\n",
      "after pred: 0.5238252482729268\n",
      "  Avg glucose prediction change: +0.1885\n",
      "Individual 2:\n",
      "  CI change: 0.011606640366851164\n",
      "  Steps change: 1.4 → 5.5 (+4.1)\n",
      "before pred: -0.7603576666024427\n",
      "after pred: -0.5940880424729286\n",
      "  Avg glucose prediction change: +0.2265\n",
      "Individual 203:\n",
      "  CI change: 0.0009205077584597273\n",
      "  Steps change: 3.6 → 14.2 (+10.7)\n",
      "before pred: 0.18054537425935732\n",
      "after pred: -0.08943981961751529\n",
      "  Avg glucose prediction change: -0.0648\n",
      "Individual 255:\n",
      "  CI change: 0.0033759552813469895\n",
      "  Steps change: 0.9 → 3.4 (+2.6)\n",
      "before pred: -0.5632305436161669\n",
      "after pred: -0.5396201395288811\n",
      "  Avg glucose prediction change: +0.0419\n",
      "Individual 206:\n",
      "  CI change: 0.017874215539352648\n",
      "  Steps change: 7.9 → 31.8 (+23.8)\n",
      "before pred: -0.2056371169802777\n",
      "after pred: -0.06161164993108526\n",
      "  Avg glucose prediction change: +0.0137\n",
      "Individual 14:\n",
      "  CI change: 0.004528414082510915\n",
      "  Steps change: 2.9 → 11.4 (+8.6)\n",
      "before pred: -0.10507531840642949\n",
      "after pred: -0.23737872478950534\n",
      "  Avg glucose prediction change: -0.2170\n",
      "Individual 36:\n",
      "  CI change: 0.017154144977963526\n",
      "  Steps change: 1.0 → 4.1 (+3.1)\n",
      "before pred: 0.45994664552040315\n",
      "after pred: 0.43960146070090256\n",
      "  Avg glucose prediction change: -0.1747\n",
      "Individual 74:\n",
      "  CI change: -0.013930016010509107\n",
      "  Steps change: 4.4 → 17.6 (+13.2)\n",
      "before pred: 2.140131648558942\n",
      "after pred: 0.7648438420767469\n",
      "  Avg glucose prediction change: -1.4654\n",
      "Individual 193:\n",
      "  CI change: 0.019025646933349794\n",
      "  Steps change: 3.3 → 13.2 (+9.9)\n",
      "before pred: -0.6667022794353799\n",
      "after pred: -0.5679946265014297\n",
      "  Avg glucose prediction change: +0.1131\n",
      "Individual 9:\n",
      "  CI change: 0.02923598314960803\n",
      "  Steps change: 19.7 → 78.8 (+59.1)\n",
      "before pred: -0.11518849352238819\n",
      "after pred: -0.09133893268104853\n",
      "  Avg glucose prediction change: +0.1450\n",
      "Individual 22:\n",
      "  CI change: 0.0026909698169037674\n",
      "  Steps change: 1.6 → 6.4 (+4.8)\n",
      "before pred: -0.3578264474375834\n",
      "after pred: -0.4113252658695623\n",
      "  Avg glucose prediction change: +0.0428\n",
      "Individual 201:\n",
      "  CI change: 0.05835673747207061\n",
      "  Steps change: 5.9 → 23.7 (+17.8)\n",
      "before pred: 1.467730081833405\n",
      "after pred: 2.2953413762486887\n",
      "  Avg glucose prediction change: +1.2080\n",
      "Individual 181:\n",
      "  CI change: -0.004886229221597288\n",
      "  Steps change: 5.7 → 22.9 (+17.1)\n",
      "before pred: 0.5955772412868785\n",
      "after pred: 0.3881199685914993\n",
      "  Avg glucose prediction change: +0.0022\n",
      "Individual 123:\n",
      "  CI change: 0.015539691685748896\n",
      "  Steps change: 13.8 → 55.3 (+41.5)\n",
      "before pred: -0.3102221906264121\n",
      "after pred: -0.2591415389097493\n",
      "  Avg glucose prediction change: +0.1507\n",
      "Individual 40:\n",
      "  CI change: 0.025518472054394746\n",
      "  Steps change: 31.2 → 124.9 (+93.7)\n",
      "before pred: -0.20583884879639597\n",
      "after pred: -0.1391769665583052\n",
      "  Avg glucose prediction change: +0.0849\n",
      "Individual 226:\n",
      "  CI change: 0.008872319370170752\n",
      "  Steps change: 5.4 → 21.5 (+16.1)\n",
      "before pred: -0.24677130435580452\n",
      "after pred: -0.3074978291231837\n",
      "  Avg glucose prediction change: -0.0385\n",
      "Individual 46:\n",
      "  CI change: 0.033228065258533016\n",
      "  Steps change: 1.0 → 4.1 (+3.1)\n",
      "before pred: 1.2241322349691628\n",
      "after pred: 0.6908256629137934\n",
      "  Avg glucose prediction change: -0.3551\n",
      "Individual 172:\n",
      "  CI change: -0.002651794747528768\n",
      "  Steps change: 9.9 → 39.6 (+29.7)\n",
      "before pred: 1.7717895857689496\n",
      "after pred: 0.7488594706189003\n",
      "  Avg glucose prediction change: -0.5858\n",
      "Individual 246:\n",
      "  CI change: 0.01316843519820075\n",
      "  Steps change: 1.1 → 4.4 (+3.3)\n",
      "before pred: 1.935921136212682\n",
      "after pred: 2.2823008204067214\n",
      "  Avg glucose prediction change: +0.2813\n",
      "Individual 147:\n",
      "  CI change: 0.0008109062910513765\n",
      "  Steps change: 12.7 → 50.9 (+38.1)\n",
      "before pred: -0.6457880632766637\n",
      "after pred: -0.8557390218444842\n",
      "  Avg glucose prediction change: -0.3630\n",
      "Individual 213:\n",
      "  CI change: 0.02269345963580142\n",
      "  Steps change: 4.9 → 19.5 (+14.6)\n",
      "before pred: 0.8744256576648988\n",
      "after pred: 1.3339351006724915\n",
      "  Avg glucose prediction change: +0.5961\n",
      "Individual 191:\n",
      "  CI change: -0.00010765409891077735\n",
      "  Steps change: 0.5 → 1.9 (+1.4)\n",
      "before pred: -0.5858230016595353\n",
      "after pred: -0.6119649122496129\n",
      "  Avg glucose prediction change: +0.0444\n",
      "Individual 91:\n",
      "  CI change: 0.010556763347708295\n",
      "  Steps change: 10.4 → 41.5 (+31.2)\n",
      "before pred: -0.37096041484672637\n",
      "after pred: -0.39939401474953196\n",
      "  Avg glucose prediction change: +0.0319\n",
      "Individual 89:\n",
      "  CI change: -0.005392325573990917\n",
      "  Steps change: 8.6 → 34.5 (+25.8)\n",
      "before pred: 0.3601662120538628\n",
      "after pred: -0.262204621756268\n",
      "  Avg glucose prediction change: -0.4362\n",
      "Individual 200:\n",
      "  CI change: 0.01060171473391847\n",
      "  Steps change: 2.9 → 11.7 (+8.7)\n",
      "before pred: 1.4239421730555324\n",
      "after pred: 0.766472573201984\n",
      "  Avg glucose prediction change: -0.8217\n",
      "Individual 129:\n",
      "  CI change: -0.002877567128418728\n",
      "  Steps change: 1.6 → 6.6 (+4.9)\n",
      "before pred: -0.2983280130943521\n",
      "after pred: -0.5250256163637927\n",
      "  Avg glucose prediction change: -0.4531\n",
      "Individual 211:\n",
      "  CI change: -0.0003072273221407392\n",
      "  Steps change: 1.0 → 4.0 (+3.0)\n",
      "before pred: -0.6861110812907016\n",
      "after pred: -0.617406293263856\n",
      "  Avg glucose prediction change: +0.0201\n",
      "Individual 45:\n",
      "  CI change: 0.02869841102364845\n",
      "  Steps change: 7.4 → 29.6 (+22.2)\n",
      "before pred: 0.8808714423117334\n",
      "after pred: 1.0722315943501042\n",
      "  Avg glucose prediction change: +0.4362\n",
      "Individual 180:\n",
      "  CI change: 0.039796045275997734\n",
      "  Steps change: 34.4 → 137.4 (+103.1)\n",
      "before pred: 0.07085215202864982\n",
      "after pred: 0.23901268194207795\n",
      "  Avg glucose prediction change: +0.4183\n",
      "Individual 202:\n",
      "  CI change: 0.03272522602638925\n",
      "  Steps change: 7.2 → 28.6 (+21.5)\n",
      "before pred: -0.249389035827573\n",
      "after pred: 0.07148205629280563\n",
      "  Avg glucose prediction change: +0.0941\n",
      "Individual 38:\n",
      "  CI change: 0.027156310332872944\n",
      "  Steps change: 6.2 → 24.6 (+18.5)\n",
      "before pred: 0.7847347968371392\n",
      "after pred: 0.27979861636846515\n",
      "  Avg glucose prediction change: -0.3888\n",
      "Individual 158:\n",
      "  CI change: 0.0006445354833510954\n",
      "  Steps change: 3.0 → 11.9 (+9.0)\n",
      "before pred: 0.38845021418098347\n",
      "after pred: -0.006093682601290075\n",
      "  Avg glucose prediction change: -0.5067\n",
      "Individual 131:\n",
      "  CI change: 0.005174436255491303\n",
      "  Steps change: 2.7 → 10.6 (+8.0)\n",
      "before pred: -0.2649315230407643\n",
      "after pred: -0.2530533781784306\n",
      "  Avg glucose prediction change: +0.0831\n",
      "Individual 134:\n",
      "  CI change: 0.008570419552801965\n",
      "  Steps change: 13.0 → 52.0 (+39.0)\n",
      "before pred: -0.055097120789533466\n",
      "after pred: -0.14069916427409598\n",
      "  Avg glucose prediction change: +0.0679\n",
      "Individual 223:\n",
      "  CI change: 0.0032531533998538123\n",
      "  Steps change: 0.7 → 2.9 (+2.2)\n",
      "before pred: -0.6247364495010366\n",
      "after pred: -0.6552641236424965\n",
      "  Avg glucose prediction change: +0.0165\n",
      "Individual 247:\n",
      "  CI change: -0.01496848942973732\n",
      "  Steps change: 2.4 → 9.7 (+7.2)\n",
      "before pred: -0.04398597923708512\n",
      "after pred: -0.30852591539159147\n",
      "  Avg glucose prediction change: -0.4000\n",
      "Individual 242:\n",
      "  CI change: 0.007226469104208935\n",
      "  Steps change: 3.1 → 12.4 (+9.3)\n",
      "before pred: -0.5570115420687312\n",
      "after pred: -0.5793850131778302\n",
      "  Avg glucose prediction change: -0.0137\n",
      "Individual 41:\n",
      "  CI change: 0.018705779677800394\n",
      "  Steps change: 2.3 → 9.3 (+7.0)\n",
      "before pred: 0.7125283487021168\n",
      "after pred: 0.7622837730286905\n",
      "  Avg glucose prediction change: -0.0292\n",
      "Individual 15:\n",
      "  CI change: 0.0019106877524745717\n",
      "  Steps change: 4.0 → 15.9 (+11.9)\n",
      "before pred: -0.3184926800364001\n",
      "after pred: -0.37103262757469724\n",
      "  Avg glucose prediction change: -0.0045\n",
      "Individual 167:\n",
      "  CI change: -0.024601452579810675\n",
      "  Steps change: 2.4 → 9.7 (+7.2)\n",
      "before pred: 0.2070188142990233\n",
      "after pred: -0.4118020680220646\n",
      "  Avg glucose prediction change: -0.8950\n",
      "Individual 23:\n",
      "  CI change: 0.01542130948801321\n",
      "  Steps change: 7.5 → 30.0 (+22.5)\n",
      "before pred: -0.0027134390843210274\n",
      "after pred: 0.2282962261342258\n",
      "  Avg glucose prediction change: +0.3334\n",
      "Individual 252:\n",
      "  CI change: -0.004881252441795753\n",
      "  Steps change: 8.1 → 32.5 (+24.4)\n",
      "before pred: -0.2145303418557496\n",
      "after pred: -0.5048201423667074\n",
      "  Avg glucose prediction change: -0.3126\n",
      "Individual 57:\n",
      "  CI change: 0.006147218227066046\n",
      "  Steps change: 1.2 → 4.6 (+3.5)\n",
      "before pred: -0.36104480397254546\n",
      "after pred: -0.412098341995214\n",
      "  Avg glucose prediction change: -0.0420\n",
      "Individual 102:\n",
      "  CI change: 0.01796964948434121\n",
      "  Steps change: 0.7 → 2.8 (+2.1)\n",
      "before pred: -0.3874076682204647\n",
      "after pred: -0.24145243518897452\n",
      "  Avg glucose prediction change: +0.1039\n",
      "Individual 198:\n",
      "  CI change: 0.02162346541020349\n",
      "  Steps change: 5.3 → 21.2 (+15.9)\n",
      "before pred: 0.023099351481189835\n",
      "after pred: 0.0999567682168743\n",
      "  Avg glucose prediction change: +0.1035\n",
      "Individual 188:\n",
      "  CI change: 0.0021716948503263853\n",
      "  Steps change: 6.0 → 24.0 (+18.0)\n",
      "before pred: 0.921402962900437\n",
      "after pred: 0.07241486125906725\n",
      "  Avg glucose prediction change: -0.6625\n",
      "Individual 237:\n",
      "  CI change: 0.003175271675663674\n",
      "  Steps change: 1.0 → 4.0 (+3.0)\n",
      "before pred: 0.6418588151658673\n",
      "after pred: 0.02463679247285159\n",
      "  Avg glucose prediction change: -0.8755\n",
      "Individual 235:\n",
      "  CI change: 0.004903697927891861\n",
      "  Steps change: 4.8 → 19.1 (+14.3)\n",
      "before pred: 0.8961967318138878\n",
      "after pred: 0.17133628749206406\n",
      "  Avg glucose prediction change: -0.2630\n",
      "Individual 39:\n",
      "  CI change: 0.013777740117047148\n",
      "  Steps change: 4.1 → 16.2 (+12.2)\n",
      "before pred: 0.5814846567324481\n",
      "after pred: -0.08084936998795744\n",
      "  Avg glucose prediction change: -0.8876\n",
      "Individual 61:\n",
      "  CI change: 0.009293190274357498\n",
      "  Steps change: 5.4 → 21.5 (+16.1)\n",
      "before pred: -0.3346726527387228\n",
      "after pred: -0.3751283950647962\n",
      "  Avg glucose prediction change: -0.1308\n",
      "Individual 5:\n",
      "  CI change: 0.007468149569977793\n",
      "  Steps change: 1.2 → 4.9 (+3.7)\n",
      "before pred: -0.26364738637173674\n",
      "after pred: -0.27965326246267036\n",
      "  Avg glucose prediction change: -0.0288\n",
      "Individual 93:\n",
      "  CI change: 0.014579987250581107\n",
      "  Steps change: 1.1 → 4.5 (+3.4)\n",
      "before pred: 0.3936119595055814\n",
      "after pred: 0.8120169816865286\n",
      "  Avg glucose prediction change: +0.4510\n",
      "Individual 65:\n",
      "  CI change: 0.013785762611095684\n",
      "  Steps change: 3.1 → 12.4 (+9.3)\n",
      "before pred: -0.02959503551234558\n",
      "after pred: 0.09215107119099233\n",
      "  Avg glucose prediction change: +0.0372\n",
      "Individual 33:\n",
      "  CI change: 0.017382588283616683\n",
      "  Steps change: 2.8 → 11.3 (+8.5)\n",
      "before pred: -0.6847457666751833\n",
      "after pred: -0.6082537240446448\n",
      "  Avg glucose prediction change: +0.0394\n",
      "Individual 88:\n",
      "  CI change: 0.01234438861842401\n",
      "  Steps change: 4.8 → 19.1 (+14.3)\n",
      "before pred: 1.2205927611554435\n",
      "after pred: 0.544410576500477\n",
      "  Avg glucose prediction change: -0.3207\n",
      "Individual 28:\n",
      "  CI change: 0.006989126138315275\n",
      "  Steps change: 15.3 → 61.3 (+46.0)\n",
      "before pred: -0.3213006112721718\n",
      "after pred: -0.38435074198688396\n",
      "  Avg glucose prediction change: -0.0806\n",
      "Individual 12:\n",
      "  CI change: -0.015974515533645692\n",
      "  Steps change: 2.4 → 9.7 (+7.2)\n",
      "before pred: 0.39311001675807256\n",
      "after pred: -0.2956909568589472\n",
      "  Avg glucose prediction change: -1.0590\n",
      "Individual 219:\n",
      "  CI change: 0.008758850027076142\n",
      "  Steps change: 2.4 → 9.5 (+7.1)\n",
      "before pred: -0.19065807907938176\n",
      "after pred: -0.07978295172359197\n",
      "  Avg glucose prediction change: +0.0142\n",
      "Individual 132:\n",
      "  CI change: 0.0038913058635265626\n",
      "  Steps change: 0.3 → 1.4 (+1.0)\n",
      "before pred: -0.07312895619630125\n",
      "after pred: -0.014557716156830346\n",
      "  Avg glucose prediction change: +0.0443\n",
      "Individual 205:\n",
      "  CI change: -0.002848137005165911\n",
      "  Steps change: 0.4 → 1.8 (+1.3)\n",
      "before pred: -0.3706953591422114\n",
      "after pred: -0.41116748689499727\n",
      "  Avg glucose prediction change: -0.0295\n",
      "Individual 37:\n",
      "  CI change: -0.00037235857039892833\n",
      "  Steps change: 0.4 → 1.8 (+1.3)\n",
      "before pred: -0.2961896264276967\n",
      "after pred: -0.3613998233041661\n",
      "  Avg glucose prediction change: +0.0085\n",
      "Individual 97:\n",
      "  CI change: 0.0015293090979925687\n",
      "  Steps change: 13.0 → 51.9 (+39.0)\n",
      "before pred: -0.42392580016726533\n",
      "after pred: -0.5514631279962228\n",
      "  Avg glucose prediction change: +0.2270\n",
      "Individual 63:\n",
      "  CI change: 0.025239236117330394\n",
      "  Steps change: 4.3 → 17.3 (+12.9)\n",
      "before pred: -0.36334223437264723\n",
      "after pred: -0.03900956861553516\n",
      "  Avg glucose prediction change: +0.2076\n",
      "Individual 104:\n",
      "  CI change: 0.026177399137540625\n",
      "  Steps change: 23.2 → 92.8 (+69.6)\n",
      "before pred: 0.05515894611337406\n",
      "after pred: 0.3360476431830997\n",
      "  Avg glucose prediction change: +0.1421\n",
      "Individual 52:\n",
      "  CI change: 0.016327322166673743\n",
      "  Steps change: 2.9 → 11.6 (+8.7)\n",
      "before pred: -0.40815630599549446\n",
      "after pred: -0.4924731958300673\n",
      "  Avg glucose prediction change: -0.0001\n",
      "Individual 16:\n",
      "  CI change: 0.009846530754722587\n",
      "  Steps change: 6.9 → 27.6 (+20.7)\n",
      "before pred: -0.38216753147296584\n",
      "after pred: -0.30490567802770807\n",
      "  Avg glucose prediction change: +0.0494\n",
      "Individual 116:\n",
      "  CI change: 0.019880200716183183\n",
      "  Steps change: 2.7 → 10.9 (+8.2)\n",
      "before pred: -0.6728368197492327\n",
      "after pred: -0.5291823470349575\n",
      "  Avg glucose prediction change: +0.0065\n",
      "Individual 113:\n",
      "  CI change: 0.008133340795185948\n",
      "  Steps change: 11.8 → 47.0 (+35.3)\n",
      "before pred: 1.7861277748153184\n",
      "after pred: 1.7591047964998745\n",
      "  Avg glucose prediction change: -0.3951\n",
      "Individual 212:\n",
      "  CI change: 0.017877218195259184\n",
      "  Steps change: 13.9 → 55.6 (+41.7)\n",
      "before pred: 0.1996034662426045\n",
      "after pred: 0.6159857243186411\n",
      "  Avg glucose prediction change: +0.1746\n",
      "Individual 248:\n",
      "  CI change: 0.009633128864143513\n",
      "  Steps change: 1.4 → 5.5 (+4.1)\n",
      "before pred: -0.8194520882651515\n",
      "after pred: -0.635678194541249\n",
      "  Avg glucose prediction change: +0.1571\n",
      "Individual 161:\n",
      "  CI change: -0.004723851961321944\n",
      "  Steps change: 8.1 → 32.5 (+24.4)\n",
      "before pred: -0.1461961002776432\n",
      "after pred: -0.46587243457424\n",
      "  Avg glucose prediction change: -0.4184\n",
      "Individual 127:\n",
      "  CI change: 0.0014180440980088363\n",
      "  Steps change: 1.0 → 3.9 (+2.9)\n",
      "before pred: 2.477950756045434\n",
      "after pred: 1.8675409772686986\n",
      "  Avg glucose prediction change: -0.8009\n",
      "Individual 90:\n",
      "  CI change: 0.023471358011553898\n",
      "  Steps change: 16.5 → 65.8 (+49.4)\n",
      "before pred: -0.33150292297752126\n",
      "after pred: 0.13786304432379137\n",
      "  Avg glucose prediction change: +0.4895\n",
      "Individual 151:\n",
      "  CI change: 0.02448114427135078\n",
      "  Steps change: 6.3 → 25.3 (+19.0)\n",
      "before pred: -0.23127322650781262\n",
      "after pred: -0.13605163787183233\n",
      "  Avg glucose prediction change: -0.1806\n",
      "Individual 218:\n",
      "  CI change: -0.032084350480571476\n",
      "  Steps change: 10.5 → 42.0 (+31.5)\n",
      "before pred: 0.7550039748558532\n",
      "after pred: -0.1021485191927699\n",
      "  Avg glucose prediction change: -1.0075\n",
      "Individual 77:\n",
      "  CI change: 0.023225317306725377\n",
      "  Steps change: 33.8 → 135.2 (+101.4)\n",
      "before pred: -0.27338360648632226\n",
      "after pred: -0.27999734235530815\n",
      "  Avg glucose prediction change: +0.0652\n",
      "Individual 115:\n",
      "  CI change: 0.00667516613740829\n",
      "  Steps change: 0.7 → 2.9 (+2.1)\n",
      "before pred: -0.04286491485603844\n",
      "after pred: -0.006152752310192201\n",
      "  Avg glucose prediction change: +0.0877\n",
      "Individual 138:\n",
      "  CI change: 0.004947476335911537\n",
      "  Steps change: 4.8 → 19.1 (+14.3)\n",
      "before pred: 0.7559124315188563\n",
      "after pred: 0.5364725655103261\n",
      "  Avg glucose prediction change: -0.1255\n",
      "Individual 79:\n",
      "  CI change: 0.007850124574208021\n",
      "  Steps change: 0.7 → 2.9 (+2.2)\n",
      "before pred: -0.24897666302720983\n",
      "after pred: -0.09936656996441844\n",
      "  Avg glucose prediction change: +0.0540\n",
      "Individual 170:\n",
      "  CI change: 0.028493958425884005\n",
      "  Steps change: 0.7 → 2.8 (+2.1)\n",
      "before pred: 0.35724176788853973\n",
      "after pred: 1.2409269389866802\n",
      "  Avg glucose prediction change: +1.0130\n",
      "Individual 190:\n",
      "  CI change: 0.008618120471472805\n",
      "  Steps change: 1.0 → 3.9 (+2.9)\n",
      "before pred: -0.07069899896534136\n",
      "after pred: -0.022444462027701884\n",
      "  Avg glucose prediction change: +0.0334\n",
      "Individual 214:\n",
      "  CI change: -0.017720984714678437\n",
      "  Steps change: 2.3 → 9.4 (+7.0)\n",
      "before pred: 0.7080538163365773\n",
      "after pred: 0.1280982607234324\n",
      "  Avg glucose prediction change: -0.7736\n",
      "Individual 216:\n",
      "  CI change: 0.004601548226647219\n",
      "  Steps change: 1.4 → 5.8 (+4.3)\n",
      "before pred: -0.3982678899628912\n",
      "after pred: -0.4303641687472805\n",
      "  Avg glucose prediction change: -0.2557\n",
      "Individual 62:\n",
      "  CI change: 0.0040778587911498515\n",
      "  Steps change: 0.9 → 3.5 (+2.6)\n",
      "before pred: 0.7539461667252869\n",
      "after pred: 0.8142718151517598\n",
      "  Avg glucose prediction change: +0.0819\n",
      "Individual 106:\n",
      "  CI change: 0.03379654580875635\n",
      "  Steps change: 8.2 → 33.0 (+24.7)\n",
      "before pred: 0.35224161554981664\n",
      "after pred: 0.5129010687948532\n",
      "  Avg glucose prediction change: +0.3750\n",
      "Individual 154:\n",
      "  CI change: 0.022939012706113683\n",
      "  Steps change: 13.4 → 53.8 (+40.3)\n",
      "before pred: 0.2761588519868585\n",
      "after pred: 0.38997072945945377\n",
      "  Avg glucose prediction change: +0.2942\n",
      "Individual 67:\n",
      "  CI change: 0.01544680764224739\n",
      "  Steps change: 4.8 → 19.1 (+14.3)\n",
      "before pred: 1.2368219260328956\n",
      "after pred: 0.5848422130354433\n",
      "  Avg glucose prediction change: -0.4272\n",
      "Individual 157:\n",
      "  CI change: 0.03559298837211236\n",
      "  Steps change: 21.2 → 84.9 (+63.6)\n",
      "before pred: 0.2822257335202659\n",
      "after pred: 0.03980725727211218\n",
      "  Avg glucose prediction change: -0.3690\n",
      "Individual 228:\n",
      "  CI change: 0.029365884525359764\n",
      "  Steps change: 19.2 → 76.6 (+57.5)\n",
      "before pred: -0.30658901520455817\n",
      "after pred: -0.052033301104218874\n",
      "  Avg glucose prediction change: +0.1715\n",
      "Individual 58:\n",
      "  CI change: 0.016388578970736215\n",
      "  Steps change: 8.5 → 34.0 (+25.5)\n",
      "before pred: -0.6882120049573583\n",
      "after pred: -0.5779382778777531\n",
      "  Avg glucose prediction change: +0.0682\n",
      "Individual 107:\n",
      "  CI change: -0.028836129782307568\n",
      "  Steps change: 2.7 → 11.0 (+8.2)\n",
      "before pred: -0.4019752251248497\n",
      "after pred: -0.8385455789406957\n",
      "  Avg glucose prediction change: -0.3615\n",
      "Individual 96:\n",
      "  CI change: 0.0105897737392289\n",
      "  Steps change: 14.5 → 57.8 (+43.4)\n",
      "before pred: -0.378401577779072\n",
      "after pred: -0.36325415494750923\n",
      "  Avg glucose prediction change: +0.1370\n",
      "Individual 120:\n",
      "  CI change: 0.0006724654012528117\n",
      "  Steps change: 1.7 → 6.7 (+5.0)\n",
      "before pred: -0.060916510683529254\n",
      "after pred: -0.21666747115944907\n",
      "  Avg glucose prediction change: -0.2088\n",
      "Individual 253:\n",
      "  CI change: 0.006596055396203881\n",
      "  Steps change: 2.7 → 10.8 (+8.1)\n",
      "before pred: -0.6047667605057606\n",
      "after pred: -0.6064807247735022\n",
      "  Avg glucose prediction change: +0.0786\n",
      "Individual 194:\n",
      "  CI change: 0.008467832910936656\n",
      "  Steps change: 0.8 → 3.3 (+2.4)\n",
      "before pred: 0.14731285597611515\n",
      "after pred: 0.36239298984945667\n",
      "  Avg glucose prediction change: +0.2988\n",
      "Individual 105:\n",
      "  CI change: 0.010327183110415554\n",
      "  Steps change: 3.4 → 13.7 (+10.3)\n",
      "before pred: 1.6039598918708573\n",
      "after pred: 1.5248691060484618\n",
      "  Avg glucose prediction change: -0.1151\n",
      "Individual 143:\n",
      "  CI change: 0.003378456307105121\n",
      "  Steps change: 2.8 → 11.1 (+8.3)\n",
      "before pred: -0.41551111256403594\n",
      "after pred: -0.4341484716041375\n",
      "  Avg glucose prediction change: +0.0238\n",
      "Individual 250:\n",
      "  CI change: 0.02396677129302864\n",
      "  Steps change: 11.2 → 45.0 (+33.7)\n",
      "before pred: 1.698653212151294\n",
      "after pred: 2.330589156819041\n",
      "  Avg glucose prediction change: +0.8401\n",
      "Individual 145:\n",
      "  CI change: 0.005872217728155313\n",
      "  Steps change: 4.6 → 18.5 (+13.9)\n",
      "before pred: -0.05185539770620311\n",
      "after pred: -0.2721887768904392\n",
      "  Avg glucose prediction change: -0.1458\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Individual time series plots for each perturbed individual (following HbA1c style)\n",
    "if 'individuals_to_perturb_indices' not in locals() or \\\n",
    "   'sampled_output_before_perturb' not in locals() or \\\n",
    "   'sampled_output_after_perturb' not in locals():\n",
    "    print(\"Error: Ensure the perturbation analysis has been run and variables are available.\")\n",
    "else:\n",
    "    # Get the time series data for plotting\n",
    "    seq_len = batch_x_orig.shape[1]\n",
    "    # Defensive: pred_len should be the last dimension of the predictions\n",
    "    # For before perturb: shape (num_individuals, num_samples, pred_len)\n",
    "    # For after perturb: shape (num_individuals, num_samples, pred_len, num_channels) or (num_individuals, num_samples, pred_len) if squeezed\n",
    "    # We'll handle both cases\n",
    "    if sampled_output_before_perturb.ndim == 3:\n",
    "        pred_len = sampled_output_before_perturb.shape[2]\n",
    "    elif sampled_output_before_perturb.ndim == 2:\n",
    "        pred_len = sampled_output_before_perturb.shape[1]\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected shape for sampled_output_before_perturb\")\n",
    "    time_history = np.arange(seq_len)\n",
    "    time_pred = np.arange(seq_len, seq_len + pred_len)\n",
    "\n",
    "    # Plot individual time series for each perturbed individual\n",
    "    for idx in individuals_to_perturb_indices:\n",
    "        # Get input history (glucose channel)\n",
    "        history_data = batch_x_orig[idx, :, 0].cpu().numpy()  # Assuming glucose is channel 0\n",
    "\n",
    "        # Get ground truth future\n",
    "        true_future_data = batch_y_orig[idx, -pred_len:, 0].cpu().numpy()  # Glucose channel\n",
    "\n",
    "        # Get predictions before perturbation\n",
    "        preds_before_raw = sampled_output_before_perturb[idx]  # (num_samples, pred_len)\n",
    "        if preds_before_raw.ndim == 2:\n",
    "            mean_preds_before = np.mean(preds_before_raw, axis=0)\n",
    "            std_preds_before = np.std(preds_before_raw, axis=0)\n",
    "        elif preds_before_raw.ndim == 1:\n",
    "            mean_preds_before = preds_before_raw\n",
    "            std_preds_before = np.zeros_like(mean_preds_before)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected shape for preds_before_raw\")\n",
    "\n",
    "        # Get predictions after perturbation\n",
    "        preds_after_raw = sampled_output_after_perturb[idx]\n",
    "        # Handle possible extra channel dimension\n",
    "        if preds_after_raw.ndim == 3:\n",
    "            # (num_samples, pred_len, num_channels)\n",
    "            preds_after_raw = preds_after_raw[..., 0]  # Glucose channel\n",
    "        if preds_after_raw.ndim == 2:\n",
    "            mean_preds_after = np.mean(preds_after_raw, axis=0)\n",
    "            std_preds_after = np.std(preds_after_raw, axis=0)\n",
    "        elif preds_after_raw.ndim == 1:\n",
    "            mean_preds_after = preds_after_raw\n",
    "            std_preds_after = np.zeros_like(mean_preds_after)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected shape for preds_after_raw\")\n",
    "\n",
    "        # Ensure all arrays are 1D and of length pred_len\n",
    "        mean_preds_before = np.asarray(mean_preds_before).flatten()\n",
    "        std_preds_before = np.asarray(std_preds_before).flatten()\n",
    "        mean_preds_after = np.asarray(mean_preds_after).flatten()\n",
    "        std_preds_after = np.asarray(std_preds_after).flatten()\n",
    "        true_future_data = np.asarray(true_future_data).flatten()\n",
    "        # Defensive: truncate or pad to pred_len if needed\n",
    "        if mean_preds_before.shape[0] != pred_len:\n",
    "            mean_preds_before = mean_preds_before[:pred_len]\n",
    "            std_preds_before = std_preds_before[:pred_len]\n",
    "        if mean_preds_after.shape[0] != pred_len:\n",
    "            mean_preds_after = mean_preds_after[:pred_len]\n",
    "            std_preds_after = std_preds_after[:pred_len]\n",
    "        if true_future_data.shape[0] != pred_len:\n",
    "            true_future_data = true_future_data[:pred_len]\n",
    "\n",
    "        plt.figure(figsize=(15, 7))\n",
    "\n",
    "        # Plot input history\n",
    "        plt.plot(time_history, history_data, label='Input History (Glucose)',\n",
    "                 color='black', linewidth=1.5)\n",
    "\n",
    "        # Plot ground truth future\n",
    "        plt.plot(time_pred, true_future_data, label='Ground Truth Future (Glucose)',\n",
    "                 color='green', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Plot predictions before perturbation\n",
    "        plt.plot(time_pred, mean_preds_before,\n",
    "                 label=f'Mean Pred (Before Perturb, Orig Steps: {original_steps_values[idx]:.1f})',\n",
    "                 color='blue', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_before - std_preds_before,\n",
    "                         mean_preds_before + std_preds_before,\n",
    "                         color='blue', alpha=0.2, label='Std Dev (Before)')\n",
    "\n",
    "        # Plot predictions after perturbation\n",
    "        plt.plot(time_pred, mean_preds_after,\n",
    "                 label=f'Mean Pred (After Perturb, New Steps: {perturbed_steps_values[idx]:.1f})',\n",
    "                 color='red', linewidth=1.5)\n",
    "        plt.fill_between(time_pred, mean_preds_after - std_preds_after,\n",
    "                         mean_preds_after + std_preds_after,\n",
    "                         color='red', alpha=0.2, label='Std Dev (After)')\n",
    "\n",
    "        plt.title(f'Glucose Prediction Steps Perturbation Analysis for Individual {idx}', fontsize=16)\n",
    "        plt.xlabel('Time Steps', fontsize=14)\n",
    "        plt.ylabel('Glucose Value', fontsize=14)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# === Summary statistics analysis ====================================\n",
    "# ---------------------------------------------------------------------\n",
    "print(f\"\\n=== Steps Perturbation Summary Analysis ===\")\n",
    "print(f\"Perturbation applied: {percentage_increase_steps}% change in steps\")\n",
    "print(f\"Number of individuals perturbed: {len(individuals_to_perturb_indices)}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  Prediction means (µ) and 95 %-CI half-widths (±1.96·σ/√n)\n",
    "# ---------------------------------------------------------------------\n",
    "# -- mean predictions -------------------------------------------------\n",
    "pred_mean_before = sampled_output_before_perturb.mean(axis=1)            # (N, pred_len)\n",
    "\n",
    "# unify AFTER tensor shape to (N, n_samples, pred_len)\n",
    "sampled_after = (\n",
    "    sampled_output_after_perturb[..., 0] if sampled_output_after_perturb.ndim == 4\n",
    "    else sampled_output_after_perturb\n",
    ")\n",
    "pred_mean_after = sampled_after.mean(axis=1)                              # (N, pred_len)\n",
    "\n",
    "# -- 95 %-CI half-widths ---------------------------------------------\n",
    "n_samp_b, n_samp_a = sampled_output_before_perturb.shape[1], sampled_after.shape[1]\n",
    "ci_half_before = 1.96 * sampled_output_before_perturb.std(axis=1) / np.sqrt(n_samp_b)\n",
    "ci_half_after  = 1.96 * sampled_after.std(axis=1)              / np.sqrt(n_samp_a)\n",
    "\n",
    "# average CI change (after - before)  ➜ report *width* change\n",
    "ci_change      = ci_half_after - ci_half_before                 # (N, pred_len)\n",
    "pert_ci_change = ci_change[individuals_to_perturb_indices].mean()\n",
    "ctrl_indices   = [i for i in range(ci_change.shape[0]) if i not in individuals_to_perturb_indices]\n",
    "ctrl_ci_change = ci_change[ctrl_indices].mean() if ctrl_indices else 0.0\n",
    "\n",
    "print(f\"Average 95 %-CI width change (perturbed individuals): {pert_ci_change:+.4f}\")\n",
    "print(f\"Average 95 %-CI width change (control individuals)  : {ctrl_ci_change:+.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  Point estimate differences --------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "pred_diff      = pred_mean_after - pred_mean_before                       # (N, pred_len)\n",
    "pert_diff      = pred_diff[individuals_to_perturb_indices].mean()\n",
    "ctrl_diff      = pred_diff[ctrl_indices].mean() if ctrl_indices else 0.0\n",
    "\n",
    "print(f\"Average glucose prediction change  (perturbed) : {pert_diff:+.4f}\")\n",
    "print(f\"Average glucose prediction change  (control)   : {ctrl_diff:+.4f}\")\n",
    "print(f\"Differential effect of steps perturbation      : {(pert_diff-ctrl_diff):+.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Per-individual report  (filtered) --------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "print(f\"\\n=== Individual Results (|Δµ| ≥ 0.1) ===\")\n",
    "for i_idx in individuals_to_perturb_indices:\n",
    "    steps_change = perturbed_steps_values[i_idx] - original_steps_values[i_idx]\n",
    "    # use last-timestep mean prediction\n",
    "    pred_change  = pred_mean_after[i_idx, -1] - pred_mean_before[i_idx, -1]\n",
    "    \n",
    "\n",
    "    CI_change = ci_change[i_idx].mean()\n",
    "\n",
    "\n",
    "    # skip tiny effects\n",
    "    if  (abs(steps_change) < 1):\n",
    "        continue\n",
    "\n",
    "    print(f\"Individual {i_idx}:\")\n",
    "    print(f\"  CI change: {CI_change}\")\n",
    "    print(f\"  Steps change: {original_steps_values[i_idx]:.1f} → {perturbed_steps_values[i_idx]:.1f} \"\n",
    "          f\"({steps_change:+.1f})\")\n",
    "    print(f\"before pred: {pred_mean_before[i_idx].mean()}\")\n",
    "    print(f\"after pred: {pred_mean_after[i_idx].mean()}\")\n",
    "    print(f\"  Avg glucose prediction change: {pred_change:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Filtering Analysis: Step Changes > 20 ===\n",
      "Total perturbed individuals: 256\n",
      "Individuals with step change > 20: 0\n",
      "No individuals have step changes > 20. Cannot proceed with analysis.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Individual time series plots for each perturbed individual (following HbA1c style)\n",
    "if 'individuals_to_perturb_indices' not in locals() or \\\n",
    "   'sampled_output_before_perturb' not in locals() or \\\n",
    "   'sampled_output_after_perturb' not in locals():\n",
    "    print(\"Error: Ensure the perturbation analysis has been run and variables are available.\")\n",
    "else:\n",
    "    # Filter individuals based on step change > 20\n",
    "    significant_change_indices = []\n",
    "    for idx in individuals_to_perturb_indices:\n",
    "        steps_change = abs(perturbed_steps_values[idx] - original_steps_values[idx])\n",
    "        if steps_change > 10:\n",
    "            significant_change_indices.append(idx)\n",
    "    \n",
    "    print(f\"=== Filtering Analysis: Step Changes > 20 ===\")\n",
    "    print(f\"Total perturbed individuals: {len(individuals_to_perturb_indices)}\")\n",
    "    print(f\"Individuals with step change > 20: {len(significant_change_indices)}\")\n",
    "    \n",
    "    if len(significant_change_indices) == 0:\n",
    "        print(\"No individuals have step changes > 20. Cannot proceed with analysis.\")\n",
    "    else:\n",
    "        # Get the time series data for plotting\n",
    "        seq_len = batch_x_orig.shape[1]\n",
    "        # Defensive: pred_len should be the last dimension of the predictions\n",
    "        if sampled_output_before_perturb.ndim == 3:\n",
    "            pred_len = sampled_output_before_perturb.shape[2]\n",
    "        elif sampled_output_before_perturb.ndim == 2:\n",
    "            pred_len = sampled_output_before_perturb.shape[1]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected shape for sampled_output_before_perturb\")\n",
    "        time_history = np.arange(seq_len)\n",
    "        time_pred = np.arange(seq_len, seq_len + pred_len)\n",
    "\n",
    "        # Plot individual time series for each individual with significant step change\n",
    "        for idx in significant_change_indices:\n",
    "            # Get input history (glucose channel)\n",
    "            history_data = batch_x_orig[idx, :, 0].cpu().numpy()  # Assuming glucose is channel 0\n",
    "\n",
    "            # Get ground truth future\n",
    "            true_future_data = batch_y_orig[idx, -pred_len:, 0].cpu().numpy()  # Glucose channel\n",
    "\n",
    "            # Get predictions before perturbation\n",
    "            preds_before_raw = sampled_output_before_perturb[idx]  # (num_samples, pred_len)\n",
    "            if preds_before_raw.ndim == 2:\n",
    "                mean_preds_before = np.mean(preds_before_raw, axis=0)\n",
    "                std_preds_before = np.std(preds_before_raw, axis=0)\n",
    "                # Calculate 95% confidence intervals\n",
    "                ci_lower_before = np.percentile(preds_before_raw, 2.5, axis=0)\n",
    "                ci_upper_before = np.percentile(preds_before_raw, 97.5, axis=0)\n",
    "            elif preds_before_raw.ndim == 1:\n",
    "                mean_preds_before = preds_before_raw\n",
    "                std_preds_before = np.zeros_like(mean_preds_before)\n",
    "                ci_lower_before = mean_preds_before\n",
    "                ci_upper_before = mean_preds_before\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected shape for preds_before_raw\")\n",
    "\n",
    "            # Get predictions after perturbation\n",
    "            preds_after_raw = sampled_output_after_perturb[idx]\n",
    "            # Handle possible extra channel dimension\n",
    "            if preds_after_raw.ndim == 3:\n",
    "                # (num_samples, pred_len, num_channels)\n",
    "                preds_after_raw = preds_after_raw[..., 0]  # Glucose channel\n",
    "            if preds_after_raw.ndim == 2:\n",
    "                mean_preds_after = np.mean(preds_after_raw, axis=0)\n",
    "                std_preds_after = np.std(preds_after_raw, axis=0)\n",
    "                # Calculate 95% confidence intervals\n",
    "                ci_lower_after = np.percentile(preds_after_raw, 2.5, axis=0)\n",
    "                ci_upper_after = np.percentile(preds_after_raw, 97.5, axis=0)\n",
    "            elif preds_after_raw.ndim == 1:\n",
    "                mean_preds_after = preds_after_raw\n",
    "                std_preds_after = np.zeros_like(mean_preds_after)\n",
    "                ci_lower_after = mean_preds_after\n",
    "                ci_upper_after = mean_preds_after\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected shape for preds_after_raw\")\n",
    "\n",
    "            # Ensure all arrays are 1D and of length pred_len\n",
    "            mean_preds_before = np.asarray(mean_preds_before).flatten()\n",
    "            std_preds_before = np.asarray(std_preds_before).flatten()\n",
    "            ci_lower_before = np.asarray(ci_lower_before).flatten()\n",
    "            ci_upper_before = np.asarray(ci_upper_before).flatten()\n",
    "            \n",
    "            mean_preds_after = np.asarray(mean_preds_after).flatten()\n",
    "            std_preds_after = np.asarray(std_preds_after).flatten()\n",
    "            ci_lower_after = np.asarray(ci_lower_after).flatten()\n",
    "            ci_upper_after = np.asarray(ci_upper_after).flatten()\n",
    "            \n",
    "            true_future_data = np.asarray(true_future_data).flatten()\n",
    "            \n",
    "            # Defensive: truncate or pad to pred_len if needed\n",
    "            if mean_preds_before.shape[0] != pred_len:\n",
    "                mean_preds_before = mean_preds_before[:pred_len]\n",
    "                std_preds_before = std_preds_before[:pred_len]\n",
    "                ci_lower_before = ci_lower_before[:pred_len]\n",
    "                ci_upper_before = ci_upper_before[:pred_len]\n",
    "            if mean_preds_after.shape[0] != pred_len:\n",
    "                mean_preds_after = mean_preds_after[:pred_len]\n",
    "                std_preds_after = std_preds_after[:pred_len]\n",
    "                ci_lower_after = ci_lower_after[:pred_len]\n",
    "                ci_upper_after = ci_upper_after[:pred_len]\n",
    "            if true_future_data.shape[0] != pred_len:\n",
    "                true_future_data = true_future_data[:pred_len]\n",
    "\n",
    "            plt.figure(figsize=(15, 8))\n",
    "\n",
    "            # Plot input history\n",
    "            plt.plot(time_history, history_data, label='Input History (Glucose)',\n",
    "                     color='black', linewidth=1.5)\n",
    "\n",
    "            # Plot ground truth future\n",
    "            plt.plot(time_pred, true_future_data, label='Ground Truth Future (Glucose)',\n",
    "                     color='green', linestyle='--', linewidth=2)\n",
    "\n",
    "            # Plot predictions before perturbation with confidence intervals\n",
    "            plt.plot(time_pred, mean_preds_before,\n",
    "                     label=f'Mean Pred (Before Perturb, Orig Steps: {original_steps_values[idx]:.1f})',\n",
    "                     color='blue', linewidth=1.5)\n",
    "            plt.fill_between(time_pred, ci_lower_before, ci_upper_before,\n",
    "                             color='blue', alpha=0.2, label='95% CI (Before)')\n",
    "\n",
    "            # Plot predictions after perturbation with confidence intervals\n",
    "            plt.plot(time_pred, mean_preds_after,\n",
    "                     label=f'Mean Pred (After Perturb, New Steps: {perturbed_steps_values[idx]:.1f})',\n",
    "                     color='red', linewidth=1.5)\n",
    "            plt.fill_between(time_pred, ci_lower_after, ci_upper_after,\n",
    "                             color='red', alpha=0.2, label='95% CI (After)')\n",
    "\n",
    "            # Calculate step change for title\n",
    "            steps_change = perturbed_steps_values[idx] - original_steps_values[idx]\n",
    "            plt.title(f'Glucose Prediction Steps Perturbation Analysis for Individual {idx}\\n'\n",
    "                     f'Step Change: {steps_change:+.1f} (>{20} threshold)', fontsize=16)\n",
    "            plt.xlabel('Time Steps', fontsize=14)\n",
    "            plt.ylabel('Glucose Value', fontsize=14)\n",
    "            plt.legend(fontsize=10, loc='best')\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Summary statistics analysis (only for individuals with step change > 20)\n",
    "        print(f\"\\n=== Steps Perturbation Summary Analysis (Step Change > 20) ===\")\n",
    "        print(f\"Perturbation applied: {percentage_increase_steps}% change in steps\")\n",
    "        print(f\"Number of individuals with significant step change (>20): {len(significant_change_indices)}\")\n",
    "\n",
    "        # Calculate prediction differences (only for significant changes)\n",
    "        pred_mean_before = sampled_output_before_perturb.mean(axis=1)  # (num_individuals, pred_len)\n",
    "        if sampled_output_after_perturb.ndim == 4:\n",
    "            pred_mean_after = sampled_output_after_perturb[..., 0].mean(axis=1)  # (num_individuals, pred_len)\n",
    "        else:\n",
    "            pred_mean_after = sampled_output_after_perturb.mean(axis=1)   # (num_individuals, pred_len)\n",
    "        pred_diff = pred_mean_after - pred_mean_before  # (num_individuals, pred_len)\n",
    "\n",
    "        # Calculate effect sizes (only for individuals with step change > 20)\n",
    "        if len(significant_change_indices) > 0:\n",
    "            significant_diff = pred_diff[significant_change_indices].mean()\n",
    "            \n",
    "            # Control group: individuals not significantly perturbed\n",
    "            control_indices = [i for i in range(pred_diff.shape[0]) if i not in significant_change_indices]\n",
    "            control_diff = pred_diff[control_indices].mean() if control_indices else 0\n",
    "\n",
    "            print(f\"Average glucose prediction change (individuals with step change >20): {significant_diff:.4f}\")\n",
    "            print(f\"Average glucose prediction change (control individuals): {control_diff:.4f}\")\n",
    "            print(f\"Differential effect of significant steps perturbation: {significant_diff - control_diff:.4f}\")\n",
    "\n",
    "            # Individual statistics (only for significant changes)\n",
    "            print(f\"\\n=== Individual Results (Step Change > 20) ===\")\n",
    "            for i_idx in significant_change_indices:\n",
    "                steps_change = perturbed_steps_values[i_idx] - original_steps_values[i_idx]\n",
    "                pred_change = pred_mean_after[i_idx].mean() - pred_mean_before[i_idx].mean()\n",
    "                \n",
    "                # Calculate confidence intervals for the prediction change\n",
    "                preds_before_individual = sampled_output_before_perturb[i_idx]\n",
    "                preds_after_individual = sampled_output_after_perturb[i_idx]\n",
    "                if preds_after_individual.ndim == 3:\n",
    "                    preds_after_individual = preds_after_individual[..., 0]\n",
    "                \n",
    "                # Calculate prediction differences for each sample\n",
    "                individual_pred_diffs = preds_after_individual.mean(axis=1) - preds_before_individual.mean(axis=1)\n",
    "                ci_lower_diff = np.percentile(individual_pred_diffs, 2.5)\n",
    "                ci_upper_diff = np.percentile(individual_pred_diffs, 97.5)\n",
    "                \n",
    "                print(f\"Individual {i_idx}:\")\n",
    "                print(f\"  Steps change: {original_steps_values[i_idx]:.1f} → {perturbed_steps_values[i_idx]:.1f} ({steps_change:+.1f})\")\n",
    "                print(f\"  Avg glucose prediction change: {pred_change:+.4f}\")\n",
    "                print(f\"  95% CI for prediction change: [{ci_lower_diff:+.4f}, {ci_upper_diff:+.4f}]\")\n",
    "        else:\n",
    "            print(\"No individuals meet the step change > 20 threshold.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cDIME",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
